{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5f417f",
   "metadata": {},
   "source": [
    "# Brazilian E-Commerce Data Exploration\n",
    "## Olist Dataset - Bronze Layer Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c1b47",
   "metadata": {},
   "source": [
    "### 1. Setup e Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "152bc61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import kaggle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e12a2d",
   "metadata": {},
   "source": [
    "### 2. Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57c4618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando pasta de destino: ..\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "# definindo nome dataset e caminho destino\n",
    "BASE_PATH = Path(\"../data/raw\") \n",
    "\n",
    "\n",
    "dataset_name = \"olistbr/brazilian-ecommerce\"\n",
    "destination_path = BASE_PATH # caminho de destino já está definido em BASE_PATH\n",
    "\n",
    "# cria a pasta 'raw' se ela não existir\n",
    "os.makedirs(destination_path, exist_ok=True)\n",
    "print(f\"Verificando pasta de destino: {destination_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe412e1",
   "metadata": {},
   "source": [
    "### Importando do Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82f7a7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baixando o dataset 'olistbr/brazilian-ecommerce'...\n",
      "Dataset URL: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\n",
      "Download e descompactação concluídos!\n"
     ]
    }
   ],
   "source": [
    "# importando dataset do kaggle\n",
    "try:\n",
    "    print(f\"\\nBaixando o dataset '{dataset_name}'...\")\n",
    "    kaggle.api.dataset_download_files(dataset_name, path=destination_path, unzip=True)\n",
    "    print(\"Download e descompactação concluídos!\")\n",
    "except Exception as e:\n",
    "    print(f\" Erro ao baixar o dataset: {e}\")\n",
    "    print(\"Verifique se o arquivo kaggle.json está no local correto.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9e603ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n",
      "\n",
      "✅ olist_orders_dataset.csv                      →     99,441 linhas\n",
      "✅ olist_order_items_dataset.csv                 →    112,650 linhas\n",
      "✅ olist_order_payments_dataset.csv              →    103,886 linhas\n",
      "✅ olist_order_reviews_dataset.csv               →     99,224 linhas\n",
      "✅ olist_customers_dataset.csv                   →     99,441 linhas\n",
      "✅ olist_products_dataset.csv                    →     32,951 linhas\n",
      "✅ olist_sellers_dataset.csv                     →      3,095 linhas\n",
      "✅ olist_geolocation_dataset.csv                 →  1,000,163 linhas\n",
      "✅ product_category_name_translation.csv         →         71 linhas\n"
     ]
    }
   ],
   "source": [
    "# Carregando os dados\n",
    "\n",
    "datasets = {}\n",
    "files = {\n",
    "    'orders': 'olist_orders_dataset.csv',\n",
    "    'items': 'olist_order_items_dataset.csv',\n",
    "    'payments': 'olist_order_payments_dataset.csv',\n",
    "    'reviews': 'olist_order_reviews_dataset.csv',\n",
    "    'customers': 'olist_customers_dataset.csv',\n",
    "    'products': 'olist_products_dataset.csv',\n",
    "    'sellers': 'olist_sellers_dataset.csv',\n",
    "    'geolocation': 'olist_geolocation_dataset.csv',\n",
    "    'translation': 'product_category_name_translation.csv'\n",
    "}\n",
    "\n",
    "print(\"Dados carregados com sucesso!\\n\")\n",
    "\n",
    "for name, filename in files.items():\n",
    "    filepath = BASE_PATH / filename\n",
    "    if filepath.exists():\n",
    "        datasets[name] = pd.read_csv(filepath, low_memory=False)\n",
    "        print(f\"✅ {filename:<45} → {len(datasets[name]):>10,} linhas\")\n",
    "    else:\n",
    "        print(f\"{filename:<45} → NÃO ENCONTRADO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnóstico: para cada dataset carregado, mostrar colunas, tipos e valores nulos\n",
    "\n",
    "def show_datasets_overview(datasets):\n",
    "    for name, df in datasets.items():\n",
    "        print(f\"\\n================ Dataset: {name} ================\\n\")\n",
    "        try:\n",
    "            print(f\"Total de linhas: {len(df):,}\")\n",
    "            print(\"Colunas e tipos:\")\n",
    "            # mostrar colunas e tipos de dados\n",
    "            for col, dtype in df.dtypes.items():\n",
    "                print(f\"  - {col:<40} : {dtype}\")\n",
    "\n",
    "            # calcular nulos por coluna\n",
    "            nulls = df.isnull().sum()\n",
    "            nulls = nulls[nulls > 0]\n",
    "            if nulls.empty:\n",
    "                print(\"Nenhum valor nulo encontrado.\")\n",
    "            else:\n",
    "                print(\"\\nColuna                          Nulos     %\")\n",
    "                for col in nulls.index:\n",
    "                    cnt = nulls[col]\n",
    "                    pct = (cnt / len(df)) * 100 if len(df) > 0 else 0\n",
    "                    print(f\"  {col:<30} {cnt:>8,} {pct:8.2f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao mostrar overview do dataset {name}: {e}\")\n",
    "\n",
    "# Chamar a função para imprimir o diagnóstico\n",
    "if 'datasets' in globals():\n",
    "    show_datasets_overview(datasets)\n",
    "else:\n",
    "    print(\"Variável 'datasets' não encontrada no escopo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32319b5b",
   "metadata": {},
   "source": [
    "### 3. Visão geral dos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed721287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de Arquivos: 9\n",
      "Total de Registros: 1,550,922 linhas\n"
     ]
    }
   ],
   "source": [
    "## Resumo dos dados (qtd arquivos e registros)\n",
    "\n",
    "total_rows = sum(len(df) for df in datasets.values()) # soma o número de linhas de todos os dataframes\n",
    "print(f\"\\nTotal de Arquivos: {len(datasets)}\")\n",
    "print(f\"Total de Registros: {total_rows:,} linhas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed721287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ ANÁLISE: ORDERS (pedidos) --------------------\n",
      "\n",
      "Total de pedidos: 99,441\n",
      "Colunas: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
      "\n",
      "Distribuição de Status:\n",
      "   - delivered            →  96,478 ( 97.0%)\n",
      "   - shipped              →   1,107 (  1.1%)\n",
      "   - canceled             →     625 (  0.6%)\n",
      "   - unavailable          →     609 (  0.6%)\n",
      "   - invoiced             →     314 (  0.3%)\n",
      "   - processing           →     301 (  0.3%)\n",
      "   - created              →       5 (  0.0%)\n",
      "   - approved             →       2 (  0.0%)\n",
      "\n",
      "Valores Nulos:\n",
      "   - order_approved_at              →    160 (  0.2%)\n",
      "   - order_delivered_carrier_date   →  1,783 (  1.8%)\n",
      "   - order_delivered_customer_date  →  2,965 (  3.0%)\n"
     ]
    }
   ],
   "source": [
    "########## Análise ORDERS ##########\n",
    "\n",
    "if 'orders' in datasets: # se o dataset 'orders' foi carregado\n",
    "    orders = datasets['orders']  \n",
    "\n",
    "    print(\"------------------ ANÁLISE: ORDERS (pedidos) --------------------\")\n",
    "\n",
    "    \n",
    "    print(f\"\\nTotal de pedidos: {len(orders):,}\")\n",
    "    print(f\"Colunas: {list(orders.columns)}\")\n",
    "    print(\"\\nDistribuição de Status:\")\n",
    "\n",
    "\n",
    "    # conta os valores únicos na coluna 'order_status', \n",
    "    # se a coluna tiver 1000 pedidos, e 700 forem 'delivered', 200 'shipped' e 100 'canceled',\n",
    "    # o resultado será {'delivered': 700, 'shipped': 200, 'canceled': 100}\n",
    "    status_dist = orders['order_status'].value_counts()\n",
    "\n",
    "    # para cada status e sua contagem, calcula a porcentagem e imprime\n",
    "    for status, count in status_dist.items(): \n",
    "        pct = (count / len(orders)) * 100 \n",
    "        print(f\"   - {status:<20} → {count:>7,} ({pct:>5.1f}%)\") \n",
    "    \n",
    "    # Valores nulos\n",
    "    print(\"\\nValores Nulos:\")\n",
    "    nulls = orders.isnull().sum() # conta valores nulos em cada coluna\n",
    "\n",
    "    # para cada coluna com valores nulos, calcula a porcentagem e imprime\n",
    "    for col in nulls[nulls > 0].index:\n",
    "        null_count = nulls[col]\n",
    "        null_pct = (null_count / len(orders)) * 100\n",
    "        print(f\"   - {col:<30} → {null_count:>6,} ({null_pct:>5.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abb4bab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ ANÁLISE: PAYMENTS (meio de pagamento) --------------------\n",
      "\n",
      "Total de Transações: 103,886\n",
      "\n",
      "Distribuição por Tipo de Pagamento:\n",
      "\n",
      "   - credit_card          →  76,795 ( 73.9%)\n",
      "   - boleto               →  19,784 ( 19.0%)\n",
      "   - voucher              →   5,775 (  5.6%)\n",
      "   - debit_card           →   1,529 (  1.5%)\n",
      "   - not_defined          →       3 (  0.0%)\n",
      "\n",
      "Valor Total Pago: R$ 16,008,872.12\n"
     ]
    }
   ],
   "source": [
    "########## Análise PAYMENTS ##########\n",
    "\n",
    "\n",
    "if 'payments' in datasets:\n",
    "    payments = datasets['payments']\n",
    "\n",
    "    print(\"------------------ ANÁLISE: PAYMENTS (meio de pagamento) --------------------\")\n",
    "    print(f\"\\nTotal de Transações: {len(payments):,}\")\n",
    "    print(\"\\nDistribuição por Tipo de Pagamento:\\n\")\n",
    "\n",
    "\n",
    "    payment_dist = payments['payment_type'].value_counts() # conta os valores únicos na coluna 'payment_type'\n",
    "\n",
    "    for payment_type, count in payment_dist.items():\n",
    "        pct = (count / len(payments)) * 100\n",
    "        print(f\"   - {payment_type:<20} → {count:>7,} ({pct:>5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nValor Total Pago: R$ {payments['payment_value'].sum():,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ffc7f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ ANÁLISE: REVIEWS (Avaliações) --------------------\n",
      "\n",
      "Total de Transações: 103,886\n",
      "\n",
      "Distribuição por Tipo de Pagamento:\n",
      "\n",
      "\n",
      "Total de Avaliações: 99,224\n",
      "\n",
      "Distribuição de Notas:\n",
      " (5) →  57,328 ( 57.8%)\n",
      " (4) →  19,142 ( 19.3%)\n",
      " (3) →   8,179 (  8.2%)\n",
      " (2) →   3,151 (  3.2%)\n",
      " (1) →  11,424 ( 11.5%)\n"
     ]
    }
   ],
   "source": [
    "########## Análise REVIEWS  ##########\n",
    "\n",
    "\n",
    "\n",
    "if 'reviews' in datasets:\n",
    "    reviews = datasets['reviews']\n",
    "\n",
    "    print(\"------------------ ANÁLISE: REVIEWS (Avaliações) --------------------\")\n",
    "    print(f\"\\nTotal de Transações: {len(payments):,}\")\n",
    "    print(\"\\nDistribuição por Tipo de Pagamento:\\n\")\n",
    "    print(f\"\\nTotal de Avaliações: {len(reviews):,}\")\n",
    "    \n",
    "    print(\"\\nDistribuição de Notas:\")\n",
    "\n",
    "    score_dist = reviews['review_score'].value_counts().sort_index(ascending=False)# conta os valores únicos na coluna 'review_score' e ordena do maior para o menor\n",
    "\n",
    "\n",
    "    for score, count in score_dist.items():\n",
    "        pct = (count / len(reviews)) * 100\n",
    "        print(f\" ({score}) → {count:>7,} ({pct:>5.1f}%)\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "496e36ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ ANÁLISE: PRODUCTS (Catálogo) --------------------\n",
      "\n",
      "Total de Produtos: 32,951\n",
      "\n",
      "Valores Nulos:\n",
      "   - product_category_name          →    610 (  1.9%)\n",
      "   - product_name_lenght            →    610 (  1.9%)\n",
      "   - product_description_lenght     →    610 (  1.9%)\n",
      "   - product_photos_qty             →    610 (  1.9%)\n",
      "   - product_weight_g               →      2 (  0.0%)\n",
      "   - product_length_cm              →      2 (  0.0%)\n",
      "   - product_height_cm              →      2 (  0.0%)\n",
      "   - product_width_cm               →      2 (  0.0%)\n",
      "\n",
      "Resumo das Categorias:\n",
      "   - Categorias Únicas: 73\n"
     ]
    }
   ],
   "source": [
    "########## Análise PRODUCTS (Catálogo) ##########\n",
    "\n",
    "if 'products' in datasets:\n",
    "    products = datasets['products']\n",
    "    \n",
    "    print(\"\\n------------------ ANÁLISE: PRODUCTS (Catálogo) --------------------\")\n",
    "    print(f\"\\nTotal de Produtos: {len(products):,}\")\n",
    "    print(\"\\nValores Nulos:\")\n",
    "    \n",
    "    # Valores nulos\n",
    "    nulls = products.isnull().sum()\n",
    "    for col in nulls[nulls > 0].index:\n",
    "        null_count = nulls[col]\n",
    "        null_pct = (null_count / len(products)) * 100\n",
    "        print(f\"   - {col:<30} → {null_count:>6,} ({null_pct:>5.1f}%)\")\n",
    "\n",
    "    # Categorias únicas (ajustado para o novo padrão)\n",
    "    print(\"\\nResumo das Categorias:\")\n",
    "    print(f\"   - Categorias Únicas: {products['product_category_name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b360f957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ ANÁLISE: SELLERS (Vendedores) --------------------\n",
      "\n",
      "Total de Vendedores: 3,095\n",
      "\n",
      "Resumo Geográfico:\n",
      "   - Cidades Únicas: 611\n",
      "   - Estados Únicos: 23\n",
      "\n",
      "Distribuição por Estado:\n",
      "   (SP   ) →   1,849 ( 59.7%)\n",
      "   (PR   ) →     349 ( 11.3%)\n",
      "   (MG   ) →     244 (  7.9%)\n",
      "   (SC   ) →     190 (  6.1%)\n",
      "   (RJ   ) →     171 (  5.5%)\n"
     ]
    }
   ],
   "source": [
    "########## Análise SELLERS (Vendedores) ##########\n",
    "\n",
    "if 'sellers' in datasets:\n",
    "    sellers = datasets['sellers']\n",
    "    \n",
    "    print(\"\\n------------------ ANÁLISE: SELLERS (Vendedores) --------------------\")\n",
    "    print(f\"\\nTotal de Vendedores: {len(sellers):,}\")\n",
    "    print(\"\\nResumo Geográfico:\")\n",
    "    print(f\"   - Cidades Únicas: {sellers['seller_city'].nunique()}\")\n",
    "    print(f\"   - Estados Únicos: {sellers['seller_state'].nunique()}\")\n",
    "    \n",
    "    # Top 5 Estados com mais vendedores (ajustado para o novo padrão)\n",
    "    print(\"\\nDistribuição por Estado:\")\n",
    "    top_states = sellers['seller_state'].value_counts().head(5)\n",
    "    for state, count in top_states.items():\n",
    "        pct = (count / len(sellers)) * 100\n",
    "        print(f\"   ({state:<5}) → {count:>7,} ({pct:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12d2732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ ANÁLISE: CUSTOMERS (Clientes) --------------------\n",
      "\n",
      "Total de Clientes: 99,441\n",
      "Total de Clientes Únicos: 96,096\n",
      "\n",
      "Resumo Geográfico:\n",
      "   - Cidades Únicas: 4119\n",
      "   - Estados Únicos: 27\n"
     ]
    }
   ],
   "source": [
    "########## Análise CUSTOMERS (Clientes) ##########\n",
    "\n",
    "if 'customers' in datasets:\n",
    "    customers = datasets['customers']\n",
    "    \n",
    "    print(\"\\n------------------ ANÁLISE: CUSTOMERS (Clientes) --------------------\")\n",
    "    print(f\"\\nTotal de Clientes: {len(customers):,}\")\n",
    "    print(f\"Total de Clientes Únicos: {customers['customer_unique_id'].nunique():,}\")\n",
    "    print(\"\\nResumo Geográfico:\")\n",
    "    print(f\"   - Cidades Únicas: {customers['customer_city'].nunique()}\")\n",
    "    print(f\"   - Estados Únicos: {customers['customer_state'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a5563c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ ANÁLISE: GEOLOCATION (Geografia) --------------------\n",
      "\n",
      "Total de Registros: 1,000,163\n",
      "Total de CEPs Únicos: 19,015\n",
      "Total de Cidades Únicas: 8,011\n"
     ]
    }
   ],
   "source": [
    "########## Análise GEOLOCATION (Geografia) ##########\n",
    "\n",
    "if 'geolocation' in datasets:\n",
    "    geo = datasets['geolocation']\n",
    "    \n",
    "    print(\"\\n------------------ ANÁLISE: GEOLOCATION (Geografia) --------------------\")\n",
    "    print(f\"\\nTotal de Registros: {len(geo):,}\")\n",
    "    print(f\"Total de CEPs Únicos: {geo['geolocation_zip_code_prefix'].nunique():,}\")\n",
    "    print(f\"Total de Cidades Únicas: {geo['geolocation_city'].nunique():,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
