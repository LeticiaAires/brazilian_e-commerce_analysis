{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0068f9d-075f-4d32-83c5-7c5247a97fc8",
   "metadata": {},
   "source": [
    "# ETL da camada Silver para camada Gold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84fa58a-b1d2-4d12-9c09-1f8c9b355d71",
   "metadata": {},
   "source": [
    "Esta célula importa todas as bibliotecas necessárias para o processo de ETL.\n",
    "Aqui são carregados os pacotes para manipulação de dados (pandas), conexão com o banco de dados PostgreSQL (psycopg), controle de mensagens de erro (sys) e tratamento de avisos (warnings).\n",
    "Ela deve ser executada antes de qualquer outra célula, pois fornece as dependências básicas que serão usadas nas etapas de Extract, Transform e Load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66405d39-8834-4564-ac01-6b3c5bd2f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg\n",
    "from psycopg import connect, sql\n",
    "import sys\n",
    "import warnings\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e503bd-17a3-45c6-b2de-9a026da11452",
   "metadata": {},
   "source": [
    "# 1. Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3aefa-7bba-4405-aa2e-b14d4631758a",
   "metadata": {},
   "source": [
    "Esta célula define as configurações de conexão com o banco de dados PostgreSQL e monta a consulta SQL que será usada para extrair os dados.\n",
    "Ela cria variáveis com credenciais, monta o nome completo da tabela (schema.tabela) e gera a query SELECT * FROM DL.ORDER_ITEMS, além de preparar a connection string usada na etapa de conexão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8653a-eda5-41c7-b1d5-54284054ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SCHEMA = \"DL\"\n",
    "TABLE_NAME = \"ORDER_ITEMS\"\n",
    "\n",
    "TABLE_FULL_NAME = sql.SQL(\"{}.{}\").format(\n",
    "    sql.Identifier(DB_SCHEMA),\n",
    "    sql.Identifier(TABLE_NAME)\n",
    ")\n",
    "\n",
    "def get_db_connection_info():\n",
    "    load_dotenv()\n",
    "    url = os.getenv('DB_URL')\n",
    "    db_env = os.getenv('DB_ENV')\n",
    "    if url is not None and db_env == 'prod':\n",
    "        return url\n",
    "\n",
    "    # credenciais do banco de dados local\n",
    "    DB_USER = \"postgres\"\n",
    "    DB_PASSWORD = \"postgres\"\n",
    "    DB_HOST = \"localhost\"\n",
    "    DB_PORT = \"5433\"\n",
    "    DB_NAME = \"olist\"\n",
    "\n",
    "    return f\"host={DB_HOST} dbname={DB_NAME} user={DB_USER} password={DB_PASSWORD} port={DB_PORT}\"\n",
    "\n",
    "\n",
    "query_object = sql.SQL(\"SELECT * FROM {}\").format(TABLE_FULL_NAME)\n",
    "\n",
    "connection_string = get_db_connection_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4bf8a8-93a2-4963-b547-e495b3c3d63f",
   "metadata": {},
   "source": [
    "Esta célula executa a extração dos dados do banco PostgreSQL.\n",
    "Ela estabelece a conexão usando as configurações definidas anteriormente, converte o objeto SQL em uma query legível, executa a consulta e carrega o resultado no DataFrame df.\n",
    "Em caso de falha na conexão ou na leitura, exibe uma mensagem de erro detalhada e encerra o processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02bc47-95a8-43ce-b090-fdd3ea9022e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Estabelecendo conexão...\")\n",
    "    with connect(connection_string) as conn:\n",
    "        print(\"Conexão estabelecida.\")\n",
    "        query_string = query_object.as_string(conn)\n",
    "        print(f\"Executando query: {query_string}\")\n",
    "        df = pd.read_sql_query(query_string, conn)\n",
    "    print(\"\\nDados carregados do banco para o DataFrame com sucesso!\")\n",
    "except psycopg.Error as e:\n",
    "    print(f\"\\n--- Ocorreu um erro ao conectar ou ler o banco de dados ---\")\n",
    "    print(f\"Erro: {e}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- Ocorreu um erro inesperado ---\")\n",
    "    print(f\"Erro: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b39988-5b56-428b-8f25-8700408cca2e",
   "metadata": {},
   "source": [
    "Estas células exibem um resumo simples do resultado da extração, mostrando o número total de registros carregados no DataFrame df, as primeiras três tuplas e os tipos de cada dado.\n",
    "Elas servem para confirmar visualmente que a consulta foi executada com sucesso e quantas linhas foram retornadas do banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0918d7-0264-45a2-8fda-3eba9add9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total de linhas carregadas: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a419cc-1c0d-4af9-9bf9-80426bfd8f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c3e8f-9a2b-4c5d-8e3f-9b4c5d6e7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4d5e6-7f8a-9b0c-1d2e-3f4a5b6c7d8e",
   "metadata": {},
   "source": [
    "# 2. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8-9a0b-1c2d-3e4f-5a6b7c8d9e0f",
   "metadata": {},
   "source": [
    "Esta célula define as colunas que farão parte de cada dimensão no modelo estrela.\n",
    "Cada lista de colunas corresponde aos atributos que serão extraídos do DataFrame principal para formar as tabelas dimensionais DIM_PRODUTOS, DIM_VENDEDORES, DIM_PEDIDOS e a dimensão temporal DIM_DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas para DIM_PRODUTOS\n",
    "cols_produtos = [\n",
    "    'product_category_name',\n",
    "    'product_name_lenght',\n",
    "    'product_description_lenght',\n",
    "    'product_photos_qty',\n",
    "    'product_weight_g',\n",
    "    'product_length_cm',\n",
    "    'product_height_cm',\n",
    "    'product_width_cm'\n",
    "]\n",
    "\n",
    "# Colunas para DIM_VENDEDORES\n",
    "cols_vendedores = [\n",
    "    'seller_zip_code_prefix',\n",
    "    'seller_city',\n",
    "    'seller_state',\n",
    "    'vendedor_geolocation_lat',\n",
    "    'vendedor_geolocation_lng'\n",
    "]\n",
    "\n",
    "# Colunas para DIM_PEDIDOS\n",
    "cols_pedidos = [\n",
    "    'review_comment_title',\n",
    "    'review_comment_message',\n",
    "    'customer_unique_id',\n",
    "    'order_status',\n",
    "    'qtd_payment_sequential',\n",
    "    'primeiro_payment_type',\n",
    "    'valor_total_pagamento',\n",
    "    'maximo_payment_installments',\n",
    "    'order_purchase_timestamp',\n",
    "    'order_delivered_customer_date',\n",
    "    'order_approved_at',\n",
    "    'order_delivered_carrier_date',\n",
    "    'order_estimated_delivery_date',\n",
    "    'review_score',\n",
    "    'review_creation_date',\n",
    "    'review_answer_timestamp',\n",
    "    'customer_zip_code_prefix',\n",
    "    'customer_city',\n",
    "    'customer_state',\n",
    "    'cliente_geolocation_lat',\n",
    "    'cliente_geolocation_lng'\n",
    "]\n",
    "\n",
    "# Coluna para DIM_DATA (será extraída de order_purchase_timestamp)\n",
    "col_data = 'order_purchase_timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8f9a0-b1c2-3d4e-5f6a-7b8c9d0e1f2a",
   "metadata": {},
   "source": [
    "Esta célula renomeia as colunas do DataFrame para corresponder à nomenclatura da camada Gold.\n",
    "Os nomes são padronizados com prefixos mnemônicos (prod_, vend_, geo_) conforme definido no dicionário de dados da camada Gold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0a1b2-c3d4-5e6f-7a8b-9c0d1e2f3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear colunas para nomenclatura Gold\n",
    "df = df.rename(columns={\n",
    "    # Produtos\n",
    "    'product_category_name': 'prod_category_name',\n",
    "    'product_name_lenght': 'prod_name_lenght',\n",
    "    'product_description_lenght': 'prod_desc_lenght',\n",
    "    'product_photos_qty': 'prod_photos_qty',\n",
    "    'product_weight_g': 'prod_weight_g',\n",
    "    'product_length_cm': 'prod_length_cm',\n",
    "    'product_height_cm': 'prod_height_cm',\n",
    "    'product_width_cm': 'prod_width_cm',\n",
    "    # Vendedores\n",
    "    'seller_zip_code_prefix': 'vend_zip_code_prefix',\n",
    "    'seller_city': 'vend_city',\n",
    "    'seller_state': 'vend_state',\n",
    "    'vendedor_geolocation_lat': 'vend_geo_lat',\n",
    "    'vendedor_geolocation_lng': 'vend_geo_lng',\n",
    "    # Cliente (geolocalização)\n",
    "    'cliente_geolocation_lat': 'cliente_geo_lat',\n",
    "    'cliente_geolocation_lng': 'cliente_geo_lng'\n",
    "})\n",
    "\n",
    "# Atualizar listas de colunas com novos nomes\n",
    "cols_produtos = [\n",
    "    'prod_category_name',\n",
    "    'prod_name_lenght',\n",
    "    'prod_desc_lenght',\n",
    "    'prod_photos_qty',\n",
    "    'prod_weight_g',\n",
    "    'prod_length_cm',\n",
    "    'prod_height_cm',\n",
    "    'prod_width_cm'\n",
    "]\n",
    "\n",
    "cols_vendedores = [\n",
    "    'vend_zip_code_prefix',\n",
    "    'vend_city',\n",
    "    'vend_state',\n",
    "    'vend_geo_lat',\n",
    "    'vend_geo_lng'\n",
    "]\n",
    "\n",
    "cols_pedidos = [\n",
    "    'review_comment_title',\n",
    "    'review_comment_message',\n",
    "    'customer_unique_id',\n",
    "    'order_status',\n",
    "    'qtd_payment_sequential',\n",
    "    'primeiro_payment_type',\n",
    "    'valor_total_pagamento',\n",
    "    'maximo_payment_installments',\n",
    "    'order_purchase_timestamp',\n",
    "    'order_delivered_customer_date',\n",
    "    'order_approved_at',\n",
    "    'order_delivered_carrier_date',\n",
    "    'order_estimated_delivery_date',\n",
    "    'review_score',\n",
    "    'review_creation_date',\n",
    "    'review_answer_timestamp',\n",
    "    'customer_zip_code_prefix',\n",
    "    'customer_city',\n",
    "    'customer_state',\n",
    "    'cliente_geo_lat',\n",
    "    'cliente_geo_lng'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2b3c4-d5e6-7f8a-9b0c-1d2e3f4a5b6c",
   "metadata": {},
   "source": [
    "Esta célula cria campos calculados para a dimensão DIM_PEDIDOS.\n",
    "Calcula o tempo de entrega em dias (tempo_entrega_dias) e a flag de atraso (flag_atraso) comparando a data de entrega real com a data estimada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6c7d8-e9f0-1a2b-3c4d-5e6f7a8b9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter colunas de timestamp para datetime\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "df['order_estimated_delivery_date'] = pd.to_datetime(df['order_estimated_delivery_date'])\n",
    "\n",
    "# Calcular tempo de entrega em dias\n",
    "df['tempo_entrega_dias'] = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.days\n",
    "\n",
    "# Calcular flag de atraso (1 se atrasou, 0 se não)\n",
    "df['flag_atraso'] = ((df['order_delivered_customer_date'] > df['order_estimated_delivery_date']).astype(int))\n",
    "\n",
    "# Adicionar campos calculados à lista de colunas de pedidos\n",
    "cols_pedidos.extend(['tempo_entrega_dias', 'flag_atraso'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7d8e9-f0a1-2b3c-4d5e-6f7a8b9c0d1e",
   "metadata": {},
   "source": [
    "Esta célula cria a dimensão temporal DIM_DATA extraindo datas únicas do campo order_purchase_timestamp.\n",
    "Para cada data única, extrai ano, mês, dia e dia da semana em português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8e9f0-a1b2-3c4d-5e6f-7a8b9c0d1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair datas únicas\n",
    "df_data = df[[col_data]].copy()\n",
    "df_data['data_completa'] = df_data[col_data].dt.date\n",
    "df_data = df_data[['data_completa']].drop_duplicates().copy()\n",
    "\n",
    "# Converter para datetime para extrair componentes\n",
    "df_data['data_completa'] = pd.to_datetime(df_data['data_completa'])\n",
    "\n",
    "# Extrair componentes da data\n",
    "df_data['ano'] = df_data['data_completa'].dt.year\n",
    "df_data['mes'] = df_data['data_completa'].dt.month\n",
    "df_data['dia'] = df_data['data_completa'].dt.day\n",
    "\n",
    "# Mapear dia da semana para português\n",
    "dias_semana_pt = {\n",
    "    0: 'Segunda',\n",
    "    1: 'Terça',\n",
    "    2: 'Quarta',\n",
    "    3: 'Quinta',\n",
    "    4: 'Sexta',\n",
    "    5: 'Sábado',\n",
    "    6: 'Domingo'\n",
    "}\n",
    "df_data['dia_da_semana'] = df_data['data_completa'].dt.dayofweek.map(dias_semana_pt)\n",
    "\n",
    "# Converter data_completa de volta para date\n",
    "df_data['data_completa'] = df_data['data_completa'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9f0a1-b2c3-4d5e-6f7a-8b9c0d1e2f3a",
   "metadata": {},
   "source": [
    "Esta célula cria DataFrames separados para cada dimensão, removendo duplicatas.\n",
    "Cada DataFrame conterá apenas as colunas relevantes para sua respectiva dimensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0a1b2-c3d4-5e6f-7a8b-9c0d1e2f3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_produtos = df[cols_produtos].drop_duplicates().copy()\n",
    "df_vendedores = df[cols_vendedores].drop_duplicates().copy()\n",
    "df_pedidos = df[cols_pedidos].drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1b2c3-d4e5-6f7a-8b9c-0d1e2f3a4b5c",
   "metadata": {},
   "source": [
    "Esta célula realiza a padronização e limpeza dos campos numéricos do DataFrame.\n",
    "Ela converte todas as colunas de métricas para tipo numérico, substitui valores infinitos por NaN e depois transforma todos os NaN e valores ausentes em None, garantindo que o banco de dados receba NULL corretamente durante a carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2bcf6-20ed-4ec9-b1f3-a09711204c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['price', 'freight_value', 'tempo_entrega_dias']\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.where(pd.notna(df), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d",
   "metadata": {},
   "source": [
    "Esta célula exibe um resumo da etapa de transformação, mostrando quantos registros foram preparados em cada dimensão e na tabela fato base.\n",
    "Em seguida, utiliza df.info() para apresentar a estrutura geral do DataFrame principal, permitindo verificar tipos de dados e possíveis valores nulos antes da carga no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7954d14-5c17-4dd2-bb28-96b35fea050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Registros preparados para carga:\")\n",
    "print(f\"DIM_PRODUTOS: {len(df_produtos)}\")\n",
    "print(f\"DIM_VENDEDORES: {len(df_vendedores)}\")\n",
    "print(f\"DIM_PEDIDOS: {len(df_pedidos)}\")\n",
    "print(f\"DIM_DATA: {len(df_data)}\")\n",
    "print(f\"FATO_ITENS_PEDIDO (base df): {len(df)}\\n\\n\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe0394e-0dc6-471f-a7b9-2965b2498912",
   "metadata": {},
   "source": [
    "# 3. Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716cf2d4-5418-48ee-835f-a68e36f5fefb",
   "metadata": {},
   "source": [
    "Esta célula configura os parâmetros de conexão com o banco de dados do Data Warehouse (DW) e valida se todas as variáveis geradas na etapa de transformação estão disponíveis na memória.\n",
    "Ela garante que o ambiente esteja pronto antes de iniciar a fase de carga, evitando erros por falta de dados ou variáveis necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e779b8d-dd04-439b-bea3-7c2418ebe77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SCHEMA_GOLD = \"DW\"\n",
    "\n",
    "connection_string = get_db_connection_info()\n",
    "\n",
    "for v in ['df', 'df_produtos', 'df_vendedores', 'df_pedidos', 'df_data', 'cols_produtos', 'cols_vendedores', 'cols_pedidos', 'col_data']:\n",
    "    if v not in globals():\n",
    "        raise RuntimeError(f\"Variável ausente: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915271d-7a91-447e-a7e1-182c4a09a312",
   "metadata": {},
   "source": [
    "Esta célula executa o script DDL responsável por criar ou recriar as tabelas do schema DW no banco de dados.\n",
    "Ela lê o arquivo SQL que contém a definição das tabelas e executa o comando dentro de uma conexão com o PostgreSQL, preparando a estrutura necessária para receber os dados na etapa de carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb09603-ab9b-47f6-9d8f-305a95b82ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ddl_gold = open('../Gold/DDL.sql').read()\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivo 'DDL.sql' não encontrado em '../Gold/DDL.sql'.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(ddl_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729132b-f4dc-4008-aa6b-0c9b2c5c1447",
   "metadata": {},
   "source": [
    "Esta célula realiza a carga da dimensão Produtos no schema DW.\n",
    "Ela insere todos os registros do DataFrame df_produtos na tabela DIM_PRODUTOS e adiciona uma linha extra com valores nulos para representar o registro "desconhecido", armazenando sua chave substituta (unknown_prod_key) para uso posterior na carga da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5349745-a71a-441b-ad4a-81f4616d1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.DIM_PRODUTOS (\n",
    "                prod_category_name, prod_name_lenght, prod_desc_lenght, prod_photos_qty,\n",
    "                prod_weight_g, prod_length_cm, prod_height_cm, prod_width_cm\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "        cur.executemany(insert_query, [tuple(x) for x in df_produtos.to_numpy()])\n",
    "        cur.execute(\n",
    "            \"\"\"INSERT INTO DW.DIM_PRODUTOS (\n",
    "                prod_category_name, prod_name_lenght, prod_desc_lenght, prod_photos_qty,\n",
    "                prod_weight_g, prod_length_cm, prod_height_cm, prod_width_cm\n",
    "            ) VALUES (NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL) RETURNING \"SRK_prod\"\"\"\n",
    "        )\n",
    "        unknown_prod_key = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2fe8f-08b7-435f-9f2d-66dd7bf2d532",
   "metadata": {},
   "source": [
    "Esta célula insere os dados da dimensão Vendedores no schema DW.\n",
    "Ela carrega todos os registros do DataFrame df_vendedores na tabela DIM_VENDEDORES e adiciona um registro adicional com valores nulos para representar o vendedor "desconhecido", salvando sua chave substituta (unknown_vend_key) para uso posterior na carga da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b3b18-8954-4ccc-acdd-35276dfa399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.DIM_VENDEDORES (\n",
    "                vend_zip_code_prefix, vend_city, vend_state, geo_lat, geo_lng\n",
    "            ) VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "        cur.executemany(insert_query, [tuple(x) for x in df_vendedores.to_numpy()])\n",
    "        cur.execute(\n",
    "            \"\"\"INSERT INTO DW.DIM_VENDEDORES (\n",
    "                vend_zip_code_prefix, vend_city, vend_state, geo_lat, geo_lng\n",
    "            ) VALUES (NULL, NULL, NULL, NULL, NULL) RETURNING \"SRK_vend\"\"\"\n",
    "        )\n",
    "        unknown_vend_key = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d0a5c0-40da-4300-b353-037f88a46caf",
   "metadata": {},
   "source": [
    "Esta célula carrega os dados da dimensão Data no schema DW.\n",
    "Ela insere os registros do DataFrame df_data na tabela DIM_DATA e adiciona um registro com valores nulos para representar datas desconhecidas, salvando sua chave substituta (unknown_data_key) que será usada na inserção da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e00be8-4979-415c-b9ec-e55851a209dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.DIM_DATA (\n",
    "                data_completa, ano, mes, dia, dia_da_semana\n",
    "            ) VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "        cur.executemany(insert_query, [tuple(x) for x in df_data.to_numpy()])\n",
    "        cur.execute(\n",
    "            \"\"\"INSERT INTO DW.DIM_DATA (\n",
    "                data_completa, ano, mes, dia, dia_da_semana\n",
    "            ) VALUES (NULL, NULL, NULL, NULL, NULL) RETURNING \"SRK_data\"\"\"\n",
    "        )\n",
    "        unknown_data_key = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e2a1a-43f1-4d2a-87ba-0d95a8579030",
   "metadata": {},
   "source": [
    "Esta célula realiza a carga da dimensão Pedidos no schema DW.\n",
    "Ela insere os registros do DataFrame df_pedidos na tabela DIM_PEDIDOS e adiciona um registro com valores nulos para representar pedidos ausentes, armazenando a chave substituta (unknown_ord_key) que será utilizada posteriormente na carga da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc718c25-dad6-4969-91f2-ab1250dab316",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.DIM_PEDIDOS (\n",
    "                review_comment_title, review_comment_message, customer_unique_id, order_status,\n",
    "                qtd_payment_sequential, primeiro_payment_type, valor_total_pagamento, maximo_payment_installments,\n",
    "                order_purchase_timestamp, order_delivered_customer_date, tempo_entrega_dias, flag_atraso,\n",
    "                order_approved_at, order_delivered_carrier_date, order_estimated_delivery_date,\n",
    "                review_score, review_creation_date, review_answer_timestamp,\n",
    "                customer_zip_code_prefix, customer_city, customer_state, geo_lat, geo_lng\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Preparar dados com renomeação de geo_lat e geo_lng\n",
    "        df_pedidos_load = df_pedidos.copy()\n",
    "        df_pedidos_load = df_pedidos_load.rename(columns={\n",
    "            'cliente_geo_lat': 'geo_lat',\n",
    "            'cliente_geo_lng': 'geo_lng'\n",
    "        })\n",
    "        \n",
    "        cols_pedidos_load = [\n",
    "            'review_comment_title', 'review_comment_message', 'customer_unique_id', 'order_status',\n",
    "            'qtd_payment_sequential', 'primeiro_payment_type', 'valor_total_pagamento', 'maximo_payment_installments',\n",
    "            'order_purchase_timestamp', 'order_delivered_customer_date', 'tempo_entrega_dias', 'flag_atraso',\n",
    "            'order_approved_at', 'order_delivered_carrier_date', 'order_estimated_delivery_date',\n",
    "            'review_score', 'review_creation_date', 'review_answer_timestamp',\n",
    "            'customer_zip_code_prefix', 'customer_city', 'customer_state', 'geo_lat', 'geo_lng'\n",
    "        ]\n",
    "        \n",
    "        cur.executemany(insert_query, [tuple(x) for x in df_pedidos_load[cols_pedidos_load].to_numpy()])\n",
    "        cur.execute(\n",
    "            \"\"\"INSERT INTO DW.DIM_PEDIDOS (\n",
    "                review_comment_title, review_comment_message, customer_unique_id, order_status,\n",
    "                qtd_payment_sequential, primeiro_payment_type, valor_total_pagamento, maximo_payment_installments,\n",
    "                order_purchase_timestamp, order_delivered_customer_date, tempo_entrega_dias, flag_atraso,\n",
    "                order_approved_at, order_delivered_carrier_date, order_estimated_delivery_date,\n",
    "                review_score, review_creation_date, review_answer_timestamp,\n",
    "                customer_zip_code_prefix, customer_city, customer_state, geo_lat, geo_lng\n",
    "            ) VALUES (NULL, NULL, 'UNKNOWN', 'unknown', NULL, NULL, NULL, NULL, '1900-01-01', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL) RETURNING \"SRK_ord\"\"\"\n",
    "        )\n",
    "        unknown_ord_key = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4bb4fa-8145-4716-aae9-8b69de2bec68",
   "metadata": {},
   "source": [
    "Esta célula faz o mapeamento das chaves substitutas (SRKs) das dimensões para o DataFrame principal.\n",
    "Ela lê as tabelas dimensionais do banco, realiza os joins com o DataFrame original (df) e substitui valores ausentes pelas chaves "desconhecidas".\n",
    "O resultado é o DataFrame df_fato, já com todas as referências dimensionais resolvidas e pronto para ser inserido na tabela fato FATO_ITENS_PEDIDO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112fc738-199a-445a-9531-74b6898573cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    df_produtos_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_PRODUTOS', conn)\n",
    "    df_vendedores_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_VENDEDORES', conn)\n",
    "    df_pedidos_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_PEDIDOS', conn)\n",
    "    df_data_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_DATA', conn)\n",
    "\n",
    "# Preparar DataFrame para merge\n",
    "df_m = df.copy()\n",
    "\n",
    "# Preparar coluna de data para merge\n",
    "df_m['data_completa'] = df_m['order_purchase_timestamp'].dt.date\n",
    "df_data_com_chaves['data_completa'] = pd.to_datetime(df_data_com_chaves['data_completa']).dt.date\n",
    "\n",
    "# Renomear colunas de vendedores para merge\n",
    "df_vendedores_com_chaves = df_vendedores_com_chaves.rename(columns={\n",
    "    'geo_lat': 'vend_geo_lat',\n",
    "    'geo_lng': 'vend_geo_lng'\n",
    "})\n",
    "\n",
    "# Renomear colunas de pedidos para merge\n",
    "df_pedidos_com_chaves = df_pedidos_com_chaves.rename(columns={\n",
    "    'geo_lat': 'cliente_geo_lat',\n",
    "    'geo_lng': 'cliente_geo_lng'\n",
    "})\n",
    "\n",
    "# Realizar merges\n",
    "df_m = pd.merge(df_m, df_produtos_com_chaves.drop_duplicates(subset=cols_produtos), on=cols_produtos, how='left')\n",
    "df_m = pd.merge(df_m, df_vendedores_com_chaves.drop_duplicates(subset=cols_vendedores), on=cols_vendedores, how='left')\n",
    "df_m = pd.merge(df_m, df_data_com_chaves.drop_duplicates(subset=['data_completa']), on='data_completa', how='left')\n",
    "\n",
    "# Preparar colunas de pedidos para merge (sem tempo_entrega_dias e flag_atraso que são calculados)\n",
    "cols_pedidos_merge = [c for c in cols_pedidos if c not in ['tempo_entrega_dias', 'flag_atraso']]\n",
    "cols_pedidos_merge.extend(['tempo_entrega_dias', 'flag_atraso'])\n",
    "df_m = pd.merge(df_m, df_pedidos_com_chaves.drop_duplicates(subset=cols_pedidos_merge), on=cols_pedidos_merge, how='left')\n",
    "\n",
    "# Preencher chaves ausentes com valores \"unknown\"\n",
    "df_m['SRK_prod'] = df_m['SRK_prod'].fillna(unknown_prod_key).astype(int)\n",
    "df_m['SRK_vend'] = df_m['SRK_vend'].fillna(unknown_vend_key).astype(int)\n",
    "df_m['SRK_data'] = df_m['SRK_data'].fillna(unknown_data_key).astype(int)\n",
    "df_m['SRK_ord'] = df_m['SRK_ord'].fillna(unknown_ord_key).astype(int)\n",
    "\n",
    "# Selecionar colunas para tabela fato\n",
    "cols_fato = ['SRK_prod', 'SRK_vend', 'SRK_data', 'SRK_ord', 'shipping_limit_date', 'price', 'freight_value']\n",
    "df_fato = df_m[cols_fato].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ed376-b013-4065-987b-31b167d52101",
   "metadata": {},
   "source": [
    "Esta célula realiza a carga final da tabela fato FATO_ITENS_PEDIDO no schema DW.\n",
    "Ela insere todos os registros do DataFrame df_fato, já com as chaves substitutas das dimensões, consolidando os dados no modelo estrela do Data Warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e63588-ec46-4156-b6bc-f0796f11da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.FATO_ITENS_PEDIDO (\n",
    "                \"SRK_prod\", \"SRK_vend\", \"SRK_data_pedido\", \"SRK_ord\",\n",
    "                ship_limit_date, price, freight_value\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "\n",
    "        cols = ['SRK_prod', 'SRK_vend', 'SRK_data', 'SRK_ord', 'shipping_limit_date', 'price', 'freight_value']\n",
    "\n",
    "        def _to_db(v):\n",
    "            if v is None:\n",
    "                return None\n",
    "            if isinstance(v, float) and math.isnan(v):\n",
    "                return None\n",
    "            if pd.isna(v):\n",
    "                return None\n",
    "            return v\n",
    "\n",
    "        rows = [\n",
    "            tuple(_to_db(v) for v in row)\n",
    "            for row in df_fato[cols].itertuples(index=False, name=None)\n",
    "        ]\n",
    "\n",
    "        cur.executemany(insert_query, rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c9211-b86a-425b-a6ae-f8026af7a075",
   "metadata": {},
   "source": [
    "Esta célula consulta diretamente o banco de dados para verificar a quantidade de registros inseridos em cada tabela.\n",
    "Ela exibe o total de linhas carregadas nas dimensões e na tabela fato, funcionando como uma checagem final para confirmar que a etapa de carga foi concluída com sucesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f83e35-d9c0-4669-bacc-2275f9aae57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_PRODUTOS'); dim_produtos_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_VENDEDORES'); dim_vendedores_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_PEDIDOS'); dim_pedidos_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_DATA'); dim_data_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.FATO_ITENS_PEDIDO'); fato_count = cur.fetchone()[0]\n",
    "\n",
    "print(f\"Registros carregados no banco:\")\n",
    "print(f\"DIM_PRODUTOS: {dim_produtos_count}\")\n",
    "print(f\"DIM_VENDEDORES: {dim_vendedores_count}\")\n",
    "print(f\"DIM_PEDIDOS: {dim_pedidos_count}\")\n",
    "print(f\"DIM_DATA: {dim_data_count}\")\n",
    "print(f\"FATO_ITENS_PEDIDO: {fato_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
