{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0068f9d-075f-4d32-83c5-7c5247a97fc8",
   "metadata": {},
   "source": [
    "# ETL da camada Silver para camada Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "13090515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (3.2.13)\n",
      "Requirement already satisfied: sqlalchemy in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (2.0.44)\n",
      "Requirement already satisfied: pandas in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: dotenv in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (from psycopg) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (from sqlalchemy) (3.2.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dotenv in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (from dotenv) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ananorberto/Documents/UnB/bancos2/brazilian_e-commerce_analysis/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg sqlalchemy pandas dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84fa58a-b1d2-4d12-9c09-1f8c9b355d71",
   "metadata": {},
   "source": [
    "Esta c√©lula importa todas as bibliotecas necess√°rias para o processo de ETL.\n",
    "Aqui s√£o carregados os pacotes para manipula√ß√£o de dados (pandas), conex√£o com o banco de dados PostgreSQL (psycopg), controle de mensagens de erro (sys) e tratamento de avisos (warnings).\n",
    "Ela deve ser executada antes de qualquer outra c√©lula, pois fornece as depend√™ncias b√°sicas que ser√£o usadas nas etapas de Extract, Transform e Load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "66405d39-8834-4564-ac01-6b3c5bd2f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg\n",
    "from psycopg import connect, sql\n",
    "from psycopg2 import connect, sql\n",
    "import psycopg2\n",
    "import sys\n",
    "import warnings\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e503bd-17a3-45c6-b2de-9a026da11452",
   "metadata": {},
   "source": [
    "# 1. Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3aefa-7bba-4405-aa2e-b14d4631758a",
   "metadata": {},
   "source": [
    "Esta c√©lula define as configura√ß√µes de conex√£o com o banco de dados PostgreSQL e monta a consulta SQL que ser√° usada para extrair os dados.\n",
    "Ela cria vari√°veis com credenciais, monta o nome completo da tabela (schema.tabela) e gera a query SELECT * FROM DL.ORDER_ITEMS, al√©m de preparar a connection string usada na etapa de conex√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f0a8653a-eda5-41c7-b1d5-54284054ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SCHEMA = 'DL'\n",
    "TABLE_NAME = 'ORDER_ITEMS'\n",
    "\n",
    "TABLE_FULL_NAME = sql.SQL(\"{}.{}\").format(\n",
    "    sql.Identifier(DB_SCHEMA),\n",
    "    sql.Identifier(TABLE_NAME)\n",
    ")\n",
    "\n",
    "def get_db_connection_info():\n",
    "    load_dotenv()\n",
    "    url = os.getenv('DB_URL')\n",
    "    db_env = os.getenv('DB_ENV')\n",
    "    if url is not None and db_env == 'prod':\n",
    "        return url\n",
    "\n",
    "    # credenciais do banco de dados local\n",
    "    DB_USER = \"postgres\"\n",
    "    DB_PASSWORD = \"postgres\"\n",
    "    DB_HOST = \"localhost\"\n",
    "    DB_PORT = \"5433\"\n",
    "    DB_NAME = \"olist\"\n",
    "\n",
    "    return f\"host={DB_HOST} dbname={DB_NAME} user={DB_USER} password={DB_PASSWORD} port={DB_PORT}\"\n",
    "\n",
    "\n",
    "query_object = sql.SQL(\"SELECT * FROM {}\").format(TABLE_FULL_NAME)\n",
    "\n",
    "connection_string = get_db_connection_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4bf8a8-93a2-4963-b547-e495b3c3d63f",
   "metadata": {},
   "source": [
    "Esta c√©lula executa a extra√ß√£o dos dados do banco PostgreSQL.\n",
    "Ela estabelece a conex√£o usando as configura√ß√µes definidas anteriormente, converte o objeto SQL em uma query leg√≠vel, executa a consulta e carrega o resultado no DataFrame df.\n",
    "Em caso de falha na conex√£o ou na leitura, exibe uma mensagem de erro detalhada e encerra o processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4f02bc47-95a8-43ce-b090-fdd3ea9022e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estabelecendo conex√£o...\n",
      "Conex√£o estabelecida.\n",
      "Executando query: SELECT * FROM \"DL\".\"ORDER_ITEMS\"\n",
      "\n",
      "Dados carregados do banco para o DataFrame com sucesso!\n"
     ]
    }
   ],
   "source": [
    "DB_SCHEMA = 'DL'          \n",
    "TABLE_NAME = 'ORDER_ITEMS' \n",
    "\n",
    "def get_db_connection_info():\n",
    "    load_dotenv()\n",
    "    url = os.getenv('DB_URL')\n",
    "    db_env = os.getenv('DB_ENV')\n",
    "    if url is not None and db_env == 'prod':\n",
    "        return url\n",
    "\n",
    "    # credenciais do banco de dados local\n",
    "    DB_USER = \"postgres\"\n",
    "    DB_PASSWORD = \"postgres\"\n",
    "    DB_HOST = \"localhost\"\n",
    "    DB_PORT = \"5433\"\n",
    "    DB_NAME = \"olist\"\n",
    "\n",
    "    return f\"host={DB_HOST} dbname={DB_NAME} user={DB_USER} password={DB_PASSWORD} port={DB_PORT}\"\n",
    "\n",
    "\n",
    "connection_string = get_db_connection_info()\n",
    "\n",
    "# Aqui montamos a query com schema + tabela de forma segura\n",
    "query_object = sql.SQL(\"SELECT * FROM {}.{}\").format(\n",
    "    sql.Identifier(DB_SCHEMA),\n",
    "    sql.Identifier(TABLE_NAME)\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"Estabelecendo conex√£o...\")\n",
    "    with connect(connection_string) as conn:\n",
    "        print(\"Conex√£o estabelecida.\")\n",
    "\n",
    "        # Gera a string SQL final a partir do objeto seguro\n",
    "        query_string = query_object.as_string(conn)\n",
    "        print(f\"Executando query: {query_string}\")\n",
    "\n",
    "        # L√™ o resultado direto em um DataFrame\n",
    "        df = pd.read_sql_query(query_string, conn)\n",
    "\n",
    "    print(\"\\nDados carregados do banco para o DataFrame com sucesso!\")\n",
    "except psycopg2.errors.UndefinedTable as e:\n",
    "    print(\"\\n--- A tabela informada n√£o existe no banco de dados ---\")\n",
    "    print(f\"Tente conferir o schema e o nome da tabela: {DB_SCHEMA}.{TABLE_NAME}\")\n",
    "    print(f\"Erro detalhado: {e}\")\n",
    "    sys.exit(1)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"\\n--- Ocorreu um erro ao conectar ou ler o banco de dados ---\")\n",
    "    print(f\"Erro: {e}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(\"\\n--- Ocorreu um erro inesperado ---\")\n",
    "    print(f\"Erro: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b39988-5b56-428b-8f25-8700408cca2e",
   "metadata": {},
   "source": [
    "Estas c√©lulas exibem um resumo simples do resultado da extra√ß√£o, mostrando o n√∫mero total de registros carregados no DataFrame df, as primeiras tr√™s tuplas e os tipos de cada dado.\n",
    "Elas servem para confirmar visualmente que a consulta foi executada com sucesso e quantas linhas foram retornadas do banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3d0918d7-0264-45a2-8fda-3eba9add9c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas carregadas: 112952\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total de linhas carregadas: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69a419cc-1c0d-4af9-9bf9-80426bfd8f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>shipping_limit_date</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>...</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>cliente_geolocation_lat</th>\n",
       "      <th>cliente_geolocation_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>2017-09-19 09:45:35</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>58.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-09-19 18:34:16</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>2017-09-22 10:57:03</td>\n",
       "      <td>28013</td>\n",
       "      <td>campos dos goytacazes</td>\n",
       "      <td>RJ</td>\n",
       "      <td>-21.758076</td>\n",
       "      <td>-41.312633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
       "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
       "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
       "      <td>2017-05-03 11:05:13</td>\n",
       "      <td>239.9</td>\n",
       "      <td>19.93</td>\n",
       "      <td>pet_shop</td>\n",
       "      <td>56.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-05-04 14:35:00</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>2017-05-15 11:34:13</td>\n",
       "      <td>15775</td>\n",
       "      <td>santa fe do sul</td>\n",
       "      <td>SP</td>\n",
       "      <td>-20.212393</td>\n",
       "      <td>-50.941471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
       "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
       "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
       "      <td>2018-01-18 14:48:30</td>\n",
       "      <td>199.0</td>\n",
       "      <td>17.87</td>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>59.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-16 12:36:48</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>2018-01-23 16:06:31</td>\n",
       "      <td>35661</td>\n",
       "      <td>para de minas</td>\n",
       "      <td>MG</td>\n",
       "      <td>-19.860439</td>\n",
       "      <td>-44.597972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_item_id                        product_id  \\\n",
       "0             1  4244733e06e7ecb4970a6e2683c13e61   \n",
       "1             1  e5f2d52b802189ee658865ca93d83a8f   \n",
       "2             1  c777355d18b72b67abbeef9df44fd0fd   \n",
       "\n",
       "                          seller_id                          order_id  \\\n",
       "0  48436dade18ac8b2bce089ec2a041202  00010242fe8c5a6d1ba2dd792cb16214   \n",
       "1  dd7ddc04e1b6c2c614352b383efe2d36  00018f77f2f0320c557190d7a144bdd3   \n",
       "2  5b51032eddd242adc84c38acab88f23d  000229ec398224ef6ca0657da4fc703e   \n",
       "\n",
       "  shipping_limit_date  price  freight_value product_category_name  \\\n",
       "0 2017-09-19 09:45:35   58.9          13.29            cool_stuff   \n",
       "1 2017-05-03 11:05:13  239.9          19.93              pet_shop   \n",
       "2 2018-01-18 14:48:30  199.0          17.87      moveis_decoracao   \n",
       "\n",
       "   product_name_lenght  product_description_lenght  ...  \\\n",
       "0                 58.0                       598.0  ...   \n",
       "1                 56.0                       239.0  ...   \n",
       "2                 59.0                       695.0  ...   \n",
       "\n",
       "   order_delivered_carrier_date  order_estimated_delivery_date  review_score  \\\n",
       "0           2017-09-19 18:34:16                     2017-09-29           5.0   \n",
       "1           2017-05-04 14:35:00                     2017-05-15           4.0   \n",
       "2           2018-01-16 12:36:48                     2018-02-05           5.0   \n",
       "\n",
       "   review_creation_date  review_answer_timestamp  customer_zip_code_prefix  \\\n",
       "0            2017-09-21      2017-09-22 10:57:03                     28013   \n",
       "1            2017-05-13      2017-05-15 11:34:13                     15775   \n",
       "2            2018-01-23      2018-01-23 16:06:31                     35661   \n",
       "\n",
       "           customer_city customer_state  cliente_geolocation_lat  \\\n",
       "0  campos dos goytacazes             RJ               -21.758076   \n",
       "1        santa fe do sul             SP               -20.212393   \n",
       "2          para de minas             MG               -19.860439   \n",
       "\n",
       "   cliente_geolocation_lng  \n",
       "0               -41.312633  \n",
       "1               -50.941471  \n",
       "2               -44.597972  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8b5c3e8f-9a2b-4c5d-8e3f-9b4c5d6e7f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112952 entries, 0 to 112951\n",
      "Data columns (total 41 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_item_id                  112952 non-null  object        \n",
      " 1   product_id                     112952 non-null  object        \n",
      " 2   seller_id                      112952 non-null  object        \n",
      " 3   order_id                       112952 non-null  object        \n",
      " 4   shipping_limit_date            112952 non-null  datetime64[ns]\n",
      " 5   price                          112952 non-null  float64       \n",
      " 6   freight_value                  112952 non-null  float64       \n",
      " 7   product_category_name          111342 non-null  object        \n",
      " 8   product_name_lenght            111342 non-null  float64       \n",
      " 9   product_description_lenght     111342 non-null  float64       \n",
      " 10  product_photos_qty             111342 non-null  float64       \n",
      " 11  product_weight_g               112934 non-null  float64       \n",
      " 12  product_length_cm              112934 non-null  float64       \n",
      " 13  product_height_cm              112934 non-null  float64       \n",
      " 14  product_width_cm               112934 non-null  float64       \n",
      " 15  seller_zip_code_prefix         112952 non-null  int64         \n",
      " 16  seller_city                    112952 non-null  object        \n",
      " 17  seller_state                   112952 non-null  object        \n",
      " 18  vendedor_geolocation_lat       112697 non-null  float64       \n",
      " 19  vendedor_geolocation_lng       112697 non-null  float64       \n",
      " 20  review_comment_title           13391 non-null   object        \n",
      " 21  review_comment_message         47292 non-null   object        \n",
      " 22  customer_unique_id             112952 non-null  object        \n",
      " 23  order_status                   112952 non-null  object        \n",
      " 24  qtd_payment_sequential         112949 non-null  float64       \n",
      " 25  primeiro_payment_type          112949 non-null  object        \n",
      " 26  valor_total_pagamento          112949 non-null  float64       \n",
      " 27  maximo_payment_installments    112949 non-null  float64       \n",
      " 28  order_purchase_timestamp       112952 non-null  datetime64[ns]\n",
      " 29  order_delivered_customer_date  110492 non-null  datetime64[ns]\n",
      " 30  order_approved_at              112937 non-null  datetime64[ns]\n",
      " 31  order_delivered_carrier_date   111757 non-null  datetime64[ns]\n",
      " 32  order_estimated_delivery_date  112952 non-null  datetime64[ns]\n",
      " 33  review_score                   111461 non-null  float64       \n",
      " 34  review_creation_date           111461 non-null  datetime64[ns]\n",
      " 35  review_answer_timestamp        111461 non-null  datetime64[ns]\n",
      " 36  customer_zip_code_prefix       112952 non-null  int64         \n",
      " 37  customer_city                  112952 non-null  object        \n",
      " 38  customer_state                 112952 non-null  object        \n",
      " 39  cliente_geolocation_lat        112648 non-null  float64       \n",
      " 40  cliente_geolocation_lng        112648 non-null  float64       \n",
      "dtypes: datetime64[ns](8), float64(17), int64(2), object(14)\n",
      "memory usage: 35.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4d5e6-7f8a-9b0c-1d2e-3f4a5b6c7d8e",
   "metadata": {},
   "source": [
    "# 2. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8-9a0b-1c2d-3e4f-5a6b7c8d9e0f",
   "metadata": {},
   "source": [
    "Esta c√©lula define as colunas que far√£o parte de cada dimens√£o no modelo estrela.\n",
    "Cada lista de colunas corresponde aos atributos que ser√£o extra√≠dos do DataFrame principal para formar as tabelas dimensionais DIM_PRODUTOS, DIM_VENDEDORES, DIM_PEDIDOS e a dimens√£o temporal DIM_DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas para DIM_PRD\n",
    "cols_produtos = [\n",
    "    'product_category_name',\n",
    "    'product_name_lenght',\n",
    "    'product_description_lenght',\n",
    "    'product_photos_qty',\n",
    "    'product_weight_g',\n",
    "    'product_length_cm',\n",
    "    'product_height_cm',\n",
    "    'product_width_cm'\n",
    "]\n",
    "\n",
    "# Colunas para DIM_VND\n",
    "cols_vendedores = [\n",
    "    'seller_zip_code_prefix',\n",
    "    'seller_city',\n",
    "    'seller_state',\n",
    "    'vendedor_geolocation_lat',\n",
    "    'vendedor_geolocation_lng'\n",
    "]\n",
    "\n",
    "# Colunas para DIM_ORD\n",
    "cols_pedidos = [\n",
    "    'rev_com_tit',\n",
    "    'rev_com_msn',\n",
    "    'cli_unq_id',\n",
    "    'ord_stt',\n",
    "    'qtd_pay_seq',\n",
    "    'pri_pay_typ',\n",
    "    'val_tot_pay',\n",
    "    'max_pay_prc',\n",
    "    'ord_pcs_ttp',\n",
    "    'ord_env_cli_dat',\n",
    "    'ord_apd_dat',\n",
    "    'ord_env_pst_dat',\n",
    "    'ord_est_env_dat',\n",
    "    'rev_sco',\n",
    "    'rev_cre_dat',\n",
    "    'rev_ans_ttp',\n",
    "    'cli_zip_cod_prf',\n",
    "    'cli_cit',\n",
    "    'cli_sta',\n",
    "    'cliente_geolocation_lat',\n",
    "    'cliente_geolocation_lng'\n",
    "]\n",
    "\n",
    "# Coluna para DIM_DAT (ser√° extra√≠da de ord_pcs_ttp)\n",
    "col_data = 'ord_pcs_ttp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8f9a0-b1c2-3d4e-5f6a-7b8c9d0e1f2a",
   "metadata": {},
   "source": [
    "Esta c√©lula renomeia as colunas do DataFrame para corresponder √† nomenclatura da camada Gold.\n",
    "Os nomes s√£o padronizados com prefixos mnem√¥nicos (prod_, vend_, geo_) conforme definido no dicion√°rio de dados da camada Gold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e9f0a1b2-c3d4-5e6f-7a8b-9c0d1e2f3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear colunas para nomenclatura Gold\n",
    "df = df.rename(columns={\n",
    "    # Produtos\n",
    "    'product_category_name': 'prd_cat_nam',\n",
    "    'product_name_lenght': 'prd_nam_lgt',\n",
    "    'product_description_lenght': 'prd_dsc_lgt',\n",
    "    'product_photos_qty': 'prd_pic_qty',\n",
    "    'product_weight_g': 'prd_wei_g',\n",
    "    'product_length_cm': 'prd_lgt_cm',\n",
    "    'product_height_cm': 'prd_hei_cm',\n",
    "    'product_width_cm': 'prd_wid_cm',\n",
    "    # Vendedores\n",
    "    'seller_zip_code_prefix': 'vnd_zip_cod_prf',\n",
    "    'seller_city': 'vnd_cit',\n",
    "    'seller_state': 'vnd_sta',\n",
    "    'vendedor_geolocation_lat': 'geo_lat',\n",
    "    'vendedor_geolocation_lng': 'geo_lng',\n",
    "    # Cliente (geolocaliza√ß√£o)\n",
    "    'cliente_geolocation_lat': 'cliente_geo_lat',\n",
    "    'cliente_geolocation_lng': 'cliente_geo_lng',\n",
    "    # Pedidos / Orders\n",
    "    'order_purchase_timestamp': 'ord_pcs_ttp',\n",
    "    'order_delivered_customer_date': 'ord_env_cli_dat',\n",
    "    'order_approved_at': 'ord_apd_dat',\n",
    "    'order_delivered_carrier_date': 'ord_env_pst_dat',\n",
    "    'order_estimated_delivery_date': 'ord_est_env_dat',\n",
    "    'review_comment_title': 'rev_com_tit',\n",
    "    'review_comment_message': 'rev_com_msn',\n",
    "    'customer_unique_id': 'cli_unq_id',\n",
    "    'order_status': 'ord_stt',\n",
    "    'qtd_payment_sequential': 'qtd_pay_seq',\n",
    "    'primeiro_payment_type': 'pri_pay_typ',\n",
    "    'valor_total_pagamento': 'val_tot_pay',\n",
    "    'maximo_payment_installments': 'max_pay_prc',\n",
    "    'review_score': 'rev_sco',\n",
    "    'review_creation_date': 'rev_cre_dat',\n",
    "    'review_answer_timestamp': 'rev_ans_ttp',\n",
    "    'customer_zip_code_prefix': 'cli_zip_cod_prf',\n",
    "    'customer_city': 'cli_cit',\n",
    "    'customer_state': 'cli_sta',\n",
    "    # Fato\n",
    "    'shipping_limit_date': 'env_lmt_dat',\n",
    "    'price': 'val',\n",
    "    'freight_value': 'frt_val',\n",
    "})\n",
    "\n",
    "# Atualizar listas de colunas com novos nomes\n",
    "cols_produtos = [\n",
    "    'prd_cat_nam',\n",
    "    'prd_nam_lgt',\n",
    "    'prd_dsc_lgt',\n",
    "    'prd_pic_qty',\n",
    "    'prd_wei_g',\n",
    "    'prd_lgt_cm',\n",
    "    'prd_hei_cm',\n",
    "    'prd_wid_cm'\n",
    "]\n",
    "\n",
    "cols_vendedores = [\n",
    "    'vnd_zip_cod_prf',\n",
    "    'vnd_cit',\n",
    "    'vnd_sta',\n",
    "    'geo_lat',\n",
    "    'geo_lng',\n",
    "]\n",
    "\n",
    "cols_pedidos = [\n",
    "    'rev_com_tit',\n",
    "    'rev_com_msn',\n",
    "    'cli_unq_id',\n",
    "    'ord_stt',\n",
    "    'qtd_pay_seq',\n",
    "    'pri_pay_typ',\n",
    "    'val_tot_pay',\n",
    "    'max_pay_prc',\n",
    "    'ord_pcs_ttp',\n",
    "    'ord_env_cli_dat',\n",
    "    'ord_apd_dat',\n",
    "    'ord_env_pst_dat',\n",
    "    'ord_est_env_dat',\n",
    "    'rev_sco',\n",
    "    'rev_cre_dat',\n",
    "    'rev_ans_ttp',\n",
    "    'cli_zip_cod_prf',\n",
    "    'cli_cit',\n",
    "    'cli_sta',\n",
    "    'cliente_geo_lat',\n",
    "    'cliente_geo_lng'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2b3c4-d5e6-7f8a-9b0c-1d2e3f4a5b6c",
   "metadata": {},
   "source": [
    "Esta c√©lula cria campos calculados para a dimens√£o DIM_PEDIDOS.\n",
    "Calcula o tempo de entrega em dias (tempo_entrega_dias) e a flag de atraso (flag_atraso) comparando a data de entrega real com a data estimada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a5b6c7d8-e9f0-1a2b-3c4d-5e6f7a8b9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter colunas de timestamp para datetime\n",
    "df['ord_pcs_ttp'] = pd.to_datetime(df['ord_pcs_ttp'])\n",
    "df['ord_env_cli_dat'] = pd.to_datetime(df['ord_env_cli_dat'])\n",
    "df['ord_est_env_dat'] = pd.to_datetime(df['ord_est_env_dat'])\n",
    "\n",
    "# Calcular tempo de entrega em dias\n",
    "df['tem_de_env_dia'] = (df['ord_env_cli_dat'] - df['ord_pcs_ttp']).dt.days\n",
    "\n",
    "# Calcular flag de atraso (1 se atrasou, 0 se n√£o)\n",
    "df['flg_atr'] = ((df['ord_env_cli_dat'] > df['ord_est_env_dat']).astype(int))\n",
    "\n",
    "# Adicionar campos calculados √† lista de colunas de pedidos\n",
    "cols_pedidos.extend(['tem_de_env_dia', 'flg_atr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7d8e9-f0a1-2b3c-4d5e-6f7a8b9c0d1e",
   "metadata": {},
   "source": [
    "Esta c√©lula cria a dimens√£o temporal DIM_DATA extraindo datas √∫nicas do campo order_purchase_timestamp.\n",
    "Para cada data √∫nica, extrai ano, m√™s, dia e dia da semana em portugu√™s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c7d8e9f0-a1b2-3c4d-5e6f-7a8b9c0d1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair datas √∫nicas\n",
    "df_data = df[[col_data]].copy()\n",
    "df_data['dat_cmp'] = df_data[col_data].dt.date\n",
    "df_data = df_data[['dat_cmp']].drop_duplicates().copy()\n",
    "\n",
    "# Converter para datetime para extrair componentes\n",
    "df_data['dat_cmp'] = pd.to_datetime(df_data['dat_cmp'])\n",
    "\n",
    "# Extrair componentes da data\n",
    "df_data['ano'] = df_data['dat_cmp'].dt.year\n",
    "df_data['mes'] = df_data['dat_cmp'].dt.month\n",
    "df_data['dia'] = df_data['dat_cmp'].dt.day\n",
    "\n",
    "# Mapear dia da semana para portugu√™s\n",
    "dias_semana_pt = {\n",
    "    0: 'Segunda',\n",
    "    1: 'Ter√ßa',\n",
    "    2: 'Quarta',\n",
    "    3: 'Quinta',\n",
    "    4: 'Sexta',\n",
    "    5: 'S√°bado',\n",
    "    6: 'Domingo'\n",
    "}\n",
    "df_data['dia_da_sem'] = df_data['dat_cmp'].dt.dayofweek.map(dias_semana_pt)\n",
    "\n",
    "# Converter dat_cmp de volta para date\n",
    "df_data['dat_cmp'] = df_data['dat_cmp'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9f0a1-b2c3-4d5e-6f7a-8b9c0d1e2f3a",
   "metadata": {},
   "source": [
    "Esta c√©lula cria DataFrames separados para cada dimens√£o, removendo duplicatas.\n",
    "Cada DataFrame conter√° apenas as colunas relevantes para sua respectiva dimens√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e9f0a1b2-c3d4-5e6f-7a8b-9c0d1e2f3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_produtos = df[cols_produtos].drop_duplicates().copy()\n",
    "df_vendedores = df[cols_vendedores].drop_duplicates().copy()\n",
    "df_pedidos = df[cols_pedidos].drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1b2c3-d4e5-6f7a-8b9c-0d1e2f3a4b5c",
   "metadata": {},
   "source": [
    "Esta c√©lula realiza a padroniza√ß√£o e limpeza dos campos num√©ricos do DataFrame.\n",
    "Ela converte todas as colunas de m√©tricas para tipo num√©rico, substitui valores infinitos por NaN e depois transforma todos os NaN e valores ausentes em None, garantindo que o banco de dados receba NULL corretamente durante a carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "67a2bcf6-20ed-4ec9-b1f3-a09711204c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['val', 'frt_val', 'tem_de_env_dia']\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.where(pd.notna(df), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d",
   "metadata": {},
   "source": [
    "Esta c√©lula exibe um resumo da etapa de transforma√ß√£o, mostrando quantos registros foram preparados em cada dimens√£o e na tabela fato base.\n",
    "Em seguida, utiliza df.info() para apresentar a estrutura geral do DataFrame principal, permitindo verificar tipos de dados e poss√≠veis valores nulos antes da carga no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a7954d14-5c17-4dd2-bb28-96b35fea050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros preparados para carga:\n",
      "DIM_PRD: 32256\n",
      "DIM_VND: 2296\n",
      "DIM_ORD: 98909\n",
      "DIM_DAT: 616\n",
      "FAT_ITS_ORD (base df): 112952\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112952 entries, 0 to 112951\n",
      "Data columns (total 43 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   order_item_id    112952 non-null  object        \n",
      " 1   product_id       112952 non-null  object        \n",
      " 2   seller_id        112952 non-null  object        \n",
      " 3   order_id         112952 non-null  object        \n",
      " 4   env_lmt_dat      112952 non-null  datetime64[ns]\n",
      " 5   val              112952 non-null  float64       \n",
      " 6   frt_val          112952 non-null  float64       \n",
      " 7   prd_cat_nam      111342 non-null  object        \n",
      " 8   prd_nam_lgt      111342 non-null  float64       \n",
      " 9   prd_dsc_lgt      111342 non-null  float64       \n",
      " 10  prd_pic_qty      111342 non-null  float64       \n",
      " 11  prd_wei_g        112934 non-null  float64       \n",
      " 12  prd_lgt_cm       112934 non-null  float64       \n",
      " 13  prd_hei_cm       112934 non-null  float64       \n",
      " 14  prd_wid_cm       112934 non-null  float64       \n",
      " 15  vnd_zip_cod_prf  112952 non-null  int64         \n",
      " 16  vnd_cit          112952 non-null  object        \n",
      " 17  vnd_sta          112952 non-null  object        \n",
      " 18  geo_lat          112697 non-null  float64       \n",
      " 19  geo_lng          112697 non-null  float64       \n",
      " 20  rev_com_tit      13391 non-null   object        \n",
      " 21  rev_com_msn      47292 non-null   object        \n",
      " 22  cli_unq_id       112952 non-null  object        \n",
      " 23  ord_stt          112952 non-null  object        \n",
      " 24  qtd_pay_seq      112949 non-null  float64       \n",
      " 25  pri_pay_typ      112949 non-null  object        \n",
      " 26  val_tot_pay      112949 non-null  float64       \n",
      " 27  max_pay_prc      112949 non-null  float64       \n",
      " 28  ord_pcs_ttp      112952 non-null  datetime64[ns]\n",
      " 29  ord_env_cli_dat  110492 non-null  datetime64[ns]\n",
      " 30  ord_apd_dat      112937 non-null  datetime64[ns]\n",
      " 31  ord_env_pst_dat  111757 non-null  datetime64[ns]\n",
      " 32  ord_est_env_dat  112952 non-null  datetime64[ns]\n",
      " 33  rev_sco          111461 non-null  float64       \n",
      " 34  rev_cre_dat      111461 non-null  datetime64[ns]\n",
      " 35  rev_ans_ttp      111461 non-null  datetime64[ns]\n",
      " 36  cli_zip_cod_prf  112952 non-null  int64         \n",
      " 37  cli_cit          112952 non-null  object        \n",
      " 38  cli_sta          112952 non-null  object        \n",
      " 39  cliente_geo_lat  112648 non-null  float64       \n",
      " 40  cliente_geo_lng  112648 non-null  float64       \n",
      " 41  tem_de_env_dia   110492 non-null  float64       \n",
      " 42  flg_atr          112952 non-null  int64         \n",
      "dtypes: datetime64[ns](8), float64(18), int64(3), object(14)\n",
      "memory usage: 37.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Registros preparados para carga:\")\n",
    "print(f\"DIM_PRD: {len(df_produtos)}\")\n",
    "print(f\"DIM_VND: {len(df_vendedores)}\")\n",
    "print(f\"DIM_ORD: {len(df_pedidos)}\")\n",
    "print(f\"DIM_DAT: {len(df_data)}\")\n",
    "print(f\"FAT_ITS_ORD (base df): {len(df)}\\n\\n\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe0394e-0dc6-471f-a7b9-2965b2498912",
   "metadata": {},
   "source": [
    "# 3. Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716cf2d4-5418-48ee-835f-a68e36f5fefb",
   "metadata": {},
   "source": [
    "Esta c√©lula configura os par√¢metros de conex√£o com o banco de dados do Data Warehouse (DW) e valida se todas as vari√°veis geradas na etapa de transforma√ß√£o est√£o dispon√≠veis na mem√≥ria.\n",
    "Ela garante que o ambiente esteja pronto antes de iniciar a fase de carga, evitando erros por falta de dados ou vari√°veis necess√°rias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9e779b8d-dd04-439b-bea3-7c2418ebe77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SCHEMA_GOLD = \"DW\"\n",
    "\n",
    "connection_string = get_db_connection_info()\n",
    "\n",
    "for v in ['df', 'df_produtos', 'df_vendedores', 'df_pedidos', 'df_data', 'cols_produtos', 'cols_vendedores', 'cols_pedidos', 'col_data']:\n",
    "    if v not in globals():\n",
    "        raise RuntimeError(f\"Vari√°vel ausente: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915271d-7a91-447e-a7e1-182c4a09a312",
   "metadata": {},
   "source": [
    "Esta c√©lula executa o script DDL respons√°vel por criar ou recriar as tabelas do schema DW no banco de dados.\n",
    "Ela l√™ o arquivo SQL que cont√©m a defini√ß√£o das tabelas e executa o comando dentro de uma conex√£o com o PostgreSQL, preparando a estrutura necess√°ria para receber os dados na etapa de carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5bb09603-ab9b-47f6-9d8f-305a95b82ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ddl_gold = open('../data_layer/gold/DDL.sql').read()\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivo 'DDL.sql' n√£o encontrado em '../data_layer/gold/DDL.sql'.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(ddl_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9c803bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Investigando schemas DL e dl...\n",
      "‚ö†Ô∏è  ATEN√á√ÉO: Encontrados m√∫ltiplos schemas similares:\n",
      "schema_name  num_tables\n",
      "         DL           1\n",
      "         dl           1\n",
      "\n",
      "üí° Dica: PostgreSQL diferencia mai√∫sculas/min√∫sculas quando o nome est√° entre aspas.\n",
      "   Considere consolidar em um √∫nico schema (preferencialmente 'DL').\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar schemas DL e dl (investiga√ß√£o do problema)\n",
    "print(\"üîç Investigando schemas DL e dl...\")\n",
    "with connect(connection_string) as conn:\n",
    "    df_schemas = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            schema_name,\n",
    "            COUNT(*) as num_tables\n",
    "        FROM information_schema.schemata\n",
    "        WHERE schema_name IN ('DL', 'dl')\n",
    "        GROUP BY schema_name\n",
    "        ORDER BY schema_name;\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    if len(df_schemas) > 0:\n",
    "        print(\"‚ö†Ô∏è  ATEN√á√ÉO: Encontrados m√∫ltiplos schemas similares:\")\n",
    "        print(df_schemas.to_string(index=False))\n",
    "        print(\"\\nüí° Dica: PostgreSQL diferencia mai√∫sculas/min√∫sculas quando o nome est√° entre aspas.\")\n",
    "        print(\"   Considere consolidar em um √∫nico schema (preferencialmente 'DL').\\n\")\n",
    "    else:\n",
    "        print(\"‚úì Schema DL verificado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729132b-f4dc-4008-aa6b-0c9b2c5c1447",
   "metadata": {},
   "source": [
    "Esta c√©lula realiza a carga da dimens√£o Produtos no schema DW.\n",
    "Ela insere todos os registros do DataFrame df_produtos na tabela DIM_PRODUTOS e adiciona uma linha extra com valores nulos para representar o registro 'desconhecido', armazenando sua chave substituta (unknown_prod_key) para uso posterior na carga da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f5669411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL</td>\n",
       "      <td>ORDER_ITEMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dl</td>\n",
       "      <td>order_items</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dw</td>\n",
       "      <td>dim_dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dw</td>\n",
       "      <td>dim_ord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dw</td>\n",
       "      <td>dim_prd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dw</td>\n",
       "      <td>dim_vnd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dw</td>\n",
       "      <td>fat_its_ord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>public</td>\n",
       "      <td>DIMDATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>public</td>\n",
       "      <td>DIMPEDIDOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>public</td>\n",
       "      <td>DIMPRODUTOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>public</td>\n",
       "      <td>DIMVENDEDORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>public</td>\n",
       "      <td>FATOITENSPEDIDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>silver</td>\n",
       "      <td>customers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>silver</td>\n",
       "      <td>geolocation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>silver</td>\n",
       "      <td>order_items</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>silver</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>silver</td>\n",
       "      <td>payments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>silver</td>\n",
       "      <td>products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>silver</td>\n",
       "      <td>reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>silver</td>\n",
       "      <td>sellers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>silver</td>\n",
       "      <td>treated_order_items</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   table_schema           table_name\n",
       "0            DL          ORDER_ITEMS\n",
       "1            dl          order_items\n",
       "2            dw              dim_dat\n",
       "3            dw              dim_ord\n",
       "4            dw              dim_prd\n",
       "5            dw              dim_vnd\n",
       "6            dw          fat_its_ord\n",
       "7        public              DIMDATA\n",
       "8        public           DIMPEDIDOS\n",
       "9        public          DIMPRODUTOS\n",
       "10       public        DIMVENDEDORES\n",
       "11       public      FATOITENSPEDIDO\n",
       "12       silver            customers\n",
       "13       silver          geolocation\n",
       "14       silver          order_items\n",
       "15       silver               orders\n",
       "16       silver             payments\n",
       "17       silver             products\n",
       "18       silver              reviews\n",
       "19       silver              sellers\n",
       "20       silver  treated_order_items"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    df_all_tables = pd.read_sql_query(\"\"\"\n",
    "        SELECT table_schema, table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema NOT IN ('pg_catalog', 'information_schema')\n",
    "        ORDER BY table_schema, table_name;\n",
    "    \"\"\", conn)\n",
    "\n",
    "df_all_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b5349745-a71a-441b-ad4a-81f4616d1500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chave surrogate do produto desconhecido: 32257\n"
     ]
    }
   ],
   "source": [
    "# Carrega dimens√£o produto no DW, incluindo linha \"desconhecido\"\n",
    "\n",
    "# Defina as colunas do banco para inser√ß√£o\n",
    "cols_produtos = [\n",
    "    \"prd_cat_nam\",\n",
    "    \"prd_nam_lgt\",\n",
    "    \"prd_dsc_lgt\",\n",
    "    \"prd_pic_qty\",\n",
    "    \"prd_wei_g\",\n",
    "    \"prd_lgt_cm\",\n",
    "    \"prd_hei_cm\",\n",
    "    \"prd_wid_cm\",\n",
    "]\n",
    "\n",
    "# Crie um DataFrame apenas com as colunas de interesse, renomeando se necess√°rio\n",
    "rename_cols = {\n",
    "    \"prod_category_name\": \"prd_cat_nam\",\n",
    "    \"prod_name_lenght\": \"prd_nam_lgt\",\n",
    "    \"prod_desc_lenght\": \"prd_dsc_lgt\",\n",
    "    \"prod_photos_qty\": \"prd_pic_qty\",\n",
    "    \"prod_weight_g\": \"prd_wei_g\",\n",
    "    \"prod_length_cm\": \"prd_lgt_cm\",\n",
    "    \"prod_height_cm\": \"prd_hei_cm\",\n",
    "    \"prod_width_cm\": \"prd_wid_cm\"\n",
    "}\n",
    "# Caso df_produtos j√° esteja com nomes internos, apenas seleciona\n",
    "if all(col in df_produtos.columns for col in cols_produtos):\n",
    "    df_ins = df_produtos[cols_produtos].copy()\n",
    "else:\n",
    "    df_ins = df_produtos.rename(columns=rename_cols)[cols_produtos].copy()\n",
    "\n",
    "# Converte para tipos num√©ricos onde precisar\n",
    "int_cols = [\"prd_nam_lgt\", \"prd_dsc_lgt\", \"prd_pic_qty\"]\n",
    "dec_cols = [\"prd_wei_g\", \"prd_lgt_cm\", \"prd_hei_cm\", \"prd_wid_cm\"]\n",
    "\n",
    "for col in int_cols:\n",
    "    df_ins[col] = pd.to_numeric(df_ins[col], errors=\"coerce\")  # N√£o num√©rico vira NaN\n",
    "\n",
    "for col in dec_cols:\n",
    "    df_ins[col] = pd.to_numeric(df_ins[col], errors=\"coerce\")\n",
    "\n",
    "# Garante None ao inv√©s de NaN para inserir no banco\n",
    "df_ins = df_ins.astype(object)\n",
    "df_ins = df_ins.where(df_ins.notna(), None)\n",
    "\n",
    "rows = list(df_ins.itertuples(index=False, name=None))\n",
    "\n",
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"\n",
    "            INSERT INTO DW.DIM_PRD (\n",
    "                prd_cat_nam, prd_nam_lgt, prd_dsc_lgt, prd_pic_qty,\n",
    "                prd_wei_g, prd_lgt_cm, prd_hei_cm, prd_wid_cm\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "        )\n",
    "        cur.executemany(insert_query, rows)\n",
    "\n",
    "        # Insere linha \"desconhecida\" explicitamente e recupera chave surrogate\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO DW.DIM_PRD (\n",
    "                prd_cat_nam, prd_nam_lgt, prd_dsc_lgt, prd_pic_qty,\n",
    "                prd_wei_g, prd_lgt_cm, prd_hei_cm, prd_wid_cm\n",
    "            ) VALUES (NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL)\n",
    "            RETURNING \"SRK_prd\";\n",
    "            \"\"\"\n",
    "        )\n",
    "        unknown_prod_key = cur.fetchone()[0]\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "print(\"Chave surrogate do produto desconhecido:\", unknown_prod_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2fe8f-08b7-435f-9f2d-66dd7bf2d532",
   "metadata": {},
   "source": [
    "Esta c√©lula insere os dados da dimens√£o Vendedores no schema DW.\n",
    "Ela carrega todos os registros do DataFrame df_vendedores na tabela DIM_VENDEDORES e adiciona um registro adicional com valores nulos para representar o vendedor 'desconhecido', salvando sua chave substituta (unknown_vend_key) para uso posterior na carga da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "594b3b18-8954-4ccc-acdd-35276dfa399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.DIM_VND (\n",
    "                vnd_zip_cod_prf, vnd_cit, vnd_sta, geo_lat, geo_lng\n",
    "            ) VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "        cur.executemany(insert_query, [tuple(x) for x in df_vendedores.to_numpy()])\n",
    "        cur.execute(\n",
    "            \"\"\"INSERT INTO DW.DIM_VND (\n",
    "                vnd_zip_cod_prf, vnd_cit, vnd_sta, geo_lat, geo_lng\n",
    "            ) VALUES (NULL, NULL, NULL, NULL, NULL) RETURNING \"SRK_vnd\" \"\"\"\n",
    "        )\n",
    "        unknown_vend_key = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d0a5c0-40da-4300-b353-037f88a46caf",
   "metadata": {},
   "source": [
    "Esta c√©lula carrega os dados da dimens√£o Data no schema DW.\n",
    "Ela insere os registros do DataFrame df_data na tabela DIM_DATA e adiciona um registro com valores nulos para representar datas desconhecidas, salvando sua chave substituta (unknown_data_key) que ser√° usada na inser√ß√£o da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "82e00be8-4979-415c-b9ec-e55851a209dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.DIM_DAT (\n",
    "                dat_cmp, ano, mes, dia, dia_da_sem\n",
    "            ) VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "        cur.executemany(insert_query, [tuple(x) for x in df_data.to_numpy()])\n",
    "        cur.execute(\n",
    "            \"\"\"INSERT INTO DW.DIM_DAT (\n",
    "                dat_cmp, ano, mes, dia, dia_da_sem\n",
    "            ) VALUES (NULL, NULL, NULL, NULL, NULL) RETURNING \"SRK_dat\" \"\"\"\n",
    "        )\n",
    "        unknown_data_key = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e2a1a-43f1-4d2a-87ba-0d95a8579030",
   "metadata": {},
   "source": [
    "Esta c√©lula realiza a carga da dimens√£o Pedidos no schema DW.\n",
    "Ela insere os registros do DataFrame df_pedidos na tabela DIM_PEDIDOS e adiciona um registro com valores nulos para representar pedidos ausentes, armazenando a chave substituta (unknown_ord_key) que ser√° utilizada posteriormente na carga da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bc718c25-dad6-4969-91f2-ab1250dab316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chave surrogate do pedido UNKNOWN: 98910\n"
     ]
    }
   ],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.DIM_ORD (\n",
    "                rev_com_tit, rev_com_msn, cli_unq_id, ord_stt,\n",
    "                qtd_pay_seq, pri_pay_typ, val_tot_pay, max_pay_prc,\n",
    "                ord_pcs_ttp, ord_env_cli_dat, tem_de_env_dia, flg_atr,\n",
    "                ord_apd_dat, ord_env_pst_dat, ord_est_env_dat,\n",
    "                rev_sco, rev_cre_dat, rev_ans_ttp,\n",
    "                cli_zip_cod_prf, cli_cit, cli_sta, geo_lat, geo_lng\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "\n",
    "        # ---------- PREPARA√á√ÉO DO DATAFRAME ----------\n",
    "        df_pedidos_load = df_pedidos.copy()\n",
    "        df_pedidos_load = df_pedidos_load.rename(columns={\n",
    "            'cliente_geo_lat': 'geo_lat',\n",
    "            'cliente_geo_lng': 'geo_lng'\n",
    "        })\n",
    "\n",
    "        cols_pedidos_load = [\n",
    "            'rev_com_tit', 'rev_com_msn', 'cli_unq_id', 'ord_stt',\n",
    "            'qtd_pay_seq', 'pri_pay_typ', 'val_tot_pay', 'max_pay_prc',\n",
    "            'ord_pcs_ttp', 'ord_env_cli_dat', 'tem_de_env_dia', 'flg_atr',\n",
    "            'ord_apd_dat', 'ord_env_pst_dat', 'ord_est_env_dat',\n",
    "            'rev_sco', 'rev_cre_dat', 'rev_ans_ttp',\n",
    "            'cli_zip_cod_prf', 'cli_cit', 'cli_sta', 'geo_lat', 'geo_lng'\n",
    "        ]\n",
    "\n",
    "        df_ins = df_pedidos_load[cols_pedidos_load].copy()\n",
    "\n",
    "        # ---------- TRATAMENTO das DATAS ----------\n",
    "        dt_cols = [\n",
    "            'ord_pcs_ttp',\n",
    "            'ord_env_cli_dat',\n",
    "            'ord_apd_dat',\n",
    "            'ord_env_pst_dat',\n",
    "            'ord_est_env_dat',\n",
    "            'rev_cre_dat',\n",
    "            'rev_ans_ttp',\n",
    "        ]\n",
    "\n",
    "        for col in dt_cols:\n",
    "            df_ins[col] = pd.to_datetime(df_ins[col], errors='coerce')\n",
    "\n",
    "        # ---------- TRATAMENTO das NUM√âRICAS ----------\n",
    "        num_cols = [\n",
    "            'qtd_pay_seq', 'val_tot_pay', 'max_pay_prc',\n",
    "            'tem_de_env_dia', 'flg_atr', 'rev_sco',\n",
    "            'cli_zip_cod_prf', 'geo_lat', 'geo_lng'\n",
    "        ]\n",
    "\n",
    "        for col in num_cols:\n",
    "            df_ins[col] = pd.to_numeric(df_ins[col], errors='coerce')\n",
    "\n",
    "        # ---------- TRATAR NaN / NaT ‚Üí None ----------\n",
    "        df_ins = df_ins.astype(object)\n",
    "        df_ins = df_ins.where(df_ins.notna(), None)\n",
    "\n",
    "        # ---------- GERAR LINHAS SEM .to_numpy ----------\n",
    "        rows = list(df_ins.itertuples(index=False, name=None))\n",
    "\n",
    "        # ---------- INSERIR TODOS ----------\n",
    "        cur.executemany(insert_query, rows)\n",
    "\n",
    "        # ---------- INSERIR UNKNOWN ----------\n",
    "        cur.execute(\n",
    "            \"\"\"INSERT INTO DW.DIM_ORD (\n",
    "                rev_com_tit, rev_com_msn, cli_unq_id, ord_stt,\n",
    "                qtd_pay_seq, pri_pay_typ, val_tot_pay, max_pay_prc,\n",
    "                ord_pcs_ttp, ord_env_cli_dat, tem_de_env_dia, flg_atr,\n",
    "                ord_apd_dat, ord_env_pst_dat, ord_est_env_dat,\n",
    "                rev_sco, rev_cre_dat, rev_ans_ttp,\n",
    "                cli_zip_cod_prf, cli_cit, cli_sta, geo_lat, geo_lng\n",
    "            ) VALUES (\n",
    "                NULL, NULL, 'UNKNOWN', 'unknown',\n",
    "                NULL, NULL, NULL, NULL,\n",
    "                '1900-01-01', NULL, NULL, NULL,\n",
    "                NULL, NULL, NULL,\n",
    "                NULL, NULL, NULL,\n",
    "                NULL, NULL, NULL, NULL, NULL\n",
    "            )\n",
    "            RETURNING \"SRK_ord\";\"\"\"\n",
    "        )\n",
    "        unknown_ord_key = cur.fetchone()[0]\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "print(\"Chave surrogate do pedido UNKNOWN:\", unknown_ord_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4bb4fa-8145-4716-aae9-8b69de2bec68",
   "metadata": {},
   "source": [
    "Esta c√©lula faz o mapeamento das chaves substitutas (SRKs) das dimens√µes para o DataFrame principal.\n",
    "Ela l√™ as tabelas dimensionais do banco, realiza os joins com o DataFrame original (df) e substitui valores ausentes pelas chaves 'desconhecidas'.\n",
    "O resultado √© o DataFrame df_fato, j√° com todas as refer√™ncias dimensionais resolvidas e pronto para ser inserido na tabela fato FATO_ITENS_PEDIDO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "112fc738-199a-445a-9531-74b6898573cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    df_produtos_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_PRD', conn)\n",
    "    df_vendedores_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_VND', conn)\n",
    "    df_pedidos_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_ORD', conn)\n",
    "    df_data_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_DAT', conn)\n",
    "\n",
    "# Preparar DataFrame para merge\n",
    "df_m = df.copy()\n",
    "\n",
    "# Preparar coluna de data para merge\n",
    "df_m['dat_cmp'] = df_m['ord_pcs_ttp'].dt.date\n",
    "df_data_com_chaves['dat_cmp'] = pd.to_datetime(df_data_com_chaves['dat_cmp']).dt.date\n",
    "\n",
    "# Renomear colunas de vendedores para merge\n",
    "# df_vendedores_com_chaves j√° tem geo_lat e geo_lng corretos, n√£o precisa renomear\n",
    "\n",
    "# Renomear colunas de pedidos para merge\n",
    "df_pedidos_com_chaves = df_pedidos_com_chaves.rename(columns={\n",
    "    'geo_lat': 'cliente_geo_lat',\n",
    "    'geo_lng': 'cliente_geo_lng'\n",
    "})\n",
    "\n",
    "# Realizar merges\n",
    "df_m = pd.merge(df_m, df_produtos_com_chaves.drop_duplicates(subset=cols_produtos), on=cols_produtos, how='left')\n",
    "df_m = pd.merge(df_m, df_vendedores_com_chaves.drop_duplicates(subset=cols_vendedores), on=cols_vendedores, how='left')\n",
    "df_m = pd.merge(df_m, df_data_com_chaves.drop_duplicates(subset=['dat_cmp']), on='dat_cmp', how='left')\n",
    "\n",
    "# Preparar colunas de pedidos para merge (sem tem_de_env_dia e flg_atr que s√£o calculados)\n",
    "cols_pedidos_merge = [c for c in cols_pedidos if c not in ['tem_de_env_dia', 'flg_atr']]\n",
    "cols_pedidos_merge.extend(['tem_de_env_dia', 'flg_atr'])\n",
    "df_m = pd.merge(df_m, df_pedidos_com_chaves.drop_duplicates(subset=cols_pedidos_merge), on=cols_pedidos_merge, how='left')\n",
    "\n",
    "# Preencher chaves ausentes com valores \"unknown\"\n",
    "df_m['SRK_prd'] = df_m['SRK_prd'].fillna(unknown_prod_key).astype(int)\n",
    "df_m['SRK_vnd'] = df_m['SRK_vnd'].fillna(unknown_vend_key).astype(int)\n",
    "df_m['SRK_dat'] = df_m['SRK_dat'].fillna(unknown_data_key).astype(int)\n",
    "df_m['SRK_ord'] = df_m['SRK_ord'].fillna(unknown_ord_key).astype(int)\n",
    "\n",
    "# Selecionar colunas para tabela fato\n",
    "cols_fato = ['SRK_prd', 'SRK_vnd', 'SRK_dat', 'SRK_ord', 'env_lmt_dat', 'val', 'frt_val']\n",
    "df_fato = df_m[cols_fato].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ed376-b013-4065-987b-31b167d52101",
   "metadata": {},
   "source": [
    "Esta c√©lula realiza a carga final da tabela fato FATO_ITENS_PEDIDO no schema DW.\n",
    "Ela insere todos os registros do DataFrame df_fato, j√° com as chaves substitutas das dimens√µes, consolidando os dados no modelo estrela do Data Warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c0e63588-ec46-4156-b6bc-f0796f11da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.FAT_ITS_ORD (\n",
    "                \"SRK_prd\", \"SRK_vnd\", \"SRK_dat_ord\", \"SRK_ord\",\n",
    "                env_lmt_dat, val, frt_val\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "\n",
    "        cols = ['SRK_prd', 'SRK_vnd', 'SRK_dat', 'SRK_ord', 'env_lmt_dat', 'val', 'frt_val']\n",
    "\n",
    "        def _to_db(v):\n",
    "            if v is None:\n",
    "                return None\n",
    "            if isinstance(v, float) and math.isnan(v):\n",
    "                return None\n",
    "            if pd.isna(v):\n",
    "                return None\n",
    "            return v\n",
    "\n",
    "        rows = [\n",
    "            tuple(_to_db(v) for v in row)\n",
    "            for row in df_fato[cols].itertuples(index=False, name=None)\n",
    "        ]\n",
    "\n",
    "        cur.executemany(insert_query, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e6f83e35-d9c0-4669-bacc-2275f9aae57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros carregados no banco:\n",
      "DIM_PRD: 32257\n",
      "DIM_VND: 2297\n",
      "DIM_ORD: 98910\n",
      "DIM_DAT: 617\n",
      "FAT_ITS_ORD: 112952\n"
     ]
    }
   ],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_PRD'); dim_produtos_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_VND'); dim_vendedores_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_ORD'); dim_pedidos_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_DAT'); dim_data_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.FAT_ITS_ORD'); fato_count = cur.fetchone()[0]\n",
    "\n",
    "print(f\"Registros carregados no banco:\")\n",
    "print(f\"DIM_PRD: {dim_produtos_count}\")\n",
    "print(f\"DIM_VND: {dim_vendedores_count}\")\n",
    "print(f\"DIM_ORD: {dim_pedidos_count}\")\n",
    "print(f\"DIM_DAT: {dim_data_count}\")\n",
    "print(f\"FAT_ITS_ORD: {fato_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
