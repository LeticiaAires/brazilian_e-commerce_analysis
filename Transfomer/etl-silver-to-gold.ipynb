{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0068f9d-075f-4d32-83c5-7c5247a97fc8",
   "metadata": {},
   "source": [
    "# ETL da camada Silver para camada Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13090515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: psycopg in /home/oem/.local/lib/python3.10/site-packages (3.2.12)\n",
      "Requirement already satisfied: sqlalchemy in /home/oem/.local/lib/python3.10/site-packages (2.0.44)\n",
      "Requirement already satisfied: pandas in /home/oem/.local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: dotenv in /home/oem/.local/lib/python3.10/site-packages (0.9.9)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /home/oem/.local/lib/python3.10/site-packages (from psycopg) (4.12.2)\n",
      "Requirement already satisfied: greenlet>=1 in /home/oem/.local/lib/python3.10/site-packages (from sqlalchemy) (3.2.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/oem/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/oem/.local/lib/python3.10/site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/oem/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in /home/oem/.local/lib/python3.10/site-packages (from dotenv) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg sqlalchemy pandas dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84fa58a-b1d2-4d12-9c09-1f8c9b355d71",
   "metadata": {},
   "source": [
    "Esta célula importa todas as bibliotecas necessárias para o processo de ETL.\n",
    "Aqui são carregados os pacotes para manipulação de dados (pandas), conexão com o banco de dados PostgreSQL (psycopg), controle de mensagens de erro (sys) e tratamento de avisos (warnings).\n",
    "Ela deve ser executada antes de qualquer outra célula, pois fornece as dependências básicas que serão usadas nas etapas de Extract, Transform e Load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66405d39-8834-4564-ac01-6b3c5bd2f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg\n",
    "from psycopg import connect, sql\n",
    "from psycopg2 import connect, sql\n",
    "import psycopg2\n",
    "import sys\n",
    "import warnings\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e503bd-17a3-45c6-b2de-9a026da11452",
   "metadata": {},
   "source": [
    "# 1. Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3aefa-7bba-4405-aa2e-b14d4631758a",
   "metadata": {},
   "source": [
    "Esta célula define as configurações de conexão com o banco de dados PostgreSQL e monta a consulta SQL que será usada para extrair os dados.\n",
    "Ela cria variáveis com credenciais, monta o nome completo da tabela (schema.tabela) e gera a query SELECT * FROM DL.ORDER_ITEMS, além de preparar a connection string usada na etapa de conexão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0a8653a-eda5-41c7-b1d5-54284054ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SCHEMA = 'DL'\n",
    "TABLE_NAME = 'ORDER_ITEMS'\n",
    "\n",
    "TABLE_FULL_NAME = sql.SQL(\"{}.{}\").format(\n",
    "    sql.Identifier(DB_SCHEMA),\n",
    "    sql.Identifier(TABLE_NAME)\n",
    ")\n",
    "\n",
    "def get_db_connection_info():\n",
    "    load_dotenv()\n",
    "    url = os.getenv('DB_URL')\n",
    "    db_env = os.getenv('DB_ENV')\n",
    "    if url is not None and db_env == 'prod':\n",
    "        return url\n",
    "\n",
    "    # credenciais do banco de dados local\n",
    "    DB_USER = \"postgres\"\n",
    "    DB_PASSWORD = \"postgres\"\n",
    "    DB_HOST = \"localhost\"\n",
    "    DB_PORT = \"5433\"\n",
    "    DB_NAME = \"olist\"\n",
    "\n",
    "    return f\"host={DB_HOST} dbname={DB_NAME} user={DB_USER} password={DB_PASSWORD} port={DB_PORT}\"\n",
    "\n",
    "\n",
    "query_object = sql.SQL(\"SELECT * FROM {}\").format(TABLE_FULL_NAME)\n",
    "\n",
    "connection_string = get_db_connection_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4bf8a8-93a2-4963-b547-e495b3c3d63f",
   "metadata": {},
   "source": [
    "Esta célula executa a extração dos dados do banco PostgreSQL.\n",
    "Ela estabelece a conexão usando as configurações definidas anteriormente, converte o objeto SQL em uma query legível, executa a consulta e carrega o resultado no DataFrame df.\n",
    "Em caso de falha na conexão ou na leitura, exibe uma mensagem de erro detalhada e encerra o processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02bc47-95a8-43ce-b090-fdd3ea9022e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estabelecendo conexão...\n",
      "Conexão estabelecida.\n",
      "Executando query: SELECT * FROM \"DL\".\"ORDER_ITEMS\"\n",
      "\n",
      "Dados carregados do banco para o DataFrame com sucesso!\n"
     ]
    }
   ],
   "source": [
    "DB_SCHEMA = 'DL'          \n",
    "TABLE_NAME = 'ORDER_ITEMS' \n",
    "\n",
    "def get_db_connection_info():\n",
    "    load_dotenv()\n",
    "    url = os.getenv('DB_URL')\n",
    "    db_env = os.getenv('DB_ENV')\n",
    "    if url is not None and db_env == 'prod':\n",
    "        return url\n",
    "\n",
    "    # credenciais do banco de dados local\n",
    "    DB_USER = \"postgres\"\n",
    "    DB_PASSWORD = \"postgres\"\n",
    "    DB_HOST = \"localhost\"\n",
    "    DB_PORT = \"5433\"\n",
    "    DB_NAME = \"olist\"\n",
    "\n",
    "    return f\"host={DB_HOST} dbname={DB_NAME} user={DB_USER} password={DB_PASSWORD} port={DB_PORT}\"\n",
    "\n",
    "\n",
    "connection_string = get_db_connection_info()\n",
    "\n",
    "# Aqui montamos a query com schema + tabela de forma segura\n",
    "query_object = sql.SQL(\"SELECT * FROM {}.{}\").format(\n",
    "    sql.Identifier(DB_SCHEMA),\n",
    "    sql.Identifier(TABLE_NAME)\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"Estabelecendo conexão...\")\n",
    "    with connect(connection_string) as conn:\n",
    "        print(\"Conexão estabelecida.\")\n",
    "\n",
    "        # Gera a string SQL final a partir do objeto seguro\n",
    "        query_string = query_object.as_string(conn)\n",
    "        print(f\"Executando query: {query_string}\")\n",
    "\n",
    "        # Lê o resultado direto em um DataFrame\n",
    "        df = pd.read_sql_query(query_string, conn)\n",
    "\n",
    "    print(\"\\nDados carregados do banco para o DataFrame com sucesso!\")\n",
    "except psycopg2.errors.UndefinedTable as e:\n",
    "    print(\"\\n--- A tabela informada não existe no banco de dados ---\")\n",
    "    print(f\"Tente conferir o schema e o nome da tabela: {DB_SCHEMA}.{TABLE_NAME}\")\n",
    "    print(f\"Erro detalhado: {e}\")\n",
    "    sys.exit(1)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"\\n--- Ocorreu um erro ao conectar ou ler o banco de dados ---\")\n",
    "    print(f\"Erro: {e}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(\"\\n--- Ocorreu um erro inesperado ---\")\n",
    "    print(f\"Erro: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b39988-5b56-428b-8f25-8700408cca2e",
   "metadata": {},
   "source": [
    "Estas células exibem um resumo simples do resultado da extração, mostrando o número total de registros carregados no DataFrame df, as primeiras três tuplas e os tipos de cada dado.\n",
    "Elas servem para confirmar visualmente que a consulta foi executada com sucesso e quantas linhas foram retornadas do banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d0918d7-0264-45a2-8fda-3eba9add9c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas carregadas: 112952\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total de linhas carregadas: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69a419cc-1c0d-4af9-9bf9-80426bfd8f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>shipping_limit_date</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>...</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>cliente_geolocation_lat</th>\n",
       "      <th>cliente_geolocation_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>2017-09-19 09:45:35</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>58.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-09-19 18:34:16</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>2017-09-22 10:57:03</td>\n",
       "      <td>28013</td>\n",
       "      <td>campos dos goytacazes</td>\n",
       "      <td>RJ</td>\n",
       "      <td>-21.758076</td>\n",
       "      <td>-41.312633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
       "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
       "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
       "      <td>2017-05-03 11:05:13</td>\n",
       "      <td>239.9</td>\n",
       "      <td>19.93</td>\n",
       "      <td>pet_shop</td>\n",
       "      <td>56.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-05-04 14:35:00</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>2017-05-15 11:34:13</td>\n",
       "      <td>15775</td>\n",
       "      <td>santa fe do sul</td>\n",
       "      <td>SP</td>\n",
       "      <td>-20.212393</td>\n",
       "      <td>-50.941471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
       "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
       "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
       "      <td>2018-01-18 14:48:30</td>\n",
       "      <td>199.0</td>\n",
       "      <td>17.87</td>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>59.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-16 12:36:48</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>2018-01-23 16:06:31</td>\n",
       "      <td>35661</td>\n",
       "      <td>para de minas</td>\n",
       "      <td>MG</td>\n",
       "      <td>-19.860439</td>\n",
       "      <td>-44.597972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_item_id                        product_id  \\\n",
       "0             1  4244733e06e7ecb4970a6e2683c13e61   \n",
       "1             1  e5f2d52b802189ee658865ca93d83a8f   \n",
       "2             1  c777355d18b72b67abbeef9df44fd0fd   \n",
       "\n",
       "                          seller_id                          order_id  \\\n",
       "0  48436dade18ac8b2bce089ec2a041202  00010242fe8c5a6d1ba2dd792cb16214   \n",
       "1  dd7ddc04e1b6c2c614352b383efe2d36  00018f77f2f0320c557190d7a144bdd3   \n",
       "2  5b51032eddd242adc84c38acab88f23d  000229ec398224ef6ca0657da4fc703e   \n",
       "\n",
       "  shipping_limit_date  price  freight_value product_category_name  \\\n",
       "0 2017-09-19 09:45:35   58.9          13.29            cool_stuff   \n",
       "1 2017-05-03 11:05:13  239.9          19.93              pet_shop   \n",
       "2 2018-01-18 14:48:30  199.0          17.87      moveis_decoracao   \n",
       "\n",
       "   product_name_lenght  product_description_lenght  ...  \\\n",
       "0                 58.0                       598.0  ...   \n",
       "1                 56.0                       239.0  ...   \n",
       "2                 59.0                       695.0  ...   \n",
       "\n",
       "   order_delivered_carrier_date  order_estimated_delivery_date  review_score  \\\n",
       "0           2017-09-19 18:34:16                     2017-09-29           5.0   \n",
       "1           2017-05-04 14:35:00                     2017-05-15           4.0   \n",
       "2           2018-01-16 12:36:48                     2018-02-05           5.0   \n",
       "\n",
       "   review_creation_date  review_answer_timestamp  customer_zip_code_prefix  \\\n",
       "0            2017-09-21      2017-09-22 10:57:03                     28013   \n",
       "1            2017-05-13      2017-05-15 11:34:13                     15775   \n",
       "2            2018-01-23      2018-01-23 16:06:31                     35661   \n",
       "\n",
       "           customer_city customer_state  cliente_geolocation_lat  \\\n",
       "0  campos dos goytacazes             RJ               -21.758076   \n",
       "1        santa fe do sul             SP               -20.212393   \n",
       "2          para de minas             MG               -19.860439   \n",
       "\n",
       "   cliente_geolocation_lng  \n",
       "0               -41.312633  \n",
       "1               -50.941471  \n",
       "2               -44.597972  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b5c3e8f-9a2b-4c5d-8e3f-9b4c5d6e7f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112952 entries, 0 to 112951\n",
      "Data columns (total 41 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_item_id                  112952 non-null  object        \n",
      " 1   product_id                     112952 non-null  object        \n",
      " 2   seller_id                      112952 non-null  object        \n",
      " 3   order_id                       112952 non-null  object        \n",
      " 4   shipping_limit_date            112952 non-null  datetime64[ns]\n",
      " 5   price                          112952 non-null  float64       \n",
      " 6   freight_value                  112952 non-null  float64       \n",
      " 7   product_category_name          111342 non-null  object        \n",
      " 8   product_name_lenght            111342 non-null  float64       \n",
      " 9   product_description_lenght     111342 non-null  float64       \n",
      " 10  product_photos_qty             111342 non-null  float64       \n",
      " 11  product_weight_g               112934 non-null  float64       \n",
      " 12  product_length_cm              112934 non-null  float64       \n",
      " 13  product_height_cm              112934 non-null  float64       \n",
      " 14  product_width_cm               112934 non-null  float64       \n",
      " 15  seller_zip_code_prefix         112952 non-null  int64         \n",
      " 16  seller_city                    112952 non-null  object        \n",
      " 17  seller_state                   112952 non-null  object        \n",
      " 18  vendedor_geolocation_lat       112697 non-null  float64       \n",
      " 19  vendedor_geolocation_lng       112697 non-null  float64       \n",
      " 20  review_comment_title           13391 non-null   object        \n",
      " 21  review_comment_message         47292 non-null   object        \n",
      " 22  customer_unique_id             112952 non-null  object        \n",
      " 23  order_status                   112952 non-null  object        \n",
      " 24  qtd_payment_sequential         112949 non-null  float64       \n",
      " 25  primeiro_payment_type          112949 non-null  object        \n",
      " 26  valor_total_pagamento          112949 non-null  float64       \n",
      " 27  maximo_payment_installments    112949 non-null  float64       \n",
      " 28  order_purchase_timestamp       112952 non-null  datetime64[ns]\n",
      " 29  order_delivered_customer_date  110492 non-null  datetime64[ns]\n",
      " 30  order_approved_at              112937 non-null  datetime64[ns]\n",
      " 31  order_delivered_carrier_date   111757 non-null  datetime64[ns]\n",
      " 32  order_estimated_delivery_date  112952 non-null  datetime64[ns]\n",
      " 33  review_score                   111461 non-null  float64       \n",
      " 34  review_creation_date           111461 non-null  datetime64[ns]\n",
      " 35  review_answer_timestamp        111461 non-null  datetime64[ns]\n",
      " 36  customer_zip_code_prefix       112952 non-null  int64         \n",
      " 37  customer_city                  112952 non-null  object        \n",
      " 38  customer_state                 112952 non-null  object        \n",
      " 39  cliente_geolocation_lat        112648 non-null  float64       \n",
      " 40  cliente_geolocation_lng        112648 non-null  float64       \n",
      "dtypes: datetime64[ns](8), float64(17), int64(2), object(14)\n",
      "memory usage: 35.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4d5e6-7f8a-9b0c-1d2e-3f4a5b6c7d8e",
   "metadata": {},
   "source": [
    "# 2. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8-9a0b-1c2d-3e4f-5a6b7c8d9e0f",
   "metadata": {},
   "source": [
    "Esta célula define as colunas que farão parte de cada dimensão no modelo estrela.\n",
    "Cada lista de colunas corresponde aos atributos que serão extraídos do DataFrame principal para formar as tabelas dimensionais DIM_PRODUTOS, DIM_VENDEDORES, DIM_PEDIDOS e a dimensão temporal DIM_DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas para DIM_PRODUTOS\n",
    "cols_produtos = [\n",
    "    'product_category_name',\n",
    "    'product_name_lenght',\n",
    "    'product_description_lenght',\n",
    "    'product_photos_qty',\n",
    "    'product_weight_g',\n",
    "    'product_length_cm',\n",
    "    'product_height_cm',\n",
    "    'product_width_cm'\n",
    "]\n",
    "\n",
    "# Colunas para DIM_VENDEDORES\n",
    "cols_vendedores = [\n",
    "    'seller_zip_code_prefix',\n",
    "    'seller_city',\n",
    "    'seller_state',\n",
    "    'vendedor_geolocation_lat',\n",
    "    'vendedor_geolocation_lng'\n",
    "]\n",
    "\n",
    "# Colunas para DIM_PEDIDOS\n",
    "cols_pedidos = [\n",
    "    'review_comment_title',\n",
    "    'review_comment_message',\n",
    "    'customer_unique_id',\n",
    "    'order_status',\n",
    "    'qtd_payment_sequential',\n",
    "    'primeiro_payment_type',\n",
    "    'valor_total_pagamento',\n",
    "    'maximo_payment_installments',\n",
    "    'order_purchase_timestamp',\n",
    "    'order_delivered_customer_date',\n",
    "    'order_approved_at',\n",
    "    'order_delivered_carrier_date',\n",
    "    'order_estimated_delivery_date',\n",
    "    'review_score',\n",
    "    'review_creation_date',\n",
    "    'review_answer_timestamp',\n",
    "    'customer_zip_code_prefix',\n",
    "    'customer_city',\n",
    "    'customer_state',\n",
    "    'cliente_geolocation_lat',\n",
    "    'cliente_geolocation_lng'\n",
    "]\n",
    "\n",
    "# Coluna para DIM_DATA (será extraída de order_purchase_timestamp)\n",
    "col_data = 'order_purchase_timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8f9a0-b1c2-3d4e-5f6a-7b8c9d0e1f2a",
   "metadata": {},
   "source": [
    "Esta célula renomeia as colunas do DataFrame para corresponder à nomenclatura da camada Gold.\n",
    "Os nomes são padronizados com prefixos mnemônicos (prod_, vend_, geo_) conforme definido no dicionário de dados da camada Gold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9f0a1b2-c3d4-5e6f-7a8b-9c0d1e2f3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear colunas para nomenclatura Gold\n",
    "df = df.rename(columns={\n",
    "    # Produtos\n",
    "    'product_category_name': 'prod_category_name',\n",
    "    'product_name_lenght': 'prod_name_lenght',\n",
    "    'product_description_lenght': 'prod_desc_lenght',\n",
    "    'product_photos_qty': 'prod_photos_qty',\n",
    "    'product_weight_g': 'prod_weight_g',\n",
    "    'product_length_cm': 'prod_length_cm',\n",
    "    'product_height_cm': 'prod_height_cm',\n",
    "    'product_width_cm': 'prod_width_cm',\n",
    "    # Vendedores\n",
    "    'seller_zip_code_prefix': 'vend_zip_code_prefix',\n",
    "    'seller_city': 'vend_city',\n",
    "    'seller_state': 'vend_state',\n",
    "    'vendedor_geolocation_lat': 'vend_geo_lat',\n",
    "    'vendedor_geolocation_lng': 'vend_geo_lng',\n",
    "    # Cliente (geolocalização)\n",
    "    'cliente_geolocation_lat': 'cliente_geo_lat',\n",
    "    'cliente_geolocation_lng': 'cliente_geo_lng'\n",
    "})\n",
    "\n",
    "# Atualizar listas de colunas com novos nomes\n",
    "cols_produtos = [\n",
    "    'prod_category_name',\n",
    "    'prod_name_lenght',\n",
    "    'prod_desc_lenght',\n",
    "    'prod_photos_qty',\n",
    "    'prod_weight_g',\n",
    "    'prod_length_cm',\n",
    "    'prod_height_cm',\n",
    "    'prod_width_cm'\n",
    "]\n",
    "\n",
    "cols_vendedores = [\n",
    "    'vend_zip_code_prefix',\n",
    "    'vend_city',\n",
    "    'vend_state',\n",
    "    'vend_geo_lat',\n",
    "    'vend_geo_lng'\n",
    "]\n",
    "\n",
    "cols_pedidos = [\n",
    "    'review_comment_title',\n",
    "    'review_comment_message',\n",
    "    'customer_unique_id',\n",
    "    'order_status',\n",
    "    'qtd_payment_sequential',\n",
    "    'primeiro_payment_type',\n",
    "    'valor_total_pagamento',\n",
    "    'maximo_payment_installments',\n",
    "    'order_purchase_timestamp',\n",
    "    'order_delivered_customer_date',\n",
    "    'order_approved_at',\n",
    "    'order_delivered_carrier_date',\n",
    "    'order_estimated_delivery_date',\n",
    "    'review_score',\n",
    "    'review_creation_date',\n",
    "    'review_answer_timestamp',\n",
    "    'customer_zip_code_prefix',\n",
    "    'customer_city',\n",
    "    'customer_state',\n",
    "    'cliente_geo_lat',\n",
    "    'cliente_geo_lng'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2b3c4-d5e6-7f8a-9b0c-1d2e3f4a5b6c",
   "metadata": {},
   "source": [
    "Esta célula cria campos calculados para a dimensão DIM_PEDIDOS.\n",
    "Calcula o tempo de entrega em dias (tempo_entrega_dias) e a flag de atraso (flag_atraso) comparando a data de entrega real com a data estimada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5b6c7d8-e9f0-1a2b-3c4d-5e6f7a8b9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter colunas de timestamp para datetime\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "df['order_estimated_delivery_date'] = pd.to_datetime(df['order_estimated_delivery_date'])\n",
    "\n",
    "# Calcular tempo de entrega em dias\n",
    "df['tempo_entrega_dias'] = (df['order_delivered_customer_date'] - df['order_purchase_timestamp']).dt.days\n",
    "\n",
    "# Calcular flag de atraso (1 se atrasou, 0 se não)\n",
    "df['flag_atraso'] = ((df['order_delivered_customer_date'] > df['order_estimated_delivery_date']).astype(int))\n",
    "\n",
    "# Adicionar campos calculados à lista de colunas de pedidos\n",
    "cols_pedidos.extend(['tempo_entrega_dias', 'flag_atraso'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7d8e9-f0a1-2b3c-4d5e-6f7a8b9c0d1e",
   "metadata": {},
   "source": [
    "Esta célula cria a dimensão temporal DIM_DATA extraindo datas únicas do campo order_purchase_timestamp.\n",
    "Para cada data única, extrai ano, mês, dia e dia da semana em português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7d8e9f0-a1b2-3c4d-5e6f-7a8b9c0d1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair datas únicas\n",
    "df_data = df[[col_data]].copy()\n",
    "df_data['data_completa'] = df_data[col_data].dt.date\n",
    "df_data = df_data[['data_completa']].drop_duplicates().copy()\n",
    "\n",
    "# Converter para datetime para extrair componentes\n",
    "df_data['data_completa'] = pd.to_datetime(df_data['data_completa'])\n",
    "\n",
    "# Extrair componentes da data\n",
    "df_data['ano'] = df_data['data_completa'].dt.year\n",
    "df_data['mes'] = df_data['data_completa'].dt.month\n",
    "df_data['dia'] = df_data['data_completa'].dt.day\n",
    "\n",
    "# Mapear dia da semana para português\n",
    "dias_semana_pt = {\n",
    "    0: 'Segunda',\n",
    "    1: 'Terça',\n",
    "    2: 'Quarta',\n",
    "    3: 'Quinta',\n",
    "    4: 'Sexta',\n",
    "    5: 'Sábado',\n",
    "    6: 'Domingo'\n",
    "}\n",
    "df_data['dia_da_semana'] = df_data['data_completa'].dt.dayofweek.map(dias_semana_pt)\n",
    "\n",
    "# Converter data_completa de volta para date\n",
    "df_data['data_completa'] = df_data['data_completa'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9f0a1-b2c3-4d5e-6f7a-8b9c0d1e2f3a",
   "metadata": {},
   "source": [
    "Esta célula cria DataFrames separados para cada dimensão, removendo duplicatas.\n",
    "Cada DataFrame conterá apenas as colunas relevantes para sua respectiva dimensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9f0a1b2-c3d4-5e6f-7a8b-9c0d1e2f3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_produtos = df[cols_produtos].drop_duplicates().copy()\n",
    "df_vendedores = df[cols_vendedores].drop_duplicates().copy()\n",
    "df_pedidos = df[cols_pedidos].drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1b2c3-d4e5-6f7a-8b9c-0d1e2f3a4b5c",
   "metadata": {},
   "source": [
    "Esta célula realiza a padronização e limpeza dos campos numéricos do DataFrame.\n",
    "Ela converte todas as colunas de métricas para tipo numérico, substitui valores infinitos por NaN e depois transforma todos os NaN e valores ausentes em None, garantindo que o banco de dados receba NULL corretamente durante a carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67a2bcf6-20ed-4ec9-b1f3-a09711204c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['price', 'freight_value', 'tempo_entrega_dias']\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.where(pd.notna(df), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d",
   "metadata": {},
   "source": [
    "Esta célula exibe um resumo da etapa de transformação, mostrando quantos registros foram preparados em cada dimensão e na tabela fato base.\n",
    "Em seguida, utiliza df.info() para apresentar a estrutura geral do DataFrame principal, permitindo verificar tipos de dados e possíveis valores nulos antes da carga no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7954d14-5c17-4dd2-bb28-96b35fea050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros preparados para carga:\n",
      "DIM_PRODUTOS: 32256\n",
      "DIM_VENDEDORES: 2296\n",
      "DIM_PEDIDOS: 98909\n",
      "DIM_DATA: 616\n",
      "FATO_ITENS_PEDIDO (base df): 112952\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112952 entries, 0 to 112951\n",
      "Data columns (total 43 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_item_id                  112952 non-null  object        \n",
      " 1   product_id                     112952 non-null  object        \n",
      " 2   seller_id                      112952 non-null  object        \n",
      " 3   order_id                       112952 non-null  object        \n",
      " 4   shipping_limit_date            112952 non-null  datetime64[ns]\n",
      " 5   price                          112952 non-null  float64       \n",
      " 6   freight_value                  112952 non-null  float64       \n",
      " 7   prod_category_name             111342 non-null  object        \n",
      " 8   prod_name_lenght               111342 non-null  float64       \n",
      " 9   prod_desc_lenght               111342 non-null  float64       \n",
      " 10  prod_photos_qty                111342 non-null  float64       \n",
      " 11  prod_weight_g                  112934 non-null  float64       \n",
      " 12  prod_length_cm                 112934 non-null  float64       \n",
      " 13  prod_height_cm                 112934 non-null  float64       \n",
      " 14  prod_width_cm                  112934 non-null  float64       \n",
      " 15  vend_zip_code_prefix           112952 non-null  int64         \n",
      " 16  vend_city                      112952 non-null  object        \n",
      " 17  vend_state                     112952 non-null  object        \n",
      " 18  vend_geo_lat                   112697 non-null  float64       \n",
      " 19  vend_geo_lng                   112697 non-null  float64       \n",
      " 20  review_comment_title           13391 non-null   object        \n",
      " 21  review_comment_message         47292 non-null   object        \n",
      " 22  customer_unique_id             112952 non-null  object        \n",
      " 23  order_status                   112952 non-null  object        \n",
      " 24  qtd_payment_sequential         112949 non-null  float64       \n",
      " 25  primeiro_payment_type          112949 non-null  object        \n",
      " 26  valor_total_pagamento          112949 non-null  float64       \n",
      " 27  maximo_payment_installments    112949 non-null  float64       \n",
      " 28  order_purchase_timestamp       112952 non-null  datetime64[ns]\n",
      " 29  order_delivered_customer_date  110492 non-null  datetime64[ns]\n",
      " 30  order_approved_at              112937 non-null  datetime64[ns]\n",
      " 31  order_delivered_carrier_date   111757 non-null  datetime64[ns]\n",
      " 32  order_estimated_delivery_date  112952 non-null  datetime64[ns]\n",
      " 33  review_score                   111461 non-null  float64       \n",
      " 34  review_creation_date           111461 non-null  datetime64[ns]\n",
      " 35  review_answer_timestamp        111461 non-null  datetime64[ns]\n",
      " 36  customer_zip_code_prefix       112952 non-null  int64         \n",
      " 37  customer_city                  112952 non-null  object        \n",
      " 38  customer_state                 112952 non-null  object        \n",
      " 39  cliente_geo_lat                112648 non-null  float64       \n",
      " 40  cliente_geo_lng                112648 non-null  float64       \n",
      " 41  tempo_entrega_dias             110492 non-null  float64       \n",
      " 42  flag_atraso                    112952 non-null  int64         \n",
      "dtypes: datetime64[ns](8), float64(18), int64(3), object(14)\n",
      "memory usage: 37.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Registros preparados para carga:\")\n",
    "print(f\"DIM_PRODUTOS: {len(df_produtos)}\")\n",
    "print(f\"DIM_VENDEDORES: {len(df_vendedores)}\")\n",
    "print(f\"DIM_PEDIDOS: {len(df_pedidos)}\")\n",
    "print(f\"DIM_DATA: {len(df_data)}\")\n",
    "print(f\"FATO_ITENS_PEDIDO (base df): {len(df)}\\n\\n\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe0394e-0dc6-471f-a7b9-2965b2498912",
   "metadata": {},
   "source": [
    "# 3. Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716cf2d4-5418-48ee-835f-a68e36f5fefb",
   "metadata": {},
   "source": [
    "Esta célula configura os parâmetros de conexão com o banco de dados do Data Warehouse (DW) e valida se todas as variáveis geradas na etapa de transformação estão disponíveis na memória.\n",
    "Ela garante que o ambiente esteja pronto antes de iniciar a fase de carga, evitando erros por falta de dados ou variáveis necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e779b8d-dd04-439b-bea3-7c2418ebe77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SCHEMA_GOLD = \"DW\"\n",
    "\n",
    "connection_string = get_db_connection_info()\n",
    "\n",
    "for v in ['df', 'df_produtos', 'df_vendedores', 'df_pedidos', 'df_data', 'cols_produtos', 'cols_vendedores', 'cols_pedidos', 'col_data']:\n",
    "    if v not in globals():\n",
    "        raise RuntimeError(f\"Variável ausente: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915271d-7a91-447e-a7e1-182c4a09a312",
   "metadata": {},
   "source": [
    "Esta célula executa o script DDL responsável por criar ou recriar as tabelas do schema DW no banco de dados.\n",
    "Ela lê o arquivo SQL que contém a definição das tabelas e executa o comando dentro de uma conexão com o PostgreSQL, preparando a estrutura necessária para receber os dados na etapa de carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bb09603-ab9b-47f6-9d8f-305a95b82ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ddl_gold = open('../data_layer/gold/DDL.sql').read()\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivo 'DDL.sql' não encontrado em '../data_layer/gold/DDL.sql'.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(ddl_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729132b-f4dc-4008-aa6b-0c9b2c5c1447",
   "metadata": {},
   "source": [
    "Esta célula realiza a carga da dimensão Produtos no schema DW.\n",
    "Ela insere todos os registros do DataFrame df_produtos na tabela DIM_PRODUTOS e adiciona uma linha extra com valores nulos para representar o registro 'desconhecido', armazenando sua chave substituta (unknown_prod_key) para uso posterior na carga da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5669411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL</td>\n",
       "      <td>ORDER_ITEMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dl</td>\n",
       "      <td>order_items</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dw</td>\n",
       "      <td>dim_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dw</td>\n",
       "      <td>dim_pedidos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dw</td>\n",
       "      <td>dim_produtos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dw</td>\n",
       "      <td>dim_vendedores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dw</td>\n",
       "      <td>fato_itens_pedido</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  table_schema         table_name\n",
       "0           DL        ORDER_ITEMS\n",
       "1           dl        order_items\n",
       "2           dw           dim_data\n",
       "3           dw        dim_pedidos\n",
       "4           dw       dim_produtos\n",
       "5           dw     dim_vendedores\n",
       "6           dw  fato_itens_pedido"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    df_all_tables = pd.read_sql_query(\"\"\"\n",
    "        SELECT table_schema, table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema NOT IN ('pg_catalog', 'information_schema')\n",
    "        ORDER BY table_schema, table_name;\n",
    "    \"\"\", conn)\n",
    "\n",
    "df_all_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5349745-a71a-441b-ad4a-81f4616d1500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chave surrogate do produto desconhecido: 33153\n"
     ]
    }
   ],
   "source": [
    "cols_produtos = [\n",
    "    \"prod_category_name\",\n",
    "    \"prod_name_lenght\",\n",
    "    \"prod_desc_lenght\",\n",
    "    \"prod_photos_qty\",\n",
    "    \"prod_weight_g\",\n",
    "    \"prod_length_cm\",\n",
    "    \"prod_height_cm\",\n",
    "    \"prod_width_cm\",\n",
    "]\n",
    "\n",
    "# 1) Copia apenas as colunas que interessam\n",
    "df_ins = df_produtos[cols_produtos].copy()\n",
    "\n",
    "# 2) Converte colunas numéricas explicitamente\n",
    "int_cols = [\"prod_name_lenght\", \"prod_desc_lenght\", \"prod_photos_qty\"]\n",
    "dec_cols = [\"prod_weight_g\", \"prod_length_cm\", \"prod_height_cm\", \"prod_width_cm\"]\n",
    "\n",
    "for col in int_cols:\n",
    "    df_ins[col] = pd.to_numeric(df_ins[col], errors=\"coerce\")  # inválido -> NaN\n",
    "\n",
    "for col in dec_cols:\n",
    "    df_ins[col] = pd.to_numeric(df_ins[col], errors=\"coerce\")\n",
    "\n",
    "# 3) Troca NaN -> None, mas SEM perder isso no .to_numpy()\n",
    "#    Transforma o DataFrame em tipo \"object\" pra preservar None\n",
    "df_ins = df_ins.astype(object)\n",
    "df_ins = df_ins.where(df_ins.notna(), None)\n",
    "\n",
    "# 4) Gera as linhas preservando None (sem .to_numpy())\n",
    "rows = list(df_ins.itertuples(index=False, name=None))\n",
    "\n",
    "insert_query = sql.SQL(\n",
    "    \"\"\"\n",
    "    INSERT INTO DW.DIM_PRODUTOS (\n",
    "        prod_category_name, prod_name_lenght, prod_desc_lenght, prod_photos_qty,\n",
    "        prod_weight_g, prod_length_cm, prod_height_cm, prod_width_cm\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # 5) Insere todos os produtos\n",
    "        cur.executemany(insert_query, rows)\n",
    "\n",
    "        # 6) Insere o registro UNKNOWN e pega a SRK\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO DW.DIM_PRODUTOS (\n",
    "                prod_category_name, prod_name_lenght, prod_desc_lenght, prod_photos_qty,\n",
    "                prod_weight_g, prod_length_cm, prod_height_cm, prod_width_cm\n",
    "            ) VALUES (NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL)\n",
    "            RETURNING \"SRK_prod\";\n",
    "            \"\"\"\n",
    "        )\n",
    "        unknown_prod_key = cur.fetchone()[0]\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "print(\"Chave surrogate do produto desconhecido:\", unknown_prod_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2fe8f-08b7-435f-9f2d-66dd7bf2d532",
   "metadata": {},
   "source": [
    "Esta célula insere os dados da dimensão Vendedores no schema DW.\n",
    "Ela carrega todos os registros do DataFrame df_vendedores na tabela DIM_VENDEDORES e adiciona um registro adicional com valores nulos para representar o vendedor 'desconhecido', salvando sua chave substituta (unknown_vend_key) para uso posterior na carga da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "594b3b18-8954-4ccc-acdd-35276dfa399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.DIM_VENDEDORES (\n",
    "                vend_zip_code_prefix, vend_city, vend_state, geo_lat, geo_lng\n",
    "            ) VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "        cur.executemany(insert_query, [tuple(x) for x in df_vendedores.to_numpy()])\n",
    "        cur.execute(\n",
    "            \"\"\"INSERT INTO DW.DIM_VENDEDORES (\n",
    "                vend_zip_code_prefix, vend_city, vend_state, geo_lat, geo_lng\n",
    "            ) VALUES (NULL, NULL, NULL, NULL, NULL) RETURNING \"SRK_vend\" \"\"\"\n",
    "        )\n",
    "        unknown_vend_key = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d0a5c0-40da-4300-b353-037f88a46caf",
   "metadata": {},
   "source": [
    "Esta célula carrega os dados da dimensão Data no schema DW.\n",
    "Ela insere os registros do DataFrame df_data na tabela DIM_DATA e adiciona um registro com valores nulos para representar datas desconhecidas, salvando sua chave substituta (unknown_data_key) que será usada na inserção da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82e00be8-4979-415c-b9ec-e55851a209dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.DIM_DATA (\n",
    "                data_completa, ano, mes, dia, dia_da_semana\n",
    "            ) VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "        cur.executemany(insert_query, [tuple(x) for x in df_data.to_numpy()])\n",
    "        cur.execute(\n",
    "            \"\"\"INSERT INTO DW.DIM_DATA (\n",
    "                data_completa, ano, mes, dia, dia_da_semana\n",
    "            ) VALUES (NULL, NULL, NULL, NULL, NULL) RETURNING \"SRK_data\" \"\"\"\n",
    "        )\n",
    "        unknown_data_key = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e2a1a-43f1-4d2a-87ba-0d95a8579030",
   "metadata": {},
   "source": [
    "Esta célula realiza a carga da dimensão Pedidos no schema DW.\n",
    "Ela insere os registros do DataFrame df_pedidos na tabela DIM_PEDIDOS e adiciona um registro com valores nulos para representar pedidos ausentes, armazenando a chave substituta (unknown_ord_key) que será utilizada posteriormente na carga da tabela fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc718c25-dad6-4969-91f2-ab1250dab316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chave surrogate do pedido UNKNOWN: 98941\n"
     ]
    }
   ],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.DIM_PEDIDOS (\n",
    "                review_comment_title, review_comment_message, customer_unique_id, order_status,\n",
    "                qtd_payment_sequential, primeiro_payment_type, valor_total_pagamento, maximo_payment_installments,\n",
    "                order_purchase_timestamp, order_delivered_customer_date, tempo_entrega_dias, flag_atraso,\n",
    "                order_approved_at, order_delivered_carrier_date, order_estimated_delivery_date,\n",
    "                review_score, review_creation_date, review_answer_timestamp,\n",
    "                customer_zip_code_prefix, customer_city, customer_state, geo_lat, geo_lng\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "\n",
    "        # ---------- PREPARAÇÃO DO DATAFRAME ----------\n",
    "        df_pedidos_load = df_pedidos.copy()\n",
    "        df_pedidos_load = df_pedidos_load.rename(columns={\n",
    "            'cliente_geo_lat': 'geo_lat',\n",
    "            'cliente_geo_lng': 'geo_lng'\n",
    "        })\n",
    "\n",
    "        cols_pedidos_load = [\n",
    "            'review_comment_title', 'review_comment_message', 'customer_unique_id', 'order_status',\n",
    "            'qtd_payment_sequential', 'primeiro_payment_type', 'valor_total_pagamento', 'maximo_payment_installments',\n",
    "            'order_purchase_timestamp', 'order_delivered_customer_date', 'tempo_entrega_dias', 'flag_atraso',\n",
    "            'order_approved_at', 'order_delivered_carrier_date', 'order_estimated_delivery_date',\n",
    "            'review_score', 'review_creation_date', 'review_answer_timestamp',\n",
    "            'customer_zip_code_prefix', 'customer_city', 'customer_state', 'geo_lat', 'geo_lng'\n",
    "        ]\n",
    "\n",
    "        df_ins = df_pedidos_load[cols_pedidos_load].copy()\n",
    "\n",
    "        # ---------- TRATAMENTO das DATAS ----------\n",
    "        dt_cols = [\n",
    "            'order_purchase_timestamp',\n",
    "            'order_delivered_customer_date',\n",
    "            'order_approved_at',\n",
    "            'order_delivered_carrier_date',\n",
    "            'order_estimated_delivery_date',\n",
    "            'review_creation_date',\n",
    "            'review_answer_timestamp',\n",
    "        ]\n",
    "\n",
    "        for col in dt_cols:\n",
    "            df_ins[col] = pd.to_datetime(df_ins[col], errors='coerce')\n",
    "\n",
    "        # ---------- TRATAMENTO das NUMÉRICAS ----------\n",
    "        num_cols = [\n",
    "            'qtd_payment_sequential', 'valor_total_pagamento', 'maximo_payment_installments',\n",
    "            'tempo_entrega_dias', 'flag_atraso', 'review_score',\n",
    "            'customer_zip_code_prefix', 'geo_lat', 'geo_lng'\n",
    "        ]\n",
    "\n",
    "        for col in num_cols:\n",
    "            df_ins[col] = pd.to_numeric(df_ins[col], errors='coerce')\n",
    "\n",
    "        # ---------- TRATAR NaN / NaT → None ----------\n",
    "        df_ins = df_ins.astype(object)\n",
    "        df_ins = df_ins.where(df_ins.notna(), None)\n",
    "\n",
    "        # ---------- GERAR LINHAS SEM .to_numpy ----------\n",
    "        rows = list(df_ins.itertuples(index=False, name=None))\n",
    "\n",
    "        # ---------- INSERIR TODOS ----------\n",
    "        cur.executemany(insert_query, rows)\n",
    "\n",
    "        # ---------- INSERIR UNKNOWN ----------\n",
    "        cur.execute(\n",
    "            \"\"\"INSERT INTO DW.DIM_PEDIDOS (\n",
    "                review_comment_title, review_comment_message, customer_unique_id, order_status,\n",
    "                qtd_payment_sequential, primeiro_payment_type, valor_total_pagamento, maximo_payment_installments,\n",
    "                order_purchase_timestamp, order_delivered_customer_date, tempo_entrega_dias, flag_atraso,\n",
    "                order_approved_at, order_delivered_carrier_date, order_estimated_delivery_date,\n",
    "                review_score, review_creation_date, review_answer_timestamp,\n",
    "                customer_zip_code_prefix, customer_city, customer_state, geo_lat, geo_lng\n",
    "            ) VALUES (\n",
    "                NULL, NULL, 'UNKNOWN', 'unknown',\n",
    "                NULL, NULL, NULL, NULL,\n",
    "                '1900-01-01', NULL, NULL, NULL,\n",
    "                NULL, NULL, NULL,\n",
    "                NULL, NULL, NULL,\n",
    "                NULL, NULL, NULL, NULL, NULL\n",
    "            )\n",
    "            RETURNING \"SRK_ord\";\"\"\"\n",
    "        )\n",
    "        unknown_ord_key = cur.fetchone()[0]\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "print(\"Chave surrogate do pedido UNKNOWN:\", unknown_ord_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4bb4fa-8145-4716-aae9-8b69de2bec68",
   "metadata": {},
   "source": [
    "Esta célula faz o mapeamento das chaves substitutas (SRKs) das dimensões para o DataFrame principal.\n",
    "Ela lê as tabelas dimensionais do banco, realiza os joins com o DataFrame original (df) e substitui valores ausentes pelas chaves 'desconhecidas'.\n",
    "O resultado é o DataFrame df_fato, já com todas as referências dimensionais resolvidas e pronto para ser inserido na tabela fato FATO_ITENS_PEDIDO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "112fc738-199a-445a-9531-74b6898573cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    df_produtos_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_PRODUTOS', conn)\n",
    "    df_vendedores_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_VENDEDORES', conn)\n",
    "    df_pedidos_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_PEDIDOS', conn)\n",
    "    df_data_com_chaves = pd.read_sql('SELECT * FROM DW.DIM_DATA', conn)\n",
    "\n",
    "# Preparar DataFrame para merge\n",
    "df_m = df.copy()\n",
    "\n",
    "# Preparar coluna de data para merge\n",
    "df_m['data_completa'] = df_m['order_purchase_timestamp'].dt.date\n",
    "df_data_com_chaves['data_completa'] = pd.to_datetime(df_data_com_chaves['data_completa']).dt.date\n",
    "\n",
    "# Renomear colunas de vendedores para merge\n",
    "df_vendedores_com_chaves = df_vendedores_com_chaves.rename(columns={\n",
    "    'geo_lat': 'vend_geo_lat',\n",
    "    'geo_lng': 'vend_geo_lng'\n",
    "})\n",
    "\n",
    "# Renomear colunas de pedidos para merge\n",
    "df_pedidos_com_chaves = df_pedidos_com_chaves.rename(columns={\n",
    "    'geo_lat': 'cliente_geo_lat',\n",
    "    'geo_lng': 'cliente_geo_lng'\n",
    "})\n",
    "\n",
    "# Realizar merges\n",
    "df_m = pd.merge(df_m, df_produtos_com_chaves.drop_duplicates(subset=cols_produtos), on=cols_produtos, how='left')\n",
    "df_m = pd.merge(df_m, df_vendedores_com_chaves.drop_duplicates(subset=cols_vendedores), on=cols_vendedores, how='left')\n",
    "df_m = pd.merge(df_m, df_data_com_chaves.drop_duplicates(subset=['data_completa']), on='data_completa', how='left')\n",
    "\n",
    "# Preparar colunas de pedidos para merge (sem tempo_entrega_dias e flag_atraso que são calculados)\n",
    "cols_pedidos_merge = [c for c in cols_pedidos if c not in ['tempo_entrega_dias', 'flag_atraso']]\n",
    "cols_pedidos_merge.extend(['tempo_entrega_dias', 'flag_atraso'])\n",
    "df_m = pd.merge(df_m, df_pedidos_com_chaves.drop_duplicates(subset=cols_pedidos_merge), on=cols_pedidos_merge, how='left')\n",
    "\n",
    "# Preencher chaves ausentes com valores \"unknown\"\n",
    "df_m['SRK_prod'] = df_m['SRK_prod'].fillna(unknown_prod_key).astype(int)\n",
    "df_m['SRK_vend'] = df_m['SRK_vend'].fillna(unknown_vend_key).astype(int)\n",
    "df_m['SRK_data'] = df_m['SRK_data'].fillna(unknown_data_key).astype(int)\n",
    "df_m['SRK_ord'] = df_m['SRK_ord'].fillna(unknown_ord_key).astype(int)\n",
    "\n",
    "# Selecionar colunas para tabela fato\n",
    "cols_fato = ['SRK_prod', 'SRK_vend', 'SRK_data', 'SRK_ord', 'shipping_limit_date', 'price', 'freight_value']\n",
    "df_fato = df_m[cols_fato].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ed376-b013-4065-987b-31b167d52101",
   "metadata": {},
   "source": [
    "Esta célula realiza a carga final da tabela fato FATO_ITENS_PEDIDO no schema DW.\n",
    "Ela insere todos os registros do DataFrame df_fato, já com as chaves substitutas das dimensões, consolidando os dados no modelo estrela do Data Warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0e63588-ec46-4156-b6bc-f0796f11da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"INSERT INTO DW.FATO_ITENS_PEDIDO (\n",
    "                \"SRK_prod\", \"SRK_vend\", \"SRK_data_pedido\", \"SRK_ord\",\n",
    "                ship_limit_date, price, freight_value\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "        )\n",
    "\n",
    "        cols = ['SRK_prod', 'SRK_vend', 'SRK_data', 'SRK_ord', 'shipping_limit_date', 'price', 'freight_value']\n",
    "\n",
    "        def _to_db(v):\n",
    "            if v is None:\n",
    "                return None\n",
    "            if isinstance(v, float) and math.isnan(v):\n",
    "                return None\n",
    "            if pd.isna(v):\n",
    "                return None\n",
    "            return v\n",
    "\n",
    "        rows = [\n",
    "            tuple(_to_db(v) for v in row)\n",
    "            for row in df_fato[cols].itertuples(index=False, name=None)\n",
    "        ]\n",
    "\n",
    "        cur.executemany(insert_query, rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c9211-b86a-425b-a6ae-f8026af7a075",
   "metadata": {},
   "source": [
    "Esta célula consulta diretamente o banco de dados para verificar a quantidade de registros inseridos em cada tabela.\n",
    "Ela exibe o total de linhas carregadas nas dimensões e na tabela fato, funcionando como uma checagem final para confirmar que a etapa de carga foi concluída com sucesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6f83e35-d9c0-4669-bacc-2275f9aae57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros carregados no banco:\n",
      "DIM_PRODUTOS: 32257\n",
      "DIM_VENDEDORES: 2297\n",
      "DIM_PEDIDOS: 98910\n",
      "DIM_DATA: 617\n",
      "FATO_ITENS_PEDIDO: 112952\n"
     ]
    }
   ],
   "source": [
    "with connect(connection_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_PRODUTOS'); dim_produtos_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_VENDEDORES'); dim_vendedores_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_PEDIDOS'); dim_pedidos_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.DIM_DATA'); dim_data_count = cur.fetchone()[0]\n",
    "        cur.execute('SELECT COUNT(*) FROM DW.FATO_ITENS_PEDIDO'); fato_count = cur.fetchone()[0]\n",
    "\n",
    "print(f\"Registros carregados no banco:\")\n",
    "print(f\"DIM_PRODUTOS: {dim_produtos_count}\")\n",
    "print(f\"DIM_VENDEDORES: {dim_vendedores_count}\")\n",
    "print(f\"DIM_PEDIDOS: {dim_pedidos_count}\")\n",
    "print(f\"DIM_DATA: {dim_data_count}\")\n",
    "print(f\"FATO_ITENS_PEDIDO: {fato_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
