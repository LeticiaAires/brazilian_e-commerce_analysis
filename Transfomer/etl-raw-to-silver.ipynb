{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "994378db",
   "metadata": {},
   "source": [
    "# **ETL da raw para a silver**\n",
    "\n",
    "Esse notebook ira realisar o ETL, um processo de três etapas — Extrair, Transformar e Carregar, usado para integrar dados de diferentes fontes em um único dat warehouse. \n",
    "Essa metodologia combina dados, limpando-os e organizando-os para análise, relatórios e tomada de decisões de negócios. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e93aba",
   "metadata": {},
   "source": [
    "A célula abaixo instala as bibliotecas Python necessárias (como Pandas para dados e SQLAlchemy para banco de dados) no ambiente do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89fe51c8-087b-485c-8927-f8db19b60ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pandas sqlalchemy psycopg2-binary python-dotenv pyarrow tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd00a6a",
   "metadata": {},
   "source": [
    "#### Importando as Bibliotecas necessarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93f552dc-7cb7-4a16-9c47-defefc98afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7911eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Configuração de schema e função utilitária para leitura ----------\n",
    "Int = \"Int64\"  # inteiros que aceitam NA\n",
    "Str = \"string\"\n",
    "\n",
    "DTYPES = {\n",
    "    \"olist_orders_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"customer_id\": Str,\n",
    "        \"order_status\": Str,\n",
    "    },\n",
    "    \"olist_order_items_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"order_item_id\": Int,\n",
    "        \"product_id\": Str,\n",
    "        \"seller_id\": Str,\n",
    "        \"price\": \"float64\",\n",
    "        \"freight_value\": \"float64\",\n",
    "    },\n",
    "    \"olist_order_payments_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"payment_sequential\": Int,\n",
    "        \"payment_type\": Str,\n",
    "        \"payment_installments\": Int,\n",
    "        \"payment_value\": \"float64\",\n",
    "    },\n",
    "    \"olist_order_reviews_dataset.csv\": {\n",
    "        \"review_id\": Str,\n",
    "        \"order_id\": Str,\n",
    "        \"review_score\": Int,\n",
    "        \"review_comment_title\": Str,\n",
    "        \"review_comment_message\": Str,\n",
    "    },\n",
    "    \"olist_products_dataset.csv\": {\n",
    "        \"product_id\": Str,\n",
    "        \"product_category_name\": Str,\n",
    "        \"product_name_lenght\": Int,\n",
    "        \"product_description_lenght\": Int,\n",
    "        \"product_photos_qty\": Int,\n",
    "        \"product_weight_g\": Int,\n",
    "        \"product_length_cm\": Int,\n",
    "        \"product_height_cm\": Int,\n",
    "        \"product_width_cm\": Int,\n",
    "    },\n",
    "    \"olist_sellers_dataset.csv\": {\n",
    "        \"seller_id\": Str,\n",
    "        \"seller_zip_code_prefix\": Int,\n",
    "        \"seller_city\": Str,\n",
    "        \"seller_state\": Str,\n",
    "    },\n",
    "    \"olist_customers_dataset.csv\": {\n",
    "        \"customer_id\": Str,\n",
    "        \"customer_unique_id\": Str,\n",
    "        \"customer_zip_code_prefix\": Int,\n",
    "        \"customer_city\": Str,\n",
    "        \"customer_state\": Str,\n",
    "    },\n",
    "    \"olist_geolocation_dataset.csv\": {\n",
    "        \"geolocation_zip_code_prefix\": Int,\n",
    "        \"geolocation_lat\": \"float64\",\n",
    "        \"geolocation_lng\": \"float64\",\n",
    "        \"geolocation_city\": Str,\n",
    "        \"geolocation_state\": Str,\n",
    "    },\n",
    "    \"product_category_name_translation.csv\": {\n",
    "        \"product_category_name\": Str,\n",
    "        \"product_category_name_english\": Str,\n",
    "    },\n",
    "}\n",
    "\n",
    "PARSE_DATES = {\n",
    "    \"olist_orders_dataset.csv\": [\n",
    "        \"order_purchase_timestamp\",\n",
    "        \"order_approved_at\",\n",
    "        \"order_delivered_carrier_date\",\n",
    "        \"order_delivered_customer_date\",\n",
    "        \"order_estimated_delivery_date\",\n",
    "    ],\n",
    "    \"olist_order_items_dataset.csv\": [\n",
    "        \"shipping_limit_date\",\n",
    "    ],\n",
    "    \"olist_order_reviews_dataset.csv\": [\n",
    "        \"review_creation_date\",\n",
    "        \"review_answer_timestamp\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "def load_csv(filename: str, dtypes=None, parse_dates=None):\n",
    "    \"\"\"Carrega um CSV da Bronze, padroniza nomes das colunas (lower) e retorna DataFrame.\"\"\"\n",
    "    path = RAW_DIR / filename\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"CSV não encontrado: {path}\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        dtype=dtypes or {},\n",
    "        parse_dates=parse_dates,\n",
    "        keep_default_na=True,\n",
    "        encoding=\"utf-8\",\n",
    "        infer_datetime_format=True,\n",
    "        low_memory=False,\n",
    "    )\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e172ba",
   "metadata": {},
   "source": [
    "A célula abaixo encontra a pasta raiz do projeto buscando por data_layer, define os caminhos importantes (raw, sql), e verifica se os dados brutos (raw e o arquivo de pedidos) existem e podem ser lidos, exibindo as 5 primeiras linhas como prova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f88701a-9b73-4be3-866d-0f4062b39dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/oem/Documentos/FGA/SBD2/SenTry/brazilian_e-commerce_analysis/Transfomer\n",
      "PROJECT_ROOT: /home/oem/Documentos/FGA/SBD2/SenTry/brazilian_e-commerce_analysis\n",
      "RAW_DIR: /home/oem/Documentos/FGA/SBD2/SenTry/brazilian_e-commerce_analysis/data_layer/raw\n",
      "DDL_PATH: /home/oem/Documentos/FGA/SBD2/SenTry/brazilian_e-commerce_analysis/data_layer/silver/DDL.sql\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  \n",
       "3           2017-12-15 00:00:00  \n",
       "4           2018-02-26 00:00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bronze encontrada e legível.\n"
     ]
    }
   ],
   "source": [
    "# 1) Detectar automaticamente a raiz que contém \"data_layer\"\n",
    "CWD = Path.cwd()\n",
    "PROJECT_ROOT = None\n",
    "for candidate in [CWD, *CWD.parents]:\n",
    "    if (candidate / \"data_layer\").exists():\n",
    "        PROJECT_ROOT = candidate\n",
    "        break\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        f'Não achei a pasta \"data_layer\" a partir de {CWD}. '\n",
    "        f'Abra o notebook a partir do repositório ou mova este .ipynb para dentro dele.'\n",
    "    )\n",
    "\n",
    "# 2) Recalcular caminhos com base na raiz correta\n",
    "RAW_DIR = PROJECT_ROOT / \"data_layer\" /  \"raw\"\n",
    "# DDL está na pasta silver (mesmo que não vamos criar pasta silver)\n",
    "DDL_PATH = PROJECT_ROOT / \"data_layer\" / \"silver\" / \"DDL.sql\"\n",
    "\n",
    "print(\"CWD:\", CWD)\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"DDL_PATH:\", DDL_PATH)\n",
    "\n",
    "# 3) Validar que CSVs existem e sao kegiveis\n",
    "assert RAW_DIR.exists(), f\"Pasta Bronze (raw) não encontrada: {RAW_DIR}\"\n",
    "\n",
    "# 4) Checagem mínima: tentar ler 5 linhas do orders\n",
    "orders_csv = RAW_DIR / \"olist_orders_dataset.csv\"\n",
    "assert orders_csv.exists(), f\"Arquivo esperado não encontrado: {orders_csv}\"\n",
    "display(pd.read_csv(orders_csv, nrows=5).head())\n",
    "print(\"✅ Bronze encontrada e legível.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f450e61-b9b8-406d-92a0-5b3930771b9f",
   "metadata": {},
   "source": [
    "# EXTRACT — Ler dados da Bronze\n",
    "\n",
    "- Carrega todos os CSVs de `olist-ecommerce-pipeline/data/raw`.\n",
    "- Define dtypes explícitos e faz *parse* de datas.\n",
    "- Exibe *shape*, tipos e amostra de linhas para validação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531944ad",
   "metadata": {},
   "source": [
    "### DB Config & Connection Test\n",
    "\n",
    "_Lê variáveis do`` =.env`` (se existir) ou usa defaults locais.\n",
    "Testa conexão, cria o schema ``DL`` (se não existir) e ajusta ``search_path``.\n",
    "Não falha o notebook se o Postgres não estiver no ar apenas avisa._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80e106ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_HOST: localhost | DB_PORT: 5435 | DB_NAME: olist | SCHEMA: DL\n"
     ]
    }
   ],
   "source": [
    "# 1) Carregar .env se existir (opcional)\n",
    "ENV_PATH = PROJECT_ROOT / \".env\"\n",
    "if ENV_PATH.exists():\n",
    "    # carregamento leve do .env (sem dependências)\n",
    "    with open(ENV_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "                continue\n",
    "            k, v = line.split(\"=\", 1)\n",
    "            os.environ.setdefault(k.strip(), v.strip())\n",
    "\n",
    "# 2) Variáveis de conexão (definidas aqui, mas a conexão será aberta somente na etapa LOAD no final do notebook)\n",
    "DB_HOST   = os.getenv(\"PGHOST\", \"localhost\")\n",
    "DB_PORT   = os.getenv(\"PGPORT\", \"5435\")\n",
    "DB_NAME   = os.getenv(\"PGDATABASE\", \"olist\")\n",
    "DB_USER   = os.getenv(\"PGUSER\", \"postgres\")\n",
    "DB_PASS   = os.getenv(\"PGPASSWORD\", \"postgres\")\n",
    "DB_SCHEMA = os.getenv(\"PGSCHEMA\", \"DL\")   # Data Layer (DL)\n",
    "\n",
    "print(\"DB_HOST:\", DB_HOST, \"| DB_PORT:\", DB_PORT, \"| DB_NAME:\", DB_NAME, \"| SCHEMA:\", DB_SCHEMA)\n",
    "\n",
    "# Nota: Não criamos `engine` nem tentamos abrir conexão aqui —\n",
    "# a conexão com o banco será feita apenas na etapa final de LOAD (para evitar depender do DB durante o desenvolvimento/transformações).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2005760",
   "metadata": {},
   "source": [
    "A célula abaixo, define uma função que verifica a existência de um arquivo CSV, carrega seu conteúdo da pasta bruta (Bronze) para a memória aplicando tipagens específicas, e, em seguida, executa um loop para extrair todos os arquivos listados ``(CSV_LIST)``, criando DataFrames em variáveis de acesso rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a900bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lendo Bronze: 100%|██████████| 9/9 [00:03<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_csv(filename: str, dtypes=None, parse_dates=None):\n",
    "    \"\"\"Carrega um CSV da Bronze, padroniza nomes das colunas (lower) e retorna DataFrame.\"\"\"\n",
    "    # 1. Encontra e verifica o caminho do arquivo no disco\n",
    "    path = RAW_DIR / filename\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"CSV não encontrado: {path}\")\n",
    "\n",
    "    # 2. LÊ o arquivo do disco para um DataFrame do Pandas (Extração Central)\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        dtype=dtypes or {},\n",
    "        parse_dates=parse_dates or [],\n",
    "        keep_default_na=True,\n",
    "        encoding=\"utf-8\",\n",
    "        # infer_datetime_format pode acelerar parsing em versões antigas do pandas,\n",
    "        # mas foi comentado antes por gerar barras duplicadas em alguns ambientes.\n",
    "        # infer_datetime_format=True, \n",
    "        low_memory=False,\n",
    "    )\n",
    "    # Padroniza nomes das colunas: remove espaços e coloca em lower-case (transformação) \n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "# ---------- load all ----------\n",
    "# Lista de CSVs esperados na pasta raw. \n",
    "CSV_LIST = [\n",
    "    \"olist_customers_dataset.csv\",\n",
    "    \"olist_geolocation_dataset.csv\",\n",
    "    \"olist_orders_dataset.csv\",\n",
    "    \"olist_order_items_dataset.csv\",\n",
    "    \"olist_order_payments_dataset.csv\",\n",
    "    \"olist_order_reviews_dataset.csv\",\n",
    "    \"olist_products_dataset.csv\",\n",
    "    \"olist_sellers_dataset.csv\",\n",
    "    \"product_category_name_translation.csv\",\n",
    "]\n",
    "\n",
    "# Safety: garantir que DTYPES e PARSE_DATES existam mesmo se o usuário executou células fora de ordem\n",
    "if 'DTYPES' not in globals():\n",
    "    print(\"[AVISO] DTYPES não encontrado. Definindo DTYPES = {} por segurança.\")\n",
    "    DTYPES = {}\n",
    "if 'PARSE_DATES' not in globals():\n",
    "    print(\"[AVISO] PARSE_DATES não encontrado. Definindo PARSE_DATES = {} por segurança.\")\n",
    "    PARSE_DATES = {}\n",
    "\n",
    "dfs = {}\n",
    "# 3. Itera sobre a lista e chama a função de leitura para extrair todos\n",
    "for name in tqdm(CSV_LIST, desc=\"Lendo Bronze\"):\n",
    "    dfs[name] = load_csv(\n",
    "        name,\n",
    "        dtypes=DTYPES.get(name),\n",
    "        parse_dates=PARSE_DATES.get(name),\n",
    "    )\n",
    "\n",
    "# 4. Cria aliases para os DataFrames extraídos\n",
    "customers   = dfs[\"olist_customers_dataset.csv\"]\n",
    "geos        = dfs[\"olist_geolocation_dataset.csv\"]\n",
    "orders      = dfs[\"olist_orders_dataset.csv\"]\n",
    "items       = dfs[\"olist_order_items_dataset.csv\"]\n",
    "payments    = dfs[\"olist_order_payments_dataset.csv\"]\n",
    "reviews     = dfs[\"olist_order_reviews_dataset.csv\"]\n",
    "products    = dfs[\"olist_products_dataset.csv\"]\n",
    "sellers     = dfs[\"olist_sellers_dataset.csv\"]\n",
    "prod_trans  = dfs[\"product_category_name_translation.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f31353-5f21-47e7-a40c-ade7191d8515",
   "metadata": {},
   "source": [
    "# TRANSFORM - Normalização para a Camada Silver\n",
    "\n",
    "- Padroniza strings, remove nulos críticos e duplicidades.\n",
    "- Enriquece `products` com tradução de categoria.\n",
    "- Garante integridade referencial: `items`, `payments` e `reviews` só com `order_id` válido; `items` só com `product_id`/`seller_id` válidos.\n",
    "- Agrega/geolocalização deduplicada por CEP prefixo.\n",
    "- Deriva campos úteis em `orders` (datas e métricas de entrega).\n",
    "- Cria dataframes finais: `silver_customers`, `silver_orders`, `silver_order_items`, `silver_products`, `silver_sellers`, `silver_payments`, `silver_reviews`, `silver_geolocation`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3822277",
   "metadata": {},
   "source": [
    "Definindo a função ``load_csv`` para leitura e padronização, e configura os dicionários ``(DTYPES, PARSE_DATES)`` que especificam os tipos de dados e colunas de data esperados para cada arquivo CSV, preparando as regras de transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0352d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename: str, dtypes=None, parse_dates=None):\n",
    "    \"\"\"Carrega um CSV da Bronze, padroniza nomes das colunas (lower) e retorna DataFrame.\"\"\"\n",
    "    path = RAW_DIR / filename\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"CSV não encontrado: {path}\")\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        dtype=dtypes or {},\n",
    "        parse_dates=parse_dates,\n",
    "        keep_default_na=True,\n",
    "        encoding=\"utf-8\",\n",
    "        infer_datetime_format=True,\n",
    "        low_memory=False,\n",
    "    )\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4868886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes por arquivo (usando tipos que aceitam NA quando necessário)\n",
    "Int = \"Int64\"  # inteiro com suporte a NA\n",
    "Str = \"string\"\n",
    "\n",
    "DTYPES = {\n",
    "    \"olist_orders_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"customer_id\": Str,\n",
    "        \"order_status\": Str,\n",
    "        # timestamps lidos via parse_dates\n",
    "    },\n",
    "    \"olist_order_items_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"order_item_id\": Int,\n",
    "        \"product_id\": Str,\n",
    "        \"seller_id\": Str,\n",
    "        \"price\": \"float64\",\n",
    "        \"freight_value\": \"float64\",\n",
    "        # shipping_limit_date via parse_dates\n",
    "    },\n",
    "    \"olist_order_payments_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"payment_sequential\": Int,\n",
    "        \"payment_type\": Str,\n",
    "        \"payment_installments\": Int,\n",
    "        \"payment_value\": \"float64\",\n",
    "    },\n",
    "    \"olist_order_reviews_dataset.csv\": {\n",
    "        \"review_id\": Str,\n",
    "        \"order_id\": Str,\n",
    "        \"review_score\": Int,\n",
    "        \"review_comment_title\": Str,\n",
    "        \"review_comment_message\": Str,\n",
    "        # creation/answer via parse_dates\n",
    "    },\n",
    "    \"olist_products_dataset.csv\": {\n",
    "        \"product_id\": Str,\n",
    "        \"product_category_name\": Str,\n",
    "        \"product_name_lenght\": Int,\n",
    "        \"product_description_lenght\": Int,\n",
    "        \"product_photos_qty\": Int,\n",
    "        \"product_weight_g\": Int,\n",
    "        \"product_length_cm\": Int,\n",
    "        \"product_height_cm\": Int,\n",
    "        \"product_width_cm\": Int,\n",
    "    },\n",
    "    \"olist_sellers_dataset.csv\": {\n",
    "        \"seller_id\": Str,\n",
    "        \"seller_zip_code_prefix\": Int,\n",
    "        \"seller_city\": Str,\n",
    "        \"seller_state\": Str,\n",
    "    },\n",
    "    \"olist_customers_dataset.csv\": {\n",
    "        \"customer_id\": Str,\n",
    "        \"customer_unique_id\": Str,\n",
    "        \"customer_zip_code_prefix\": Int,\n",
    "        \"customer_city\": Str,\n",
    "        \"customer_state\": Str,\n",
    "    },\n",
    "    \"olist_geolocation_dataset.csv\": {\n",
    "        \"geolocation_zip_code_prefix\": Int,\n",
    "        \"geolocation_lat\": \"float64\",\n",
    "        \"geolocation_lng\": \"float64\",\n",
    "        \"geolocation_city\": Str,\n",
    "        \"geolocation_state\": Str,\n",
    "    },\n",
    "    \"product_category_name_translation.csv\": {\n",
    "        \"product_category_name\": Str,\n",
    "        \"product_category_name_english\": Str,\n",
    "    },\n",
    "}\n",
    "\n",
    "PARSE_DATES = {\n",
    "    \"olist_orders_dataset.csv\": [\n",
    "        \"order_purchase_timestamp\",\n",
    "        \"order_approved_at\",\n",
    "        \"order_delivered_carrier_date\",\n",
    "        \"order_delivered_customer_date\",\n",
    "        \"order_estimated_delivery_date\",\n",
    "    ],\n",
    "    \"olist_order_items_dataset.csv\": [\n",
    "        \"shipping_limit_date\",\n",
    "    ],\n",
    "    \"olist_order_reviews_dataset.csv\": [\n",
    "        \"review_creation_date\",\n",
    "        \"review_answer_timestamp\",\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb2383",
   "metadata": {},
   "source": [
    "Exibindo o número de linhas e colunas (shape) de todos os DataFrames carregados e imprime o detalhe dos tipos de dados (dtypes) do DataFrame de orders, fornecendo uma visão rápida da estrutura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1397c914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Shapes\n",
      "olist_customers_dataset.csv              -> (99441, 5)\n",
      "olist_geolocation_dataset.csv            -> (1000163, 5)\n",
      "olist_orders_dataset.csv                 -> (99441, 8)\n",
      "olist_order_items_dataset.csv            -> (112650, 7)\n",
      "olist_order_payments_dataset.csv         -> (103886, 5)\n",
      "olist_order_reviews_dataset.csv          -> (99224, 7)\n",
      "olist_products_dataset.csv               -> (32951, 9)\n",
      "olist_sellers_dataset.csv                -> (3095, 4)\n",
      "product_category_name_translation.csv    -> (71, 2)\n",
      "\n",
      "# Dtypes (orders)\n",
      "order_id                         string[python]\n",
      "customer_id                      string[python]\n",
      "order_status                     string[python]\n",
      "order_purchase_timestamp         datetime64[ns]\n",
      "order_approved_at                datetime64[ns]\n",
      "order_delivered_carrier_date     datetime64[ns]\n",
      "order_delivered_customer_date    datetime64[ns]\n",
      "order_estimated_delivery_date    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ---------- quick summary: Shapes ----------\n",
    "print(\"\\n# Shapes\")\n",
    "for k, v in dfs.items():\n",
    "    print(f\"{k:40s} -> {v.shape}\")\n",
    "\n",
    "print(\"\\n# Dtypes (orders)\")\n",
    "print(orders.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c13ddf",
   "metadata": {},
   "source": [
    "Exibe as três primeiras linhas (head(3)) de alguns DataFrames principais (orders, items, payments) para uma inspeção visual rápida e validação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d761d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Amostras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "\n",
       "  order_status order_purchase_timestamp   order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37 2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49 2018-08-08 08:55:23   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0                    2017-10-18  \n",
       "1                    2018-08-13  \n",
       "2                    2018-09-04  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>shipping_limit_date</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>1</td>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
       "      <td>2017-09-19 09:45:35</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
       "      <td>1</td>\n",
       "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
       "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
       "      <td>2017-05-03 11:05:13</td>\n",
       "      <td>239.9</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
       "      <td>1</td>\n",
       "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
       "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
       "      <td>2018-01-18 14:48:30</td>\n",
       "      <td>199.0</td>\n",
       "      <td>17.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  order_item_id  \\\n",
       "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
       "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
       "2  000229ec398224ef6ca0657da4fc703e              1   \n",
       "\n",
       "                         product_id                         seller_id  \\\n",
       "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
       "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
       "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
       "\n",
       "  shipping_limit_date  price  freight_value  \n",
       "0 2017-09-19 09:45:35   58.9          13.29  \n",
       "1 2017-05-03 11:05:13  239.9          19.93  \n",
       "2 2018-01-18 14:48:30  199.0          17.87  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>payment_installments</th>\n",
       "      <th>payment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b81ef226f3fe1789b1e8b2acac839d17</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>8</td>\n",
       "      <td>99.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9810da82917af2d9aefd1278f1dcfa0</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>24.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25e8ea4e93396b6fa0d3dd708e76c1bd</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>65.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  payment_sequential payment_type  \\\n",
       "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
       "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
       "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
       "\n",
       "   payment_installments  payment_value  \n",
       "0                     8          99.33  \n",
       "1                     1          24.39  \n",
       "2                     1          65.71  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- quick summary: Amostras ----------\n",
    "print(\"\\n# Amostras\")\n",
    "display(orders.head(3))\n",
    "display(items.head(3))\n",
    "display(payments.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b332c0b",
   "metadata": {},
   "source": [
    "Define e executa a função ``na_overview`` para calcular e imprimir a contagem de valores ausentes (NAs) nas colunas dos DataFrames principais, identificando onde a limpeza de dados (Transformação) será necessária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1a898da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NA overview — orders\n",
      "order_delivered_customer_date    2965\n",
      "order_delivered_carrier_date     1783\n",
      "order_approved_at                 160\n",
      "dtype: int64\n",
      "\n",
      "NA overview — products\n",
      "product_category_name         610\n",
      "product_name_lenght           610\n",
      "product_description_lenght    610\n",
      "product_photos_qty            610\n",
      "product_weight_g                2\n",
      "product_length_cm               2\n",
      "product_height_cm               2\n",
      "product_width_cm                2\n",
      "dtype: int64\n",
      "\n",
      "NA overview — reviews\n",
      "review_comment_title      87656\n",
      "review_comment_message    58247\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# NAs por coluna (visão geral) — útil para planejar a transformação\n",
    "def na_overview(df, name):\n",
    "    s = df.isna().sum()\n",
    "    if (s > 0).any():\n",
    "        print(f\"\\nNA overview — {name}\")\n",
    "        print(s[s > 0].sort_values(ascending=False).head(12))\n",
    "\n",
    "na_overview(orders, \"orders\")\n",
    "na_overview(items, \"items\")\n",
    "na_overview(products, \"products\")\n",
    "na_overview(reviews, \"reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8b4a9",
   "metadata": {},
   "source": [
    "### Funções Auxiliares de Limpeza (Transformação)\n",
    "Define três funções auxiliares essenciais para a fase de Transformação: norm_str (padronização de texto), drop_nulls (remoção de linhas com valores nulos) e drop_dups (remoção de linhas duplicadas, reportando a contagem de linhas afetadas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a2bb16b-09dd-414c-a1d7-5afd77b81c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_str(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = (\n",
    "                df[c]\n",
    "                .astype(\"string\")\n",
    "                .str.strip()\n",
    "            )\n",
    "\n",
    "def drop_nulls(df, cols, name):\n",
    "    before = len(df)\n",
    "    df2 = df.dropna(subset=[c for c in cols if c in df.columns])\n",
    "    removed = before - len(df2)\n",
    "    if removed:\n",
    "        print(f\"[{name}] removidas {removed} linhas por nulos em {cols}\")\n",
    "    return df2\n",
    "\n",
    "def drop_dups(df, keys, name):\n",
    "    before = len(df)\n",
    "    df2 = df.drop_duplicates(subset=keys, keep=\"first\")\n",
    "    removed = before - len(df2)\n",
    "    if removed:\n",
    "        print(f\"[{name}] removidas {removed} duplicatas por {keys}\")\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6d673",
   "metadata": {},
   "source": [
    "### Limpeza e Transformação das Dimensões Mestre\n",
    "Aplica as funções de limpeza aos DataFrames de customers, sellers e geolocation (tabelas mestre/dimensão), garantindo que as chaves primárias não contenham nulos ou duplicatas, e realiza o merge para traduzir a categoria de products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1550e726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[geolocation] removidas 981148 duplicatas por ['geolocation_zip_code_prefix']\n"
     ]
    }
   ],
   "source": [
    "# ---------- Customers, Sellers, Geolocation (Limpeza Básica) ----------\n",
    "silver_customers = customers.copy()\n",
    "norm_str(silver_customers, [\"customer_id\",\"customer_unique_id\",\"customer_city\",\"customer_state\"])\n",
    "silver_customers = drop_nulls(silver_customers, [\"customer_id\"], \"customers\")\n",
    "silver_customers = drop_dups(silver_customers, [\"customer_id\"], \"customers\")\n",
    "\n",
    "silver_sellers = sellers.copy()\n",
    "norm_str(silver_sellers, [\"seller_id\",\"seller_city\",\"seller_state\"])\n",
    "silver_sellers = drop_nulls(silver_sellers, [\"seller_id\"], \"sellers\")\n",
    "silver_sellers = drop_dups(silver_sellers, [\"seller_id\"], \"sellers\")\n",
    "\n",
    "silver_geolocation = geos.copy()\n",
    "silver_geolocation = drop_nulls(silver_geolocation, [\"geolocation_zip_code_prefix\"], \"geolocation\")\n",
    "silver_geolocation = drop_dups(silver_geolocation, [\"geolocation_zip_code_prefix\"], \"geolocation\")\n",
    "\n",
    "# ---------- Products (+ tradução da categoria) ----------\n",
    "silver_products = products.copy()\n",
    "norm_str(silver_products, [\"product_id\",\"product_category_name\"])\n",
    "silver_products = silver_products.merge(\n",
    "    prod_trans, on=\"product_category_name\", how=\"left\"\n",
    ")\n",
    "silver_products = silver_products.rename(\n",
    "    columns={\"product_category_name_english\": \"product_category_en\"}\n",
    ")\n",
    "silver_products = drop_nulls(silver_products, [\"product_id\"], \"products\")\n",
    "silver_products = drop_dups(silver_products, [\"product_id\"], \"products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d201bc",
   "metadata": {},
   "source": [
    "### Transformação e Derivação de Pedidos (Orders)\n",
    "Limpa a tabela de orders e calcula métricas importantes de tempo de entrega, como o tempo total de delivery, o atraso em relação à estimativa e uma flag binária para indicar se o pedido foi entregue com atraso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "220279d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Orders (Limpeza e Derivados de Entrega) ----------\n",
    "silver_orders = orders.copy()\n",
    "norm_str(silver_orders, [\"order_id\",\"customer_id\",\"order_status\"])\n",
    "silver_orders = drop_nulls(silver_orders, [\"order_id\",\"customer_id\"], \"orders\")\n",
    "silver_orders = drop_dups(silver_orders, [\"order_id\"], \"orders\")\n",
    "\n",
    "# Garantir que colunas de data estão no tipo datetime (prevenindo AttributeError ao usar .dt)\n",
    "date_cols = [\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_approved_at\",\n",
    "    \"order_delivered_carrier_date\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\",\n",
    "]\n",
    "for c in date_cols:\n",
    "    if c in silver_orders.columns:\n",
    "        silver_orders[c] = pd.to_datetime(silver_orders[c], errors='coerce')\n",
    "\n",
    "# derivados úteis\n",
    "if \"order_purchase_timestamp\" in silver_orders.columns:\n",
    "    silver_orders[\"order_purchase_date\"] = silver_orders[\"order_purchase_timestamp\"].dt.date\n",
    "else:\n",
    "    silver_orders[\"order_purchase_date\"] = pd.NaT\n",
    "\n",
    "silver_orders[\"delivery_time_days\"] = (\n",
    "    silver_orders[\"order_delivered_customer_date\"] - silver_orders[\"order_purchase_timestamp\"]\n",
    ")\n",
    "# extrai dias e armazena como Int64 (suporta NA)\n",
    "silver_orders[\"delivery_time_days\"] = silver_orders[\"delivery_time_days\"].dt.days.astype(\"Int64\")\n",
    "\n",
    "silver_orders[\"delivery_delay_days\"] = (\n",
    "    silver_orders[\"order_delivered_customer_date\"] - silver_orders[\"order_estimated_delivery_date\"]\n",
    ")\n",
    "silver_orders[\"delivery_delay_days\"] = silver_orders[\"delivery_delay_days\"].dt.days.astype(\"Int64\")\n",
    "\n",
    "# flag binária indicando se foi entregue com atraso (1) ou não (0); trata NAs\n",
    "silver_orders[\"delivered_late\"] = (\n",
    "    (silver_orders[\"order_delivered_customer_date\"] > silver_orders[\"order_estimated_delivery_date\"]) \n",
    ")\n",
    "# converte para Int64 (1/0/NA)\n",
    "silver_orders[\"delivered_late\"] = silver_orders[\"delivered_late\"].astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6d3b6",
   "metadata": {},
   "source": [
    "### Integridade Referencial e Limpeza de Transações\n",
    "Garante a integridade dos dados ao filtrar as tabelas transacionais (items, payments, reviews), removendo registros que não possuem chaves válidas nas tabelas mestre recém-limpas (Silver), e aplica a limpeza final de nulos e duplicatas nessas tabelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ef7558b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reviews] removidas 814 duplicatas por ['review_id']\n"
     ]
    }
   ],
   "source": [
    "# ---------- Itens, Pagamentos, Avaliações (Integridade Referencial) ----------\n",
    "valid_orders = set(silver_orders[\"order_id\"])\n",
    "valid_products = set(silver_products[\"product_id\"])\n",
    "valid_sellers  = set(silver_sellers[\"seller_id\"])\n",
    "\n",
    "# Items\n",
    "silver_order_items = items.copy()\n",
    "norm_str(silver_order_items, [\"order_id\",\"product_id\",\"seller_id\"])\n",
    "silver_order_items = drop_nulls(silver_order_items, [\"order_id\",\"order_item_id\",\"product_id\",\"seller_id\"], \"order_items\")\n",
    "silver_order_items = silver_order_items[\n",
    "    silver_order_items[\"order_id\"].isin(valid_orders)\n",
    "    & silver_order_items[\"product_id\"].isin(valid_products)\n",
    "    & silver_order_items[\"seller_id\"].isin(valid_sellers)\n",
    "].copy()\n",
    "silver_order_items = drop_dups(silver_order_items, [\"order_id\",\"order_item_id\"], \"order_items\")\n",
    "\n",
    "# Payments\n",
    "silver_payments = payments.copy()\n",
    "norm_str(silver_payments, [\"order_id\",\"payment_type\"])\n",
    "silver_payments = drop_nulls(silver_payments, [\"order_id\"], \"payments\")\n",
    "silver_payments = silver_payments[silver_payments[\"order_id\"].isin(valid_orders)].copy()\n",
    "\n",
    "# Reviews\n",
    "silver_reviews = reviews.copy()\n",
    "norm_str(silver_reviews, [\"review_id\",\"order_id\"])\n",
    "silver_reviews = drop_nulls(silver_reviews, [\"review_id\",\"order_id\"], \"reviews\")\n",
    "silver_reviews = silver_reviews[silver_reviews[\"order_id\"].isin(valid_orders)].copy()\n",
    "silver_reviews = drop_dups(silver_reviews, [\"review_id\"], \"reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88579bb3",
   "metadata": {},
   "source": [
    "### Sanity Check Final da Camada Silver\n",
    "Exibe um resumo final da estrutura (shape) e amostras dos DataFrames recém-criados e limpos da camada Silver, confirmando que a Transformação foi concluída com sucesso e os dados estão prontos para a fase de Carregamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41d70ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resumo de Shapes da Camada Silver:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linhas</th>\n",
       "      <th>Colunas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>silver_customers</th>\n",
       "      <td>99441</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_sellers</th>\n",
       "      <td>3095</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_products</th>\n",
       "      <td>32951</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_geolocation</th>\n",
       "      <td>19015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_orders</th>\n",
       "      <td>99441</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_order_items</th>\n",
       "      <td>112650</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_payments</th>\n",
       "      <td>103886</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_reviews</th>\n",
       "      <td>98410</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Linhas  Colunas\n",
       "silver_customers     99441        5\n",
       "silver_sellers        3095        4\n",
       "silver_products      32951       10\n",
       "silver_geolocation   19015        5\n",
       "silver_orders        99441       12\n",
       "silver_order_items  112650        7\n",
       "silver_payments     103886        5\n",
       "silver_reviews       98410        7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crie o dicionário de resumo dos shapes\n",
    "summary = {\n",
    "    \"silver_customers\": silver_customers.shape,\n",
    "    \"silver_sellers\": silver_sellers.shape,\n",
    "    \"silver_products\": silver_products.shape,\n",
    "    \"silver_geolocation\": silver_geolocation.shape,\n",
    "    \"silver_orders\": silver_orders.shape,\n",
    "    \"silver_order_items\": silver_order_items.shape,\n",
    "    \"silver_payments\": silver_payments.shape,\n",
    "    \"silver_reviews\": silver_reviews.shape,\n",
    "}\n",
    "\n",
    "# Converte o dicionário em um DataFrame para exibição tabular\n",
    "summary_df = pd.DataFrame(\n",
    "    summary.values(), \n",
    "    index=summary.keys(), \n",
    "    columns=[\"Linhas\", \"Colunas\"]\n",
    ")\n",
    "\n",
    "# Título do Resumo\n",
    "print(\"✅ Resumo de Shapes da Camada Silver:\")\n",
    "\n",
    "# Exibe o DataFrame de resumo\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f65a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae6f195a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostras da Camada Silver ---\n",
      "\n",
      "silver_orders (Pedidos):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>order_purchase_date</th>\n",
       "      <th>delivery_time_days</th>\n",
       "      <th>delivery_delay_days</th>\n",
       "      <th>delivered_late</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>8</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>13</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>9</td>\n",
       "      <td>-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "\n",
       "  order_status order_purchase_timestamp   order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37 2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49 2018-08-08 08:55:23   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "\n",
       "  order_estimated_delivery_date order_purchase_date  delivery_time_days  \\\n",
       "0                    2017-10-18          2017-10-02                   8   \n",
       "1                    2018-08-13          2018-07-24                  13   \n",
       "2                    2018-09-04          2018-08-08                   9   \n",
       "\n",
       "   delivery_delay_days  delivered_late  \n",
       "0                   -8               0  \n",
       "1                   -6               0  \n",
       "2                  -18               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "silver_order_items (Itens de Pedido):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>shipping_limit_date</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>1</td>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
       "      <td>2017-09-19 09:45:35</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
       "      <td>1</td>\n",
       "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
       "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
       "      <td>2017-05-03 11:05:13</td>\n",
       "      <td>239.9</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
       "      <td>1</td>\n",
       "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
       "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
       "      <td>2018-01-18 14:48:30</td>\n",
       "      <td>199.0</td>\n",
       "      <td>17.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  order_item_id  \\\n",
       "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
       "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
       "2  000229ec398224ef6ca0657da4fc703e              1   \n",
       "\n",
       "                         product_id                         seller_id  \\\n",
       "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
       "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
       "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
       "\n",
       "  shipping_limit_date  price  freight_value  \n",
       "0 2017-09-19 09:45:35   58.9          13.29  \n",
       "1 2017-05-03 11:05:13  239.9          19.93  \n",
       "2 2018-01-18 14:48:30  199.0          17.87  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "silver_products (Produtos):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "      <th>product_category_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>40</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>perfumery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>artes</td>\n",
       "      <td>44</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96bd76ec8810374ed1b65e291975717f</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>46</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>sports_leisure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id product_category_name  \\\n",
       "0  1e9e8ef04dbcff4541ed26657ea517e5            perfumaria   \n",
       "1  3aa071139cb16b67ca9e5dea641aaa2f                 artes   \n",
       "2  96bd76ec8810374ed1b65e291975717f         esporte_lazer   \n",
       "\n",
       "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
       "0                   40                         287                   1   \n",
       "1                   44                         276                   1   \n",
       "2                   46                         250                   1   \n",
       "\n",
       "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \\\n",
       "0               225                 16                 10                14   \n",
       "1              1000                 30                 18                20   \n",
       "2               154                 18                  9                15   \n",
       "\n",
       "  product_category_en  \n",
       "0           perfumery  \n",
       "1                 art  \n",
       "2      sports_leisure  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Amostras da Camada Silver ---\")\n",
    "\n",
    "print(\"\\nsilver_orders (Pedidos):\")\n",
    "display(silver_orders.head(3))\n",
    "\n",
    "print(\"\\nsilver_order_items (Itens de Pedido):\")\n",
    "display(silver_order_items.head(3))\n",
    "\n",
    "print(\"\\nsilver_products (Produtos):\")\n",
    "display(silver_products.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b6b63",
   "metadata": {},
   "source": [
    "# LOAD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ea881-d70a-445f-9d42-c32840b767e8",
   "metadata": {},
   "source": [
    "## Conectar e aplicar o DDL\n",
    "\n",
    "Esta célula configura a conexão com o banco de dados PostgreSQL lendo credenciais de um arquivo .env ou usando defaults, tenta se conectar, garante que o esquema DL (Data Layer) exista e, se o arquivo DDL for encontrado, executa os comandos SQL para criar a estrutura da tabela única ORDER_ITEMS, preparando o banco para receber os dados limpos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6bc8762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates to test: [5435, 5432, 5434, 5436]\n",
      "✖ port 5435: OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5435 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n",
      "✖ port 5432: OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n",
      "connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n",
      "\n",
      "✖ port 5434: OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5434 failed: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n",
      "✖ port 5436: OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5436 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n",
      "\n",
      "No successful connection using provided credentials and tried ports.\n",
      "If you expect a Docker container to expose Postgres, check `docker ps` and `docker logs` and/or fix port mapping in docker-compose.yml.\n"
     ]
    }
   ],
   "source": [
    "# Connection test — tenta detectar a porta PG funcional e ajusta PGPORT para as próximas células\n",
    "# Esta célula tenta se conectar via psycopg2 em uma lista de portas candidatas\n",
    "import os\n",
    "from pathlib import Path\n",
    "import psycopg2\n",
    "\n",
    "# Recarrega .env leve (se existir)\n",
    "ENV_PATH = PROJECT_ROOT / '.env'\n",
    "if ENV_PATH.exists():\n",
    "    for line in ENV_PATH.read_text(encoding='utf-8').splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#') or '=' not in line:\n",
    "            continue\n",
    "        k, v = line.split('=', 1)\n",
    "        os.environ.setdefault(k.strip(), v.strip())\n",
    "\n",
    "candidates = []\n",
    "env_port = os.getenv('PGPORT')\n",
    "if env_port:\n",
    "    try:\n",
    "        candidates.append(int(env_port))\n",
    "    except ValueError:\n",
    "        pass\n",
    "# common ports to try (preserves order)\n",
    "for p in (5435, 5432, 5434, 5436):\n",
    "    if p not in candidates:\n",
    "        candidates.append(p)\n",
    "\n",
    "DB_HOST = os.getenv('PGHOST', 'localhost')\n",
    "DB_NAME = os.getenv('PGDATABASE', 'olist')\n",
    "DB_USER = os.getenv('PGUSER', 'postgres')\n",
    "DB_PASS = os.getenv('PGPASSWORD', 'postgres')\n",
    "\n",
    "print('Candidates to test:', candidates)\n",
    "\n",
    "def try_connect(port, timeout=3):\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=DB_HOST, port=port, dbname=DB_NAME, user=DB_USER, password=DB_PASS, connect_timeout=timeout)\n",
    "        conn.close()\n",
    "        return True, None\n",
    "    except Exception as e:\n",
    "        return False, e\n",
    "\n",
    "success = None\n",
    "for port in candidates:\n",
    "    ok, err = try_connect(port)\n",
    "    if ok:\n",
    "        print(f'✅ Connection successful on port {port} (host={DB_HOST}, db={DB_NAME}, user={DB_USER})')\n",
    "        os.environ['PGPORT'] = str(port)\n",
    "        DB_PORT = str(port)\n",
    "        success = port\n",
    "        break\n",
    "    else:\n",
    "        print(f'✖ port {port}: {type(err).__name__}: {err}')\n",
    "\n",
    "if success is None:\n",
    "    print('\\nNo successful connection using provided credentials and tried ports.')\n",
    "    print('If you expect a Docker container to expose Postgres, check `docker ps` and `docker logs` and/or fix port mapping in docker-compose.yml.')\n",
    "else:\n",
    "    print('\\nSet PGPORT to', success, 'for subsequent cells. You can re-run the LOAD cell now.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07e7a5dc-8f72-45f5-9e9d-2b8859b2db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Tentando conectar…\n",
      "Conectado! -> ('olist', 'public', 'PostgreSQL 16.10 (Debian 16.10-1.pgdg13+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit')\n",
      "→ Executando DDL de DDL.sql (tamanho ~1797 bytes)…\n",
      "✅ DDL aplicado.\n"
     ]
    }
   ],
   "source": [
    "# 2.6.1 — Conectar no Postgres e aplicar o DDL (Data Layer)\n",
    "# Reusa PROJECT_ROOT, DDL_PATH, etc. já definidos antes\n",
    "ENV_PATH = PROJECT_ROOT / \".env\"\n",
    "if ENV_PATH.exists():\n",
    "    for line in ENV_PATH.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "            continue\n",
    "        k, v = line.split(\"=\", 1)\n",
    "        os.environ.setdefault(k.strip(), v.strip())\n",
    "\n",
    "DB_HOST   = os.getenv(\"PGHOST\", \"localhost\")\n",
    "DB_PORT   = os.getenv(\"PGPORT\", \"5433\")\n",
    "DB_NAME   = os.getenv(\"PGDATABASE\", \"olist\")\n",
    "DB_USER   = os.getenv(\"PGUSER\", \"postgres\")\n",
    "DB_PASS   = os.getenv(\"PGPASSWORD\", \"postgres\")\n",
    "DB_SCHEMA = os.getenv(\"PGSCHEMA\", \"DL\")   # Data Layer (DL)\n",
    "\n",
    "db_url = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(db_url, pool_pre_ping=True, future=True)\n",
    "\n",
    "print(\"→ Tentando conectar…\")\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        row = conn.exec_driver_sql(\"select current_database(), current_schema(), version();\").fetchone()\n",
    "        print(\"Conectado! ->\", row)\n",
    "\n",
    "        # Garante o schema Silver e seta o search_path\n",
    "        conn.exec_driver_sql(f'CREATE SCHEMA IF NOT EXISTS \"{DB_SCHEMA}\";')\n",
    "        conn.exec_driver_sql(f'SET search_path TO \"{DB_SCHEMA}\", public;')\n",
    "\n",
    "        # Executa o DDL do Pablo (se existir)\n",
    "        if DDL_PATH.exists():\n",
    "            sql = DDL_PATH.read_text(encoding=\"utf-8\").strip()\n",
    "            print(f\"→ Executando DDL de {DDL_PATH.name} (tamanho ~{DDL_PATH.stat().st_size} bytes)…\")\n",
    "            conn.exec_driver_sql(sql)\n",
    "            print(\"✅ DDL aplicado.\")\n",
    "        else:\n",
    "            print(\"⚠️ DDL não encontrado — seguiremos com to_sql para criar as tabelas.\")\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(\"\\n[AVISO] Não foi possível conectar ao Postgres agora. Detalhe do erro:\")\n",
    "    print(type(e).__name__, str(e))\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34ba949e-baf8-46cf-bc62-b6f099589307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela unificada criada: 112,952 linhas, 41 colunas\n",
      "   Colunas: order_item_id, product_id, seller_id, order_id, shipping_limit_date... (41 total)\n"
     ]
    }
   ],
   "source": [
    "# 2.5 — Build single unified table for DL (Data Layer)\n",
    "\n",
    "# Payments aggregated per order (matching DDL.sql structure)\n",
    "payments_agg = (\n",
    "    silver_payments\n",
    "    .groupby(\"order_id\", as_index=False)\n",
    "    .agg(\n",
    "        qtd_payment_sequential=(\"payment_sequential\", \"count\"),\n",
    "        primeiro_payment_type=(\"payment_type\", \"first\"),\n",
    "        valor_total_pagamento=(\"payment_value\", \"sum\"),\n",
    "        maximo_payment_installments=(\"payment_installments\", \"max\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Get geolocation for sellers (by zip_code_prefix)\n",
    "seller_geo = (\n",
    "    silver_geolocation\n",
    "    .groupby(\"geolocation_zip_code_prefix\", as_index=False)\n",
    "    .agg(\n",
    "        vendedor_geolocation_lat=(\"geolocation_lat\", \"first\"),\n",
    "        vendedor_geolocation_lng=(\"geolocation_lng\", \"first\")\n",
    "    )\n",
    "    .rename(columns={\"geolocation_zip_code_prefix\": \"seller_zip_code_prefix\"})\n",
    ")\n",
    "\n",
    "# Get geolocation for customers (by zip_code_prefix)\n",
    "customer_geo = (\n",
    "    silver_geolocation\n",
    "    .groupby(\"geolocation_zip_code_prefix\", as_index=False)\n",
    "    .agg(\n",
    "        cliente_geolocation_lat=(\"geolocation_lat\", \"first\"),\n",
    "        cliente_geolocation_lng=(\"geolocation_lng\", \"first\")\n",
    "    )\n",
    "    .rename(columns={\"geolocation_zip_code_prefix\": \"customer_zip_code_prefix\"})\n",
    ")\n",
    "\n",
    "# Build unified table by joining all normalized Silver tables\n",
    "# Starting from order_items as base (one row per item)\n",
    "dl_order_items = (\n",
    "    silver_order_items\n",
    "    # Join orders\n",
    "    .merge(\n",
    "        silver_orders[[\n",
    "            \"order_id\", \"customer_id\", \"order_status\",\n",
    "            \"order_purchase_timestamp\", \"order_approved_at\",\n",
    "            \"order_delivered_carrier_date\", \"order_delivered_customer_date\",\n",
    "            \"order_estimated_delivery_date\"\n",
    "        ]],\n",
    "        on=\"order_id\", how=\"left\"\n",
    "    )\n",
    "    # Join products\n",
    "    .merge(\n",
    "        silver_products[[\n",
    "            \"product_id\", \"product_category_name\",\n",
    "            \"product_name_lenght\", \"product_description_lenght\",\n",
    "            \"product_photos_qty\", \"product_weight_g\",\n",
    "            \"product_length_cm\", \"product_height_cm\", \"product_width_cm\"\n",
    "        ]],\n",
    "        on=\"product_id\", how=\"left\"\n",
    "    )\n",
    "    # Join customers\n",
    "    .merge(\n",
    "        silver_customers[[\n",
    "            \"customer_id\", \"customer_unique_id\",\n",
    "            \"customer_zip_code_prefix\", \"customer_city\", \"customer_state\"\n",
    "        ]],\n",
    "        on=\"customer_id\", how=\"left\"\n",
    "    )\n",
    "    # Join sellers\n",
    "    .merge(\n",
    "        silver_sellers[[\n",
    "            \"seller_id\", \"seller_zip_code_prefix\",\n",
    "            \"seller_city\", \"seller_state\"\n",
    "        ]],\n",
    "        on=\"seller_id\", how=\"left\"\n",
    "    )\n",
    "    # Join payments aggregated\n",
    "    .merge(\n",
    "        payments_agg, on=\"order_id\", how=\"left\"\n",
    "    )\n",
    "    # Join reviews (one review per order, so we can merge on order_id)\n",
    "    .merge(\n",
    "        silver_reviews[[\n",
    "            \"order_id\", \"review_score\", \"review_comment_title\",\n",
    "            \"review_comment_message\", \"review_creation_date\", \"review_answer_timestamp\"\n",
    "        ]],\n",
    "        on=\"order_id\", how=\"left\"\n",
    "    )\n",
    "    # Join seller geolocation\n",
    "    .merge(\n",
    "        seller_geo, on=\"seller_zip_code_prefix\", how=\"left\"\n",
    "    )\n",
    "    # Join customer geolocation\n",
    "    .merge(\n",
    "        customer_geo, on=\"customer_zip_code_prefix\", how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ensure order_item_id is string (as per DDL: VARCHAR(255))\n",
    "dl_order_items[\"order_item_id\"] = dl_order_items[\"order_item_id\"].astype(str)\n",
    "\n",
    "# Select and order columns to match DDL.sql structure\n",
    "final_cols = [\n",
    "    \"order_item_id\",\n",
    "    \"product_id\",\n",
    "    \"seller_id\",\n",
    "    \"order_id\",\n",
    "    \"shipping_limit_date\",\n",
    "    \"price\",\n",
    "    \"freight_value\",\n",
    "    \"product_category_name\",\n",
    "    \"product_name_lenght\",\n",
    "    \"product_description_lenght\",\n",
    "    \"product_photos_qty\",\n",
    "    \"product_weight_g\",\n",
    "    \"product_length_cm\",\n",
    "    \"product_height_cm\",\n",
    "    \"product_width_cm\",\n",
    "    \"seller_zip_code_prefix\",\n",
    "    \"seller_city\",\n",
    "    \"seller_state\",\n",
    "    \"vendedor_geolocation_lat\",\n",
    "    \"vendedor_geolocation_lng\",\n",
    "    \"review_comment_title\",\n",
    "    \"review_comment_message\",\n",
    "    \"customer_unique_id\",\n",
    "    \"order_status\",\n",
    "    \"qtd_payment_sequential\",\n",
    "    \"primeiro_payment_type\",\n",
    "    \"valor_total_pagamento\",\n",
    "    \"maximo_payment_installments\",\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_approved_at\",\n",
    "    \"order_delivered_carrier_date\",\n",
    "    \"order_estimated_delivery_date\",\n",
    "    \"review_score\",\n",
    "    \"review_creation_date\",\n",
    "    \"review_answer_timestamp\",\n",
    "    \"customer_zip_code_prefix\",\n",
    "    \"customer_city\",\n",
    "    \"customer_state\",\n",
    "    \"cliente_geolocation_lat\",\n",
    "    \"cliente_geolocation_lng\",\n",
    "]\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "dl_order_items = dl_order_items[[c for c in final_cols if c in dl_order_items.columns]].copy()\n",
    "\n",
    "print(f\"✅ Tabela unificada criada: {len(dl_order_items):,} linhas, {len(dl_order_items.columns)} colunas\")\n",
    "print(f\"   Colunas: {', '.join(dl_order_items.columns[:5])}... ({len(dl_order_items.columns)} total)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab75375-5132-48b4-8e44-071373e15c8b",
   "metadata": {},
   "source": [
    "## Load para DL (Data Layer) - Tabela única ORDER_ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a409ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando carga da tabela única ORDER_ITEMS no schema DL ---\n",
      "→ ORDER_ITEMS: 112,952 linhas carregadas no schema DL.\n",
      "✅ Carga concluída.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Iniciando carga da tabela única ORDER_ITEMS no schema DL ---\")\n",
    "\n",
    "if \"engine\" not in globals():\n",
    "    raise RuntimeError(\"Engine SQLAlchemy não inicializado. Execute a célula de conexão antes desta.\")\n",
    "if \"dl_order_items\" not in globals():\n",
    "    raise RuntimeError(\"DataFrame dl_order_items não encontrado. Execute as etapas de transformação antes da carga.\")\n",
    "\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        # Set search path to DL schema\n",
    "        conn.exec_driver_sql(f'SET search_path TO \"{DB_SCHEMA}\", public;')\n",
    "        \n",
    "        # Load single unified table ORDER_ITEMS\n",
    "        dl_order_items.to_sql(\n",
    "            \"ORDER_ITEMS\",\n",
    "            conn,\n",
    "            schema=DB_SCHEMA,\n",
    "            if_exists=\"replace\",\n",
    "            index=False,\n",
    "            method=\"multi\",\n",
    "            chunksize=1000,\n",
    "        )\n",
    "        print(f\"→ ORDER_ITEMS: {len(dl_order_items):,} linhas carregadas no schema {DB_SCHEMA}.\")\n",
    "    print(\"✅ Carga concluída.\")\n",
    "except Exception as exc:\n",
    "    print(\"❌ Falha ao carregar dados no Postgres:\", exc)\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
