{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "994378db",
   "metadata": {},
   "source": [
    "# **ETL da raw para a silver**\n",
    "\n",
    "Esse notebook ira realisar o ETL, um processo de três etapas — Extrair, Transformar e Carregar, usado para integrar dados de diferentes fontes em um único dat warehouse. \n",
    "Essa metodologia combina dados, limpando-os e organizando-os para análise, relatórios e tomada de decisões de negócios. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e93aba",
   "metadata": {},
   "source": [
    "A célula abaixo instala as bibliotecas Python necessárias (como Pandas para dados e SQLAlchemy para banco de dados) no ambiente do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89fe51c8-087b-485c-8927-f8db19b60ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pandas sqlalchemy psycopg2-binary python-dotenv pyarrow tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd00a6a",
   "metadata": {},
   "source": [
    "#### Importando as Bibliotecas necessarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f552dc-7cb7-4a16-9c47-defefc98afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK imports\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "print(\"OK imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7911eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Configuração de schema e função utilitária para leitura ----------\n",
    "Int = \"Int64\"  # inteiros que aceitam NA\n",
    "Str = \"string\"\n",
    "\n",
    "DTYPES = {\n",
    "    \"olist_orders_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"customer_id\": Str,\n",
    "        \"order_status\": Str,\n",
    "    },\n",
    "    \"olist_order_items_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"order_item_id\": Int,\n",
    "        \"product_id\": Str,\n",
    "        \"seller_id\": Str,\n",
    "        \"price\": \"float64\",\n",
    "        \"freight_value\": \"float64\",\n",
    "    },\n",
    "    \"olist_order_payments_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"payment_sequential\": Int,\n",
    "        \"payment_type\": Str,\n",
    "        \"payment_installments\": Int,\n",
    "        \"payment_value\": \"float64\",\n",
    "    },\n",
    "    \"olist_order_reviews_dataset.csv\": {\n",
    "        \"review_id\": Str,\n",
    "        \"order_id\": Str,\n",
    "        \"review_score\": Int,\n",
    "        \"review_comment_title\": Str,\n",
    "        \"review_comment_message\": Str,\n",
    "    },\n",
    "    \"olist_products_dataset.csv\": {\n",
    "        \"product_id\": Str,\n",
    "        \"product_category_name\": Str,\n",
    "        \"product_name_lenght\": Int,\n",
    "        \"product_description_lenght\": Int,\n",
    "        \"product_photos_qty\": Int,\n",
    "        \"product_weight_g\": Int,\n",
    "        \"product_length_cm\": Int,\n",
    "        \"product_height_cm\": Int,\n",
    "        \"product_width_cm\": Int,\n",
    "    },\n",
    "    \"olist_sellers_dataset.csv\": {\n",
    "        \"seller_id\": Str,\n",
    "        \"seller_zip_code_prefix\": Int,\n",
    "        \"seller_city\": Str,\n",
    "        \"seller_state\": Str,\n",
    "    },\n",
    "    \"olist_customers_dataset.csv\": {\n",
    "        \"customer_id\": Str,\n",
    "        \"customer_unique_id\": Str,\n",
    "        \"customer_zip_code_prefix\": Int,\n",
    "        \"customer_city\": Str,\n",
    "        \"customer_state\": Str,\n",
    "    },\n",
    "    \"olist_geolocation_dataset.csv\": {\n",
    "        \"geolocation_zip_code_prefix\": Int,\n",
    "        \"geolocation_lat\": \"float64\",\n",
    "        \"geolocation_lng\": \"float64\",\n",
    "        \"geolocation_city\": Str,\n",
    "        \"geolocation_state\": Str,\n",
    "    },\n",
    "    \"product_category_name_translation.csv\": {\n",
    "        \"product_category_name\": Str,\n",
    "        \"product_category_name_english\": Str,\n",
    "    },\n",
    "}\n",
    "\n",
    "PARSE_DATES = {\n",
    "    \"olist_orders_dataset.csv\": [\n",
    "        \"order_purchase_timestamp\",\n",
    "        \"order_approved_at\",\n",
    "        \"order_delivered_carrier_date\",\n",
    "        \"order_delivered_customer_date\",\n",
    "        \"order_estimated_delivery_date\",\n",
    "    ],\n",
    "    \"olist_order_items_dataset.csv\": [\n",
    "        \"shipping_limit_date\",\n",
    "    ],\n",
    "    \"olist_order_reviews_dataset.csv\": [\n",
    "        \"review_creation_date\",\n",
    "        \"review_answer_timestamp\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "def load_csv(filename: str, dtypes=None, parse_dates=None):\n",
    "    \"\"\"Carrega um CSV da Bronze, padroniza nomes das colunas (lower) e retorna DataFrame.\"\"\"\n",
    "    path = RAW_DIR / filename\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"CSV não encontrado: {path}\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        dtype=dtypes or {},\n",
    "        parse_dates=parse_dates,\n",
    "        keep_default_na=True,\n",
    "        encoding=\"utf-8\",\n",
    "        infer_datetime_format=True,\n",
    "        low_memory=False,\n",
    "    )\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e172ba",
   "metadata": {},
   "source": [
    "A célula abaixo encontra a pasta raiz do projeto buscando por data_layer, define os caminhos importantes (raw, sql), e verifica se os dados brutos (raw e o arquivo de pedidos) existem e podem ser lidos, exibindo as 5 primeiras linhas como prova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f88701a-9b73-4be3-866d-0f4062b39dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/oem/Documentos/FGA/SBD2/SenTry/brazilian_e-commerce_analysis/Transfomer\n",
      "PROJECT_ROOT: /home/oem/Documentos/FGA/SBD2/SenTry/brazilian_e-commerce_analysis\n",
      "RAW_DIR: /home/oem/Documentos/FGA/SBD2/SenTry/brazilian_e-commerce_analysis/data_layer/raw\n",
      "DDL_PATH: /home/oem/Documentos/FGA/SBD2/SenTry/brazilian_e-commerce_analysis/data_layer/silver/DDL.sql\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  \n",
       "3           2017-12-15 00:00:00  \n",
       "4           2018-02-26 00:00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bronze encontrada e legível.\n"
     ]
    }
   ],
   "source": [
    "# 1) Detectar automaticamente a raiz que contém \"data_layer\"\n",
    "CWD = Path.cwd()\n",
    "PROJECT_ROOT = None\n",
    "for candidate in [CWD, *CWD.parents]:\n",
    "    if (candidate / \"data_layer\").exists():\n",
    "        PROJECT_ROOT = candidate\n",
    "        break\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        f'Não achei a pasta \"data_layer\" a partir de {CWD}. '\n",
    "        f'Abra o notebook a partir do repositório ou mova este .ipynb para dentro dele.'\n",
    "    )\n",
    "\n",
    "# 2) Recalcular caminhos com base na raiz correta\n",
    "RAW_DIR = PROJECT_ROOT / \"data_layer\" /  \"raw\"\n",
    "# CORREÇÃO AQUI:\n",
    "DDL_PATH = PROJECT_ROOT / \"data_layer\" / \"silver\" / \"DDL.sql\"\n",
    "\n",
    "print(\"CWD:\", CWD)\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"DDL_PATH:\", DDL_PATH)\n",
    "\n",
    "# 3) Validar que CSVs existem e sao kegiveis\n",
    "assert RAW_DIR.exists(), f\"Pasta Bronze (raw) não encontrada: {RAW_DIR}\"\n",
    "\n",
    "# 4) Checagem mínima: tentar ler 5 linhas do orders\n",
    "orders_csv = RAW_DIR / \"olist_orders_dataset.csv\"\n",
    "assert orders_csv.exists(), f\"Arquivo esperado não encontrado: {orders_csv}\"\n",
    "display(pd.read_csv(orders_csv, nrows=5).head())\n",
    "print(\"✅ Bronze encontrada e legível.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30271ba7-c704-46ab-a20d-e35e97c2b605",
   "metadata": {},
   "source": [
    "## DB Config & Connection Test\n",
    "\n",
    "- Lê variáveis do `.env` (se existir) ou usa defaults locais.\n",
    "- Testa conexão, cria o schema `silver` (se não existir) e ajusta `search_path`.\n",
    "- Não falha o notebook se o Postgres não estiver no ar apenas avisa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a84d7eb-56ae-4373-8b93-307c1d7c98fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_HOST: localhost | DB_PORT: 5432 | DB_NAME: olist | SCHEMA: silver\n",
      "\n",
      "[AVISO] Não foi possível conectar ao Postgres agora.\n",
      "→ Motivos comuns: container não iniciado ou credenciais/DB diferentes.\n",
      "→ Quando o Levi subir o docker-compose, esta célula deve funcionar.\n",
      "Detalhe do erro: OperationalError('(psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\\n')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from contextlib import suppress\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# 1) Carregar .env se existir (opcional)\n",
    "ENV_PATH = PROJECT_ROOT / \".env\"\n",
    "if ENV_PATH.exists():\n",
    "    # carregamento leve do .env (sem dependências)\n",
    "    with open(ENV_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "                continue\n",
    "            k, v = line.split(\"=\", 1)\n",
    "            os.environ.setdefault(k.strip(), v.strip())\n",
    "\n",
    "# 2) Variáveis de conexão (use as que o Levi definir; estas são defaults comuns)\n",
    "DB_HOST   = os.getenv(\"PGHOST\", \"localhost\")\n",
    "DB_PORT   = os.getenv(\"PGPORT\", \"5432\")\n",
    "DB_NAME   = os.getenv(\"PGDATABASE\", \"olist\")\n",
    "DB_USER   = os.getenv(\"PGUSER\", \"postgres\")\n",
    "DB_PASS   = os.getenv(\"PGPASSWORD\", \"postgres\")\n",
    "DB_SCHEMA = os.getenv(\"PGSCHEMA\", \"silver\")   # camada Silver\n",
    "\n",
    "print(\"DB_HOST:\", DB_HOST, \"| DB_PORT:\", DB_PORT, \"| DB_NAME:\", DB_NAME, \"| SCHEMA:\", DB_SCHEMA)\n",
    "\n",
    "# 3) Criar engine SQLAlchemy\n",
    "db_url = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(db_url, pool_pre_ping=True, future=True)\n",
    "\n",
    "# 4) Teste de conexão e criação do schema\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        row = conn.exec_driver_sql(\"select current_database(), current_schema(), version();\").fetchone()\n",
    "        print(\"Conectado! ->\", row)\n",
    "\n",
    "        # cria schema silver se não existir e seta o search_path\n",
    "        conn.exec_driver_sql(f'CREATE SCHEMA IF NOT EXISTS \"{DB_SCHEMA}\";')\n",
    "        conn.exec_driver_sql(f'SET search_path TO \"{DB_SCHEMA}\", public;')\n",
    "\n",
    "        # checar DDL\n",
    "        if DDL_PATH.exists():\n",
    "            print(f\"DDL localizado em: {DDL_PATH} (tamanho ~{DDL_PATH.stat().st_size} bytes)\")\n",
    "        else:\n",
    "            print(\"[AVISO] DDL não encontrado ainda — ok, seguimos com ETL e executamos depois.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n[AVISO] Não foi possível conectar ao Postgres agora.\")\n",
    "    print(\"→ Motivos comuns: container não iniciado ou credenciais/DB diferentes.\")\n",
    "    print(\"→ Quando o Levi subir o docker-compose, esta célula deve funcionar.\")\n",
    "    print(\"Detalhe do erro:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f450e61-b9b8-406d-92a0-5b3930771b9f",
   "metadata": {},
   "source": [
    "# EXTRACT — Ler dados da Bronze\n",
    "\n",
    "- Carrega todos os CSVs de `olist-ecommerce-pipeline/data/raw`.\n",
    "- Define dtypes explícitos e faz *parse* de datas.\n",
    "- Exibe *shape*, tipos e amostra de linhas para validação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531944ad",
   "metadata": {},
   "source": [
    "### DB Config & Connection Test\n",
    "\n",
    "_Lê variáveis do`` =.env`` (se existir) ou usa defaults locais.\n",
    "Testa conexão, cria o schema ``silver`` (se não existir) e ajusta ``search_path``.\n",
    "Não falha o notebook se o Postgres não estiver no ar apenas avisa._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80e106ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_HOST: localhost | DB_PORT: 5435 | DB_NAME: olist | SCHEMA: silver\n"
     ]
    }
   ],
   "source": [
    "# 1) Carregar .env se existir (opcional)\n",
    "ENV_PATH = PROJECT_ROOT / \".env\"\n",
    "if ENV_PATH.exists():\n",
    "    # carregamento leve do .env (sem dependências)\n",
    "    with open(ENV_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "                continue\n",
    "            k, v = line.split(\"=\", 1)\n",
    "            os.environ.setdefault(k.strip(), v.strip())\n",
    "\n",
    "# 2) Variáveis de conexão (definidas aqui, mas a conexão será aberta somente na etapa LOAD no final do notebook)\n",
    "DB_HOST   = os.getenv(\"PGHOST\", \"localhost\")\n",
    "DB_PORT   = os.getenv(\"PGPORT\", \"5435\")\n",
    "DB_NAME   = os.getenv(\"PGDATABASE\", \"olist\")\n",
    "DB_USER   = os.getenv(\"PGUSER\", \"postgres\")\n",
    "DB_PASS   = os.getenv(\"PGPASSWORD\", \"postgres\")\n",
    "DB_SCHEMA = os.getenv(\"PGSCHEMA\", \"silver\")   # camada Silver\n",
    "\n",
    "print(\"DB_HOST:\", DB_HOST, \"| DB_PORT:\", DB_PORT, \"| DB_NAME:\", DB_NAME, \"| SCHEMA:\", DB_SCHEMA)\n",
    "\n",
    "# Nota: Não criamos `engine` nem tentamos abrir conexão aqui —\n",
    "# a conexão com o banco será feita apenas na etapa final de LOAD (para evitar depender do DB durante o desenvolvimento/transformações).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2005760",
   "metadata": {},
   "source": [
    "A célula abaixo, define uma função que verifica a existência de um arquivo CSV, carrega seu conteúdo da pasta bruta (Bronze) para a memória aplicando tipagens específicas, e, em seguida, executa um loop para extrair todos os arquivos listados ``(CSV_LIST)``, criando DataFrames em variáveis de acesso rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a900bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lendo Bronze: 100%|██████████| 9/9 [00:03<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_csv(filename: str, dtypes=None, parse_dates=None):\n",
    "    \"\"\"Carrega um CSV da Bronze, padroniza nomes das colunas (lower) e retorna DataFrame.\"\"\"\n",
    "    # 1. Encontra e verifica o caminho do arquivo no disco\n",
    "    path = RAW_DIR / filename\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"CSV não encontrado: {path}\")\n",
    "\n",
    "    # 2. LÊ o arquivo do disco para um DataFrame do Pandas (Extração Central)\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        dtype=dtypes or {},\n",
    "        parse_dates=parse_dates or [],\n",
    "        keep_default_na=True,\n",
    "        encoding=\"utf-8\",\n",
    "        # infer_datetime_format pode acelerar parsing em versões antigas do pandas,\n",
    "        # mas foi comentado antes por gerar barras duplicadas em alguns ambientes.\n",
    "        # infer_datetime_format=True, \n",
    "        low_memory=False,\n",
    "    )\n",
    "    # Padroniza nomes das colunas: remove espaços e coloca em lower-case (transformação) \n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "# ---------- load all ----------\n",
    "# Lista de CSVs esperados na pasta raw. \n",
    "CSV_LIST = [\n",
    "    \"olist_customers_dataset.csv\",\n",
    "    \"olist_geolocation_dataset.csv\",\n",
    "    \"olist_orders_dataset.csv\",\n",
    "    \"olist_order_items_dataset.csv\",\n",
    "    \"olist_order_payments_dataset.csv\",\n",
    "    \"olist_order_reviews_dataset.csv\",\n",
    "    \"olist_products_dataset.csv\",\n",
    "    \"olist_sellers_dataset.csv\",\n",
    "    \"product_category_name_translation.csv\",\n",
    "]\n",
    "\n",
    "# Safety: garantir que DTYPES e PARSE_DATES existam mesmo se o usuário executou células fora de ordem\n",
    "if 'DTYPES' not in globals():\n",
    "    print(\"[AVISO] DTYPES não encontrado. Definindo DTYPES = {} por segurança.\")\n",
    "    DTYPES = {}\n",
    "if 'PARSE_DATES' not in globals():\n",
    "    print(\"[AVISO] PARSE_DATES não encontrado. Definindo PARSE_DATES = {} por segurança.\")\n",
    "    PARSE_DATES = {}\n",
    "\n",
    "dfs = {}\n",
    "# 3. Itera sobre a lista e chama a função de leitura para extrair todos\n",
    "for name in tqdm(CSV_LIST, desc=\"Lendo Bronze\"):\n",
    "    dfs[name] = load_csv(\n",
    "        name,\n",
    "        dtypes=DTYPES.get(name),\n",
    "        parse_dates=PARSE_DATES.get(name),\n",
    "    )\n",
    "\n",
    "# 4. Cria aliases para os DataFrames extraídos\n",
    "customers   = dfs[\"olist_customers_dataset.csv\"]\n",
    "geos        = dfs[\"olist_geolocation_dataset.csv\"]\n",
    "orders      = dfs[\"olist_orders_dataset.csv\"]\n",
    "items       = dfs[\"olist_order_items_dataset.csv\"]\n",
    "payments    = dfs[\"olist_order_payments_dataset.csv\"]\n",
    "reviews     = dfs[\"olist_order_reviews_dataset.csv\"]\n",
    "products    = dfs[\"olist_products_dataset.csv\"]\n",
    "sellers     = dfs[\"olist_sellers_dataset.csv\"]\n",
    "prod_trans  = dfs[\"product_category_name_translation.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f31353-5f21-47e7-a40c-ade7191d8515",
   "metadata": {},
   "source": [
    "# TRANSFORM - Normalização para a Camada Silver\n",
    "\n",
    "- Padroniza strings, remove nulos críticos e duplicidades.\n",
    "- Enriquece `products` com tradução de categoria.\n",
    "- Garante integridade referencial: `items`, `payments` e `reviews` só com `order_id` válido; `items` só com `product_id`/`seller_id` válidos.\n",
    "- Agrega/geolocalização deduplicada por CEP prefixo.\n",
    "- Deriva campos úteis em `orders` (datas e métricas de entrega).\n",
    "- Cria dataframes finais: `silver_customers`, `silver_orders`, `silver_order_items`, `silver_products`, `silver_sellers`, `silver_payments`, `silver_reviews`, `silver_geolocation`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3822277",
   "metadata": {},
   "source": [
    "Definindo a função ``load_csv`` para leitura e padronização, e configura os dicionários ``(DTYPES, PARSE_DATES)`` que especificam os tipos de dados e colunas de data esperados para cada arquivo CSV, preparando as regras de transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0352d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename: str, dtypes=None, parse_dates=None):\n",
    "    \"\"\"Carrega um CSV da Bronze, padroniza nomes das colunas (lower) e retorna DataFrame.\"\"\"\n",
    "    path = RAW_DIR / filename\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"CSV não encontrado: {path}\")\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        dtype=dtypes or {},\n",
    "        parse_dates=parse_dates,\n",
    "        keep_default_na=True,\n",
    "        encoding=\"utf-8\",\n",
    "        infer_datetime_format=True,\n",
    "        low_memory=False,\n",
    "    )\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4868886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes por arquivo (usando tipos que aceitam NA quando necessário)\n",
    "Int = \"Int64\"  # inteiro com suporte a NA\n",
    "Str = \"string\"\n",
    "\n",
    "DTYPES = {\n",
    "    \"olist_orders_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"customer_id\": Str,\n",
    "        \"order_status\": Str,\n",
    "        # timestamps lidos via parse_dates\n",
    "    },\n",
    "    \"olist_order_items_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"order_item_id\": Int,\n",
    "        \"product_id\": Str,\n",
    "        \"seller_id\": Str,\n",
    "        \"price\": \"float64\",\n",
    "        \"freight_value\": \"float64\",\n",
    "        # shipping_limit_date via parse_dates\n",
    "    },\n",
    "    \"olist_order_payments_dataset.csv\": {\n",
    "        \"order_id\": Str,\n",
    "        \"payment_sequential\": Int,\n",
    "        \"payment_type\": Str,\n",
    "        \"payment_installments\": Int,\n",
    "        \"payment_value\": \"float64\",\n",
    "    },\n",
    "    \"olist_order_reviews_dataset.csv\": {\n",
    "        \"review_id\": Str,\n",
    "        \"order_id\": Str,\n",
    "        \"review_score\": Int,\n",
    "        \"review_comment_title\": Str,\n",
    "        \"review_comment_message\": Str,\n",
    "        # creation/answer via parse_dates\n",
    "    },\n",
    "    \"olist_products_dataset.csv\": {\n",
    "        \"product_id\": Str,\n",
    "        \"product_category_name\": Str,\n",
    "        \"product_name_lenght\": Int,\n",
    "        \"product_description_lenght\": Int,\n",
    "        \"product_photos_qty\": Int,\n",
    "        \"product_weight_g\": Int,\n",
    "        \"product_length_cm\": Int,\n",
    "        \"product_height_cm\": Int,\n",
    "        \"product_width_cm\": Int,\n",
    "    },\n",
    "    \"olist_sellers_dataset.csv\": {\n",
    "        \"seller_id\": Str,\n",
    "        \"seller_zip_code_prefix\": Int,\n",
    "        \"seller_city\": Str,\n",
    "        \"seller_state\": Str,\n",
    "    },\n",
    "    \"olist_customers_dataset.csv\": {\n",
    "        \"customer_id\": Str,\n",
    "        \"customer_unique_id\": Str,\n",
    "        \"customer_zip_code_prefix\": Int,\n",
    "        \"customer_city\": Str,\n",
    "        \"customer_state\": Str,\n",
    "    },\n",
    "    \"olist_geolocation_dataset.csv\": {\n",
    "        \"geolocation_zip_code_prefix\": Int,\n",
    "        \"geolocation_lat\": \"float64\",\n",
    "        \"geolocation_lng\": \"float64\",\n",
    "        \"geolocation_city\": Str,\n",
    "        \"geolocation_state\": Str,\n",
    "    },\n",
    "    \"product_category_name_translation.csv\": {\n",
    "        \"product_category_name\": Str,\n",
    "        \"product_category_name_english\": Str,\n",
    "    },\n",
    "}\n",
    "\n",
    "PARSE_DATES = {\n",
    "    \"olist_orders_dataset.csv\": [\n",
    "        \"order_purchase_timestamp\",\n",
    "        \"order_approved_at\",\n",
    "        \"order_delivered_carrier_date\",\n",
    "        \"order_delivered_customer_date\",\n",
    "        \"order_estimated_delivery_date\",\n",
    "    ],\n",
    "    \"olist_order_items_dataset.csv\": [\n",
    "        \"shipping_limit_date\",\n",
    "    ],\n",
    "    \"olist_order_reviews_dataset.csv\": [\n",
    "        \"review_creation_date\",\n",
    "        \"review_answer_timestamp\",\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb2383",
   "metadata": {},
   "source": [
    "Exibindo o número de linhas e colunas (shape) de todos os DataFrames carregados e imprime o detalhe dos tipos de dados (dtypes) do DataFrame de orders, fornecendo uma visão rápida da estrutura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1397c914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Shapes\n",
      "olist_customers_dataset.csv              -> (99441, 5)\n",
      "olist_geolocation_dataset.csv            -> (1000163, 5)\n",
      "olist_orders_dataset.csv                 -> (99441, 8)\n",
      "olist_order_items_dataset.csv            -> (112650, 7)\n",
      "olist_order_payments_dataset.csv         -> (103886, 5)\n",
      "olist_order_reviews_dataset.csv          -> (99224, 7)\n",
      "olist_products_dataset.csv               -> (32951, 9)\n",
      "olist_sellers_dataset.csv                -> (3095, 4)\n",
      "product_category_name_translation.csv    -> (71, 2)\n",
      "\n",
      "# Dtypes (orders)\n",
      "order_id                         string[python]\n",
      "customer_id                      string[python]\n",
      "order_status                     string[python]\n",
      "order_purchase_timestamp         datetime64[ns]\n",
      "order_approved_at                datetime64[ns]\n",
      "order_delivered_carrier_date     datetime64[ns]\n",
      "order_delivered_customer_date    datetime64[ns]\n",
      "order_estimated_delivery_date    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ---------- quick summary: Shapes ----------\n",
    "print(\"\\n# Shapes\")\n",
    "for k, v in dfs.items():\n",
    "    print(f\"{k:40s} -> {v.shape}\")\n",
    "\n",
    "print(\"\\n# Dtypes (orders)\")\n",
    "print(orders.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c13ddf",
   "metadata": {},
   "source": [
    "Exibe as três primeiras linhas (head(3)) de alguns DataFrames principais (orders, items, payments) para uma inspeção visual rápida e validação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d761d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Amostras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "\n",
       "  order_status order_purchase_timestamp   order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37 2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49 2018-08-08 08:55:23   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0                    2017-10-18  \n",
       "1                    2018-08-13  \n",
       "2                    2018-09-04  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>shipping_limit_date</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>1</td>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
       "      <td>2017-09-19 09:45:35</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
       "      <td>1</td>\n",
       "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
       "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
       "      <td>2017-05-03 11:05:13</td>\n",
       "      <td>239.9</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
       "      <td>1</td>\n",
       "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
       "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
       "      <td>2018-01-18 14:48:30</td>\n",
       "      <td>199.0</td>\n",
       "      <td>17.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  order_item_id  \\\n",
       "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
       "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
       "2  000229ec398224ef6ca0657da4fc703e              1   \n",
       "\n",
       "                         product_id                         seller_id  \\\n",
       "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
       "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
       "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
       "\n",
       "  shipping_limit_date  price  freight_value  \n",
       "0 2017-09-19 09:45:35   58.9          13.29  \n",
       "1 2017-05-03 11:05:13  239.9          19.93  \n",
       "2 2018-01-18 14:48:30  199.0          17.87  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>payment_installments</th>\n",
       "      <th>payment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b81ef226f3fe1789b1e8b2acac839d17</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>8</td>\n",
       "      <td>99.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9810da82917af2d9aefd1278f1dcfa0</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>24.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25e8ea4e93396b6fa0d3dd708e76c1bd</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>65.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  payment_sequential payment_type  \\\n",
       "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
       "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
       "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
       "\n",
       "   payment_installments  payment_value  \n",
       "0                     8          99.33  \n",
       "1                     1          24.39  \n",
       "2                     1          65.71  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- quick summary: Amostras ----------\n",
    "print(\"\\n# Amostras\")\n",
    "display(orders.head(3))\n",
    "display(items.head(3))\n",
    "display(payments.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b332c0b",
   "metadata": {},
   "source": [
    "Define e executa a função ``na_overview`` para calcular e imprimir a contagem de valores ausentes (NAs) nas colunas dos DataFrames principais, identificando onde a limpeza de dados (Transformação) será necessária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1a898da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NA overview — orders\n",
      "order_delivered_customer_date    2965\n",
      "order_delivered_carrier_date     1783\n",
      "order_approved_at                 160\n",
      "dtype: int64\n",
      "\n",
      "NA overview — products\n",
      "product_category_name         610\n",
      "product_name_lenght           610\n",
      "product_description_lenght    610\n",
      "product_photos_qty            610\n",
      "product_weight_g                2\n",
      "product_length_cm               2\n",
      "product_height_cm               2\n",
      "product_width_cm                2\n",
      "dtype: int64\n",
      "\n",
      "NA overview — reviews\n",
      "review_comment_title      87656\n",
      "review_comment_message    58247\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# NAs por coluna (visão geral) — útil para planejar a transformação\n",
    "def na_overview(df, name):\n",
    "    s = df.isna().sum()\n",
    "    if (s > 0).any():\n",
    "        print(f\"\\nNA overview — {name}\")\n",
    "        print(s[s > 0].sort_values(ascending=False).head(12))\n",
    "\n",
    "na_overview(orders, \"orders\")\n",
    "na_overview(items, \"items\")\n",
    "na_overview(products, \"products\")\n",
    "na_overview(reviews, \"reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8b4a9",
   "metadata": {},
   "source": [
    "### Funções Auxiliares de Limpeza (Transformação)\n",
    "Define três funções auxiliares essenciais para a fase de Transformação: norm_str (padronização de texto), drop_nulls (remoção de linhas com valores nulos) e drop_dups (remoção de linhas duplicadas, reportando a contagem de linhas afetadas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2bb16b-09dd-414c-a1d7-5afd77b81c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_str(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = (\n",
    "                df[c]\n",
    "                .astype(\"string\")\n",
    "                .str.strip()\n",
    "            )\n",
    "\n",
    "def drop_nulls(df, cols, name):\n",
    "    before = len(df)\n",
    "    df2 = df.dropna(subset=[c for c in cols if c in df.columns])\n",
    "    removed = before - len(df2)\n",
    "    if removed:\n",
    "        print(f\"[{name}] removidas {removed} linhas por nulos em {cols}\")\n",
    "    return df2\n",
    "\n",
    "def drop_dups(df, keys, name):\n",
    "    before = len(df)\n",
    "    df2 = df.drop_duplicates(subset=keys, keep=\"first\")\n",
    "    removed = before - len(df2)\n",
    "    if removed:\n",
    "        print(f\"[{name}] removidas {removed} duplicatas por {keys}\")\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6d673",
   "metadata": {},
   "source": [
    "### Limpeza e Transformação das Dimensões Mestre\n",
    "Aplica as funções de limpeza aos DataFrames de customers, sellers e geolocation (tabelas mestre/dimensão), garantindo que as chaves primárias não contenham nulos ou duplicatas, e realiza o merge para traduzir a categoria de products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1550e726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[geolocation] removidas 981148 duplicatas por ['geolocation_zip_code_prefix']\n"
     ]
    }
   ],
   "source": [
    "# ---------- Customers, Sellers, Geolocation (Limpeza Básica) ----------\n",
    "silver_customers = customers.copy()\n",
    "norm_str(silver_customers, [\"customer_id\",\"customer_unique_id\",\"customer_city\",\"customer_state\"])\n",
    "silver_customers = drop_nulls(silver_customers, [\"customer_id\"], \"customers\")\n",
    "silver_customers = drop_dups(silver_customers, [\"customer_id\"], \"customers\")\n",
    "\n",
    "silver_sellers = sellers.copy()\n",
    "norm_str(silver_sellers, [\"seller_id\",\"seller_city\",\"seller_state\"])\n",
    "silver_sellers = drop_nulls(silver_sellers, [\"seller_id\"], \"sellers\")\n",
    "silver_sellers = drop_dups(silver_sellers, [\"seller_id\"], \"sellers\")\n",
    "\n",
    "silver_geolocation = geos.copy()\n",
    "silver_geolocation = drop_nulls(silver_geolocation, [\"geolocation_zip_code_prefix\"], \"geolocation\")\n",
    "silver_geolocation = drop_dups(silver_geolocation, [\"geolocation_zip_code_prefix\"], \"geolocation\")\n",
    "\n",
    "# ---------- Products (+ tradução da categoria) ----------\n",
    "silver_products = products.copy()\n",
    "norm_str(silver_products, [\"product_id\",\"product_category_name\"])\n",
    "silver_products = silver_products.merge(\n",
    "    prod_trans, on=\"product_category_name\", how=\"left\"\n",
    ")\n",
    "silver_products = silver_products.rename(\n",
    "    columns={\"product_category_name_english\": \"product_category_en\"}\n",
    ")\n",
    "silver_products = drop_nulls(silver_products, [\"product_id\"], \"products\")\n",
    "silver_products = drop_dups(silver_products, [\"product_id\"], \"products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d201bc",
   "metadata": {},
   "source": [
    "### Transformação e Derivação de Pedidos (Orders)\n",
    "Limpa a tabela de orders e calcula métricas importantes de tempo de entrega, como o tempo total de delivery, o atraso em relação à estimativa e uma flag binária para indicar se o pedido foi entregue com atraso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "220279d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Orders (Limpeza e Derivados de Entrega) ----------\n",
    "silver_orders = orders.copy()\n",
    "norm_str(silver_orders, [\"order_id\",\"customer_id\",\"order_status\"])\n",
    "silver_orders = drop_nulls(silver_orders, [\"order_id\",\"customer_id\"], \"orders\")\n",
    "silver_orders = drop_dups(silver_orders, [\"order_id\"], \"orders\")\n",
    "\n",
    "# Garantir que colunas de data estão no tipo datetime (prevenindo AttributeError ao usar .dt)\n",
    "date_cols = [\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_approved_at\",\n",
    "    \"order_delivered_carrier_date\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\",\n",
    "]\n",
    "for c in date_cols:\n",
    "    if c in silver_orders.columns:\n",
    "        silver_orders[c] = pd.to_datetime(silver_orders[c], errors='coerce')\n",
    "\n",
    "# derivados úteis\n",
    "if \"order_purchase_timestamp\" in silver_orders.columns:\n",
    "    silver_orders[\"order_purchase_date\"] = silver_orders[\"order_purchase_timestamp\"].dt.date\n",
    "else:\n",
    "    silver_orders[\"order_purchase_date\"] = pd.NaT\n",
    "\n",
    "silver_orders[\"delivery_time_days\"] = (\n",
    "    silver_orders[\"order_delivered_customer_date\"] - silver_orders[\"order_purchase_timestamp\"]\n",
    ")\n",
    "# extrai dias e armazena como Int64 (suporta NA)\n",
    "silver_orders[\"delivery_time_days\"] = silver_orders[\"delivery_time_days\"].dt.days.astype(\"Int64\")\n",
    "\n",
    "silver_orders[\"delivery_delay_days\"] = (\n",
    "    silver_orders[\"order_delivered_customer_date\"] - silver_orders[\"order_estimated_delivery_date\"]\n",
    ")\n",
    "silver_orders[\"delivery_delay_days\"] = silver_orders[\"delivery_delay_days\"].dt.days.astype(\"Int64\")\n",
    "\n",
    "# flag binária indicando se foi entregue com atraso (1) ou não (0); trata NAs\n",
    "silver_orders[\"delivered_late\"] = (\n",
    "    (silver_orders[\"order_delivered_customer_date\"] > silver_orders[\"order_estimated_delivery_date\"]) \n",
    ")\n",
    "# converte para Int64 (1/0/NA)\n",
    "silver_orders[\"delivered_late\"] = silver_orders[\"delivered_late\"].astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ef9f3",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c440156",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea43701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6d3b6",
   "metadata": {},
   "source": [
    "### Integridade Referencial e Limpeza de Transações\n",
    "Garante a integridade dos dados ao filtrar as tabelas transacionais (items, payments, reviews), removendo registros que não possuem chaves válidas nas tabelas mestre recém-limpas (Silver), e aplica a limpeza final de nulos e duplicatas nessas tabelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ef7558b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reviews] removidas 814 duplicatas por ['review_id']\n"
     ]
    }
   ],
   "source": [
    "# ---------- Itens, Pagamentos, Avaliações (Integridade Referencial) ----------\n",
    "valid_orders = set(silver_orders[\"order_id\"])\n",
    "valid_products = set(silver_products[\"product_id\"])\n",
    "valid_sellers  = set(silver_sellers[\"seller_id\"])\n",
    "\n",
    "# Items\n",
    "silver_order_items = items.copy()\n",
    "norm_str(silver_order_items, [\"order_id\",\"product_id\",\"seller_id\"])\n",
    "silver_order_items = drop_nulls(silver_order_items, [\"order_id\",\"order_item_id\",\"product_id\",\"seller_id\"], \"order_items\")\n",
    "silver_order_items = silver_order_items[\n",
    "    silver_order_items[\"order_id\"].isin(valid_orders)\n",
    "    & silver_order_items[\"product_id\"].isin(valid_products)\n",
    "    & silver_order_items[\"seller_id\"].isin(valid_sellers)\n",
    "].copy()\n",
    "silver_order_items = drop_dups(silver_order_items, [\"order_id\",\"order_item_id\"], \"order_items\")\n",
    "\n",
    "# Payments\n",
    "silver_payments = payments.copy()\n",
    "norm_str(silver_payments, [\"order_id\",\"payment_type\"])\n",
    "silver_payments = drop_nulls(silver_payments, [\"order_id\"], \"payments\")\n",
    "silver_payments = silver_payments[silver_payments[\"order_id\"].isin(valid_orders)].copy()\n",
    "\n",
    "# Reviews\n",
    "silver_reviews = reviews.copy()\n",
    "norm_str(silver_reviews, [\"review_id\",\"order_id\"])\n",
    "silver_reviews = drop_nulls(silver_reviews, [\"review_id\",\"order_id\"], \"reviews\")\n",
    "silver_reviews = silver_reviews[silver_reviews[\"order_id\"].isin(valid_orders)].copy()\n",
    "silver_reviews = drop_dups(silver_reviews, [\"review_id\"], \"reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88579bb3",
   "metadata": {},
   "source": [
    "### Sanity Check Final da Camada Silver\n",
    "Exibe um resumo final da estrutura (shape) e amostras dos DataFrames recém-criados e limpos da camada Silver, confirmando que a Transformação foi concluída com sucesso e os dados estão prontos para a fase de Carregamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41d70ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resumo de Shapes da Camada Silver:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linhas</th>\n",
       "      <th>Colunas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>silver_customers</th>\n",
       "      <td>99441</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_sellers</th>\n",
       "      <td>3095</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_products</th>\n",
       "      <td>32951</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_geolocation</th>\n",
       "      <td>19015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_orders</th>\n",
       "      <td>99441</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_order_items</th>\n",
       "      <td>112650</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_payments</th>\n",
       "      <td>103886</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver_reviews</th>\n",
       "      <td>98410</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Linhas  Colunas\n",
       "silver_customers     99441        5\n",
       "silver_sellers        3095        4\n",
       "silver_products      32951       10\n",
       "silver_geolocation   19015        5\n",
       "silver_orders        99441       12\n",
       "silver_order_items  112650        7\n",
       "silver_payments     103886        5\n",
       "silver_reviews       98410        7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crie o dicionário de resumo dos shapes\n",
    "summary = {\n",
    "    \"silver_customers\": silver_customers.shape,\n",
    "    \"silver_sellers\": silver_sellers.shape,\n",
    "    \"silver_products\": silver_products.shape,\n",
    "    \"silver_geolocation\": silver_geolocation.shape,\n",
    "    \"silver_orders\": silver_orders.shape,\n",
    "    \"silver_order_items\": silver_order_items.shape,\n",
    "    \"silver_payments\": silver_payments.shape,\n",
    "    \"silver_reviews\": silver_reviews.shape,\n",
    "}\n",
    "\n",
    "# Converte o dicionário em um DataFrame para exibição tabular\n",
    "summary_df = pd.DataFrame(\n",
    "    summary.values(), \n",
    "    index=summary.keys(), \n",
    "    columns=[\"Linhas\", \"Colunas\"]\n",
    ")\n",
    "\n",
    "# Título do Resumo\n",
    "print(\"✅ Resumo de Shapes da Camada Silver:\")\n",
    "\n",
    "# Exibe o DataFrame de resumo\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f65a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae6f195a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostras da Camada Silver ---\n",
      "\n",
      "silver_orders (Pedidos):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>order_purchase_date</th>\n",
       "      <th>delivery_time_days</th>\n",
       "      <th>delivery_delay_days</th>\n",
       "      <th>delivered_late</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>8</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>13</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>9</td>\n",
       "      <td>-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "\n",
       "  order_status order_purchase_timestamp   order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37 2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49 2018-08-08 08:55:23   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "\n",
       "  order_estimated_delivery_date order_purchase_date  delivery_time_days  \\\n",
       "0                    2017-10-18          2017-10-02                   8   \n",
       "1                    2018-08-13          2018-07-24                  13   \n",
       "2                    2018-09-04          2018-08-08                   9   \n",
       "\n",
       "   delivery_delay_days  delivered_late  \n",
       "0                   -8               0  \n",
       "1                   -6               0  \n",
       "2                  -18               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "silver_order_items (Itens de Pedido):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>shipping_limit_date</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>1</td>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
       "      <td>2017-09-19 09:45:35</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
       "      <td>1</td>\n",
       "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
       "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
       "      <td>2017-05-03 11:05:13</td>\n",
       "      <td>239.9</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
       "      <td>1</td>\n",
       "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
       "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
       "      <td>2018-01-18 14:48:30</td>\n",
       "      <td>199.0</td>\n",
       "      <td>17.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  order_item_id  \\\n",
       "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
       "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
       "2  000229ec398224ef6ca0657da4fc703e              1   \n",
       "\n",
       "                         product_id                         seller_id  \\\n",
       "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
       "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
       "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
       "\n",
       "  shipping_limit_date  price  freight_value  \n",
       "0 2017-09-19 09:45:35   58.9          13.29  \n",
       "1 2017-05-03 11:05:13  239.9          19.93  \n",
       "2 2018-01-18 14:48:30  199.0          17.87  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "silver_products (Produtos):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "      <th>product_category_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>40</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>perfumery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>artes</td>\n",
       "      <td>44</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96bd76ec8810374ed1b65e291975717f</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>46</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>sports_leisure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id product_category_name  \\\n",
       "0  1e9e8ef04dbcff4541ed26657ea517e5            perfumaria   \n",
       "1  3aa071139cb16b67ca9e5dea641aaa2f                 artes   \n",
       "2  96bd76ec8810374ed1b65e291975717f         esporte_lazer   \n",
       "\n",
       "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
       "0                   40                         287                   1   \n",
       "1                   44                         276                   1   \n",
       "2                   46                         250                   1   \n",
       "\n",
       "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \\\n",
       "0               225                 16                 10                14   \n",
       "1              1000                 30                 18                20   \n",
       "2               154                 18                  9                15   \n",
       "\n",
       "  product_category_en  \n",
       "0           perfumery  \n",
       "1                 art  \n",
       "2      sports_leisure  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Amostras da Camada Silver ---\")\n",
    "\n",
    "print(\"\\nsilver_orders (Pedidos):\")\n",
    "display(silver_orders.head(3))\n",
    "\n",
    "print(\"\\nsilver_order_items (Itens de Pedido):\")\n",
    "display(silver_order_items.head(3))\n",
    "\n",
    "print(\"\\nsilver_products (Produtos):\")\n",
    "display(silver_products.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b6b63",
   "metadata": {},
   "source": [
    "# LOAD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ea881-d70a-445f-9d42-c32840b767e8",
   "metadata": {},
   "source": [
    "## Conectar e aplicar o DDL\n",
    "\n",
    "Esta célula configura a conexão com o banco de dados PostgreSQL lendo credenciais de um arquivo .env ou usando defaults, tenta se conectar, garante que o esquema silver exista e, se o arquivo DDL for encontrado, executa os comandos SQL para criar a estrutura de tabelas, preparando o banco para receber os dados limpos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6bc8762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates to test: [5435, 5432, 5434, 5436]\n",
      "✖ port 5435: OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5435 failed: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n",
      "✖ port 5432: OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n",
      "connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n",
      "\n",
      "✖ port 5434: OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5434 failed: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n",
      "✖ port 5436: OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5436 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n",
      "\n",
      "No successful connection using provided credentials and tried ports.\n",
      "If you expect a Docker container to expose Postgres, check `docker ps` and `docker logs` and/or fix port mapping in docker-compose.yml.\n"
     ]
    }
   ],
   "source": [
    "# Connection test — tenta detectar a porta PG funcional e ajusta PGPORT para as próximas células\n",
    "# Esta célula tenta se conectar via psycopg2 em uma lista de portas candidatas\n",
    "import os\n",
    "from pathlib import Path\n",
    "import psycopg2\n",
    "\n",
    "# Recarrega .env leve (se existir)\n",
    "ENV_PATH = PROJECT_ROOT / '.env'\n",
    "if ENV_PATH.exists():\n",
    "    for line in ENV_PATH.read_text(encoding='utf-8').splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#') or '=' not in line:\n",
    "            continue\n",
    "        k, v = line.split('=', 1)\n",
    "        os.environ.setdefault(k.strip(), v.strip())\n",
    "\n",
    "candidates = []\n",
    "env_port = os.getenv('PGPORT')\n",
    "if env_port:\n",
    "    try:\n",
    "        candidates.append(int(env_port))\n",
    "    except ValueError:\n",
    "        pass\n",
    "# common ports to try (preserves order)\n",
    "for p in (5435, 5432, 5434, 5436):\n",
    "    if p not in candidates:\n",
    "        candidates.append(p)\n",
    "\n",
    "DB_HOST = os.getenv('PGHOST', 'localhost')\n",
    "DB_NAME = os.getenv('PGDATABASE', 'olist')\n",
    "DB_USER = os.getenv('PGUSER', 'postgres')\n",
    "DB_PASS = os.getenv('PGPASSWORD', 'postgres')\n",
    "\n",
    "print('Candidates to test:', candidates)\n",
    "\n",
    "def try_connect(port, timeout=3):\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=DB_HOST, port=port, dbname=DB_NAME, user=DB_USER, password=DB_PASS, connect_timeout=timeout)\n",
    "        conn.close()\n",
    "        return True, None\n",
    "    except Exception as e:\n",
    "        return False, e\n",
    "\n",
    "success = None\n",
    "for port in candidates:\n",
    "    ok, err = try_connect(port)\n",
    "    if ok:\n",
    "        print(f'✅ Connection successful on port {port} (host={DB_HOST}, db={DB_NAME}, user={DB_USER})')\n",
    "        os.environ['PGPORT'] = str(port)\n",
    "        DB_PORT = str(port)\n",
    "        success = port\n",
    "        break\n",
    "    else:\n",
    "        print(f'✖ port {port}: {type(err).__name__}: {err}')\n",
    "\n",
    "if success is None:\n",
    "    print('\\nNo successful connection using provided credentials and tried ports.')\n",
    "    print('If you expect a Docker container to expose Postgres, check `docker ps` and `docker logs` and/or fix port mapping in docker-compose.yml.')\n",
    "else:\n",
    "    print('\\nSet PGPORT to', success, 'for subsequent cells. You can re-run the LOAD cell now.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07e7a5dc-8f72-45f5-9e9d-2b8859b2db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Tentando conectar…\n",
      "\n",
      "[AVISO] Não foi possível conectar ao Postgres agora. Detalhe do erro:\n",
      "OperationalError (psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5435 failed: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 143, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 3301, in raw_connection\n",
      "    return self.pool.connect()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 447, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 1264, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 711, in checkout\n",
      "    rec = pool._do_get()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py\", line 177, in _do_get\n",
      "    with util.safe_reraise():\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py\", line 224, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py\", line 175, in _do_get\n",
      "    return self._create_connection()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 388, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 673, in __init__\n",
      "    self.__connect()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 899, in __connect\n",
      "    with util.safe_reraise():\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py\", line 224, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 895, in __connect\n",
      "    self.dbapi_connection = connection = pool._invoke_creator(self)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py\", line 661, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 629, in connect\n",
      "    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/psycopg2/__init__.py\", line 122, in connect\n",
      "    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\n",
      "psycopg2.OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5435 failed: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_141764/1687945631.py\", line 29, in <module>\n",
      "    with engine.begin() as conn:\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 3241, in begin\n",
      "    with self.connect() as conn:\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 3277, in connect\n",
      "    return self._connection_cls(self)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 145, in __init__\n",
      "    Connection._handle_dbapi_exception_noconnection(\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 2440, in _handle_dbapi_exception_noconnection\n",
      "    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 143, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 3301, in raw_connection\n",
      "    return self.pool.connect()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 447, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 1264, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 711, in checkout\n",
      "    rec = pool._do_get()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py\", line 177, in _do_get\n",
      "    with util.safe_reraise():\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py\", line 224, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py\", line 175, in _do_get\n",
      "    return self._create_connection()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 388, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 673, in __init__\n",
      "    self.__connect()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 899, in __connect\n",
      "    with util.safe_reraise():\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py\", line 224, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 895, in __connect\n",
      "    self.dbapi_connection = connection = pool._invoke_creator(self)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py\", line 661, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 629, in connect\n",
      "    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/psycopg2/__init__.py\", line 122, in connect\n",
      "    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\n",
      "sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5435 failed: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "# 2.6.1 — Conectar no Postgres e aplicar o DDL (Silver)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Reusa PROJECT_ROOT, DDL_PATH, etc. já definidos antes\n",
    "ENV_PATH = PROJECT_ROOT / \".env\"\n",
    "if ENV_PATH.exists():\n",
    "    for line in ENV_PATH.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "            continue\n",
    "        k, v = line.split(\"=\", 1)\n",
    "        os.environ.setdefault(k.strip(), v.strip())\n",
    "\n",
    "DB_HOST   = os.getenv(\"PGHOST\", \"localhost\")\n",
    "DB_PORT   = os.getenv(\"PGPORT\", \"5435\")\n",
    "DB_NAME   = os.getenv(\"PGDATABASE\", \"olist\")\n",
    "DB_USER   = os.getenv(\"PGUSER\", \"postgres\")\n",
    "DB_PASS   = os.getenv(\"PGPASSWORD\", \"postgres\")\n",
    "DB_SCHEMA = os.getenv(\"PGSCHEMA\", \"silver\")   # camada Silver\n",
    "\n",
    "db_url = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(db_url, pool_pre_ping=True, future=True)\n",
    "\n",
    "print(\"→ Tentando conectar…\")\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        row = conn.exec_driver_sql(\"select current_database(), current_schema(), version();\").fetchone()\n",
    "        print(\"Conectado! ->\", row)\n",
    "\n",
    "        # Garante o schema Silver e seta o search_path\n",
    "        conn.exec_driver_sql(f'CREATE SCHEMA IF NOT EXISTS \"{DB_SCHEMA}\";')\n",
    "        conn.exec_driver_sql(f'SET search_path TO \"{DB_SCHEMA}\", public;')\n",
    "\n",
    "        # Executa o DDL do Pablo (se existir)\n",
    "        if DDL_PATH.exists():\n",
    "            sql = DDL_PATH.read_text(encoding=\"utf-8\").strip()\n",
    "            print(f\"→ Executando DDL de {DDL_PATH.name} (tamanho ~{DDL_PATH.stat().st_size} bytes)…\")\n",
    "            conn.exec_driver_sql(sql)\n",
    "            print(\"✅ DDL aplicado.\")\n",
    "        else:\n",
    "            print(\"⚠️ DDL não encontrado — seguiremos com to_sql para criar as tabelas.\")\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(\"\\n[AVISO] Não foi possível conectar ao Postgres agora. Detalhe do erro:\")\n",
    "    print(type(e).__name__, str(e))\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34ba949e-baf8-46cf-bc62-b6f099589307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ silver_treated_dataset.csv salvo em: /home/oem/Documentos/FGA/SBD2/SenTry/brazilian_e-commerce_analysis/data_layer/silver/silver_treated_dataset.csv  (112,650 linhas)\n"
     ]
    }
   ],
   "source": [
    "# 2.5 — Export: treated_dataset.csv (Silver)\n",
    "\n",
    "# Define Silver directory (same folder where your DDL lives)\n",
    "SILVER_DIR = PROJECT_ROOT / \"data_layer\" / \"silver\"\n",
    "SILVER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Payments aggregated per order (total value; you can add more metrics if needed)\n",
    "payments_agg = (\n",
    "    silver_payments\n",
    "    .groupby(\"order_id\", as_index=False)\n",
    "    .agg(total_payment_value=(\"payment_value\", \"sum\"))\n",
    ")\n",
    "\n",
    "# Build a row-per-item \"treated\" dataset by joining normalized Silver tables\n",
    "treated = (\n",
    "    silver_order_items\n",
    "    .merge(\n",
    "        silver_orders[[\n",
    "            \"order_id\",\"customer_id\",\"order_status\",\"order_purchase_timestamp\",\n",
    "            \"order_purchase_date\",\"delivery_time_days\",\"delivery_delay_days\",\"delivered_late\"\n",
    "        ]],\n",
    "        on=\"order_id\", how=\"left\"\n",
    "    )\n",
    "    .merge(\n",
    "        silver_products[[\n",
    "            \"product_id\",\"product_category_name\",\"product_category_en\",\n",
    "            \"product_weight_g\",\"product_length_cm\",\"product_height_cm\",\"product_width_cm\",\"product_photos_qty\"\n",
    "        ]],\n",
    "        on=\"product_id\", how=\"left\"\n",
    "    )\n",
    "    .merge(\n",
    "        silver_customers[[\n",
    "            \"customer_id\",\"customer_city\",\"customer_state\",\"customer_zip_code_prefix\"\n",
    "        ]],\n",
    "        on=\"customer_id\", how=\"left\"\n",
    "    )\n",
    "    .merge(\n",
    "        silver_sellers[[\n",
    "            \"seller_id\",\"seller_city\",\"seller_state\",\"seller_zip_code_prefix\"\n",
    "        ]],\n",
    "        on=\"seller_id\", how=\"left\"\n",
    "    )\n",
    "    .merge(\n",
    "        payments_agg, on=\"order_id\", how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Optional: friendly column order\n",
    "cols = [\n",
    "    # order / time\n",
    "    \"order_id\",\"order_status\",\"order_purchase_timestamp\",\"order_purchase_date\",\n",
    "    \"delivery_time_days\",\"delivery_delay_days\",\"delivered_late\",\n",
    "    # customer\n",
    "    \"customer_id\",\"customer_city\",\"customer_state\",\"customer_zip_code_prefix\",\n",
    "    # item\n",
    "    \"order_item_id\",\"product_id\",\"seller_id\",\"price\",\"freight_value\",\"shipping_limit_date\",\n",
    "    # product\n",
    "    \"product_category_en\",\"product_category_name\",\"product_photos_qty\",\n",
    "    \"product_weight_g\",\"product_length_cm\",\"product_height_cm\",\"product_width_cm\",\n",
    "    # seller\n",
    "    \"seller_city\",\"seller_state\",\"seller_zip_code_prefix\",\n",
    "    # payments\n",
    "    \"total_payment_value\",\n",
    "]\n",
    "treated = treated[[c for c in cols if c in treated.columns]].copy()\n",
    "\n",
    "# Save CSV to Silver\n",
    "treated_path = SILVER_DIR / \"silver_treated_dataset.csv\"\n",
    "treated.to_csv(treated_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ silver_treated_dataset.csv salvo em: {treated_path}  ({len(treated):,} linhas)\")\n",
    "\n",
    "silver_tables = {\n",
    "    \"customers\": silver_customers,\n",
    "    \"sellers\": silver_sellers,\n",
    "    \"products\": silver_products,\n",
    "    \"geolocation\": silver_geolocation,\n",
    "    \"orders\": silver_orders,\n",
    "    \"order_items\": silver_order_items,\n",
    "    \"payments\": silver_payments,\n",
    "    \"reviews\": silver_reviews,\n",
    "    \"treated_order_items\": treated,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab75375-5132-48b4-8e44-071373e15c8b",
   "metadata": {},
   "source": [
    "## Load para Silver (to_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a409ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando carga das tabelas Silver no PostgreSQL ---\n",
      "❌ Falha ao carregar dados no Postgres: (psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5435 failed: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5435 failed: server closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:143\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3301\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3280\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3281\u001b[0m \n\u001b[1;32m   3282\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3299\u001b[0m \n\u001b[1;32m   3300\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:447\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:1264\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1264\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:711\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 711\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:175\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:388\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:673\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 673\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:899\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 899\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    900\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:895\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 895\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py:661\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:629\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DBAPIConnection:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/psycopg2/__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOperationalError\u001b[0m: connection to server at \"localhost\" (127.0.0.1), port 5435 failed: server closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 21\u001b[0m\n\u001b[1;32m      8\u001b[0m load_order \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msellers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtreated_order_items\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m ]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mbegin() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     22\u001b[0m         conn\u001b[38;5;241m.\u001b[39mexec_driver_sql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSET search_path TO \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDB_SCHEMA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, public;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m table_name \u001b[38;5;129;01min\u001b[39;00m load_order:\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3241\u001b[0m, in \u001b[0;36mEngine.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3216\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m   3217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbegin\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Connection]:\n\u001b[1;32m   3218\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a context manager delivering a :class:`_engine.Connection`\u001b[39;00m\n\u001b[1;32m   3219\u001b[0m \u001b[38;5;124;03m    with a :class:`.Transaction` established.\u001b[39;00m\n\u001b[1;32m   3220\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3239\u001b[0m \n\u001b[1;32m   3240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m-> 3241\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m   3242\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mbegin():\n\u001b[1;32m   3243\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m conn\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3277\u001b[0m, in \u001b[0;36mEngine.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[1;32m   3255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m \n\u001b[1;32m   3257\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3274\u001b[0m \n\u001b[1;32m   3275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 145\u001b[0m         \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2440\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[0;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2439\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2442\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:143\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    145\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[1;32m    146\u001b[0m             err, dialect, engine\n\u001b[1;32m    147\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3301\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m   3280\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3281\u001b[0m \n\u001b[1;32m   3282\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3299\u001b[0m \n\u001b[1;32m   3300\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:447\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:1264\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1264\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1267\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:711\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    709\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 711\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    714\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:175\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:388\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[1;32m    386\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:673\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 673\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:899\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 899\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    900\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:895\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py:661\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    659\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:629\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DBAPIConnection:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/psycopg2/__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[0;31mOperationalError\u001b[0m: (psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5435 failed: server closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "print(\"--- Iniciando carga das tabelas Silver no PostgreSQL ---\")\n",
    "\n",
    "if \"engine\" not in globals():\n",
    "    raise RuntimeError(\"Engine SQLAlchemy não inicializado. Execute a célula de conexão antes desta.\")\n",
    "if \"silver_tables\" not in globals():\n",
    "    raise RuntimeError(\"Nenhum DataFrame Silver encontrado. Execute as etapas de transformação antes da carga.\")\n",
    "\n",
    "load_order = [\n",
    "    \"customers\",\n",
    "    \"sellers\",\n",
    "    \"products\",\n",
    "    \"geolocation\",\n",
    "    \"orders\",\n",
    "    \"order_items\",\n",
    "    \"payments\",\n",
    "    \"reviews\",\n",
    "    \"treated_order_items\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        conn.exec_driver_sql(f'SET search_path TO \"{DB_SCHEMA}\", public;')\n",
    "        for table_name in load_order:\n",
    "            df = silver_tables[table_name]\n",
    "            df.to_sql(\n",
    "                table_name,\n",
    "                conn,\n",
    "                schema=DB_SCHEMA,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "                method=\"multi\",\n",
    "                chunksize=1000,\n",
    "            )\n",
    "            print(f\"→ {table_name}: {len(df):,} linhas carregadas.\")\n",
    "    print(\"✅ Carga concluída.\")\n",
    "except Exception as exc:\n",
    "    print(\"❌ Falha ao carregar dados no Postgres:\", exc)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1aded6",
   "metadata": {},
   "source": [
    "### ✅ Validação da Carga no PostgreSQL\n",
    "\n",
    "As células abaixo executam conferências diretas no banco para garantir que a etapa `LOAD` funcionou como esperado:\n",
    "- **Contagem de linhas**: compara o número de registros de cada tabela Silver no Postgres com o que foi gerado em memória.\n",
    "- **Integridade referencial**: identifica pedidos sem itens associados, para confirmar que os ausentes correspondem a status cancelados/unavailable.\n",
    "- **Métricas derivadas**: verifica a distribuição da flag `delivered_late` e o faturamento por estado (`total_payment_value`) a partir da tabela `treated_order_items`.\n",
    "\n",
    "Esses checks servem como *sanity checks* após o ETL, assegurando que não houve perda de dados e que as métricas principais permanecem consistentes com os resultados esperados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2034fa9",
   "metadata": {},
   "source": [
    "## Validando contagem das tabelas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744de61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers: 99,441 linhas\n",
      "sellers: 3,095 linhas\n",
      "products: 32,951 linhas\n",
      "geolocation: 19,015 linhas\n",
      "orders: 99,441 linhas\n",
      "order_items: 112,650 linhas\n",
      "payments: 103,886 linhas\n",
      "reviews: 98,410 linhas\n",
      "treated_order_items: 112,650 linhas\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.exec_driver_sql(f'SET search_path TO \"{DB_SCHEMA}\", public;')\n",
    "    for table in [\n",
    "        \"customers\",\n",
    "        \"sellers\",\n",
    "        \"products\",\n",
    "        \"geolocation\",\n",
    "        \"orders\",\n",
    "        \"order_items\",\n",
    "        \"payments\",\n",
    "        \"reviews\",\n",
    "        \"treated_order_items\",\n",
    "    ]:\n",
    "        count = conn.exec_driver_sql(f\"SELECT COUNT(*) FROM {table};\").scalar()\n",
    "        print(f\"{table}: {count:,} linhas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15545a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedidos sem itens: 775\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.exec_driver_sql(f'SET search_path TO \"{DB_SCHEMA}\", public;')\n",
    "    missing_items = conn.exec_driver_sql(\"\"\"\n",
    "        SELECT COUNT(*) FROM orders o\n",
    "        WHERE NOT EXISTS (\n",
    "            SELECT 1 FROM order_items oi WHERE oi.order_id = o.order_id\n",
    "        );\n",
    "    \"\"\").scalar()\n",
    "    print(\"Pedidos sem itens:\", missing_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b39f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delivered_late</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>91614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   delivered_late  count\n",
       "0               0  91614\n",
       "1               1   7827"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\n",
    "    'SELECT delivered_late, COUNT(*) FROM orders GROUP BY delivered_late',\n",
    "    engine,\n",
    "    params=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0973f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_state</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP</td>\n",
       "      <td>7597209.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RJ</td>\n",
       "      <td>2769347.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MG</td>\n",
       "      <td>2326151.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RS</td>\n",
       "      <td>1147277.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR</td>\n",
       "      <td>1064603.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_state  total_amount\n",
       "0             SP    7597209.66\n",
       "1             RJ    2769347.44\n",
       "2             MG    2326151.64\n",
       "3             RS    1147277.00\n",
       "4             PR    1064603.99"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT customer_state, SUM(total_payment_value) AS total_amount\n",
    "    FROM treated_order_items\n",
    "    GROUP BY customer_state\n",
    "    ORDER BY total_amount DESC\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1046cb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_state</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP</td>\n",
       "      <td>7597209.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RJ</td>\n",
       "      <td>2769347.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MG</td>\n",
       "      <td>2326151.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RS</td>\n",
       "      <td>1147277.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR</td>\n",
       "      <td>1064603.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_state  total_amount\n",
       "0             SP    7597209.66\n",
       "1             RJ    2769347.44\n",
       "2             MG    2326151.64\n",
       "3             RS    1147277.00\n",
       "4             PR    1064603.99"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT customer_state, SUM(total_payment_value) AS total_amount\n",
    "    FROM treated_order_items\n",
    "    GROUP BY customer_state\n",
    "    ORDER BY total_amount DESC\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ea476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_status</th>\n",
       "      <th>qtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canceled</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>created</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invoiced</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shipped</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_status  qtd\n",
       "0  unavailable  603\n",
       "1     canceled  164\n",
       "2      created    5\n",
       "3     invoiced    2\n",
       "4      shipped    1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"\"\"\n",
    "    SELECT order_status, COUNT(*) AS qtd\n",
    "    FROM orders o\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM order_items oi WHERE oi.order_id = o.order_id\n",
    "    )\n",
    "    GROUP BY order_status\n",
    "    ORDER BY qtd DESC;\n",
    "\"\"\", engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
